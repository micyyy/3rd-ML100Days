{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day077_HW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogwBhRkh5A6y",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
        "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29i7zVU75A64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "a03cca79-9215-4f72-b9ac-523a839918bf"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "\n",
        "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASQrunc25A7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c0263363-030d-4a5a-d610-a4f89c76e741"
      },
      "source": [
        "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyG1GPcc5A7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 將 X 與 Y 獨立放進變數\n",
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "# 資料前處理 - 標準化\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "\n",
        "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "x_test = x_test.reshape((len(x_test), -1))\n",
        "\n",
        "# 將目標轉為 one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BAUnaD-5A7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "2f01e92a-86df-4dd4-ca02-31be76faa523"
      },
      "source": [
        "def build_mlp():\n",
        "    \"\"\"Code Here\n",
        "    建立你的神經網路\n",
        "    \"\"\"\n",
        "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
        "    x = keras.layers.Dense(units=512, activation='relu')(input_layer)\n",
        "    x = keras.layers.Dense(units=256, activation='relu')(x)\n",
        "    x = keras.layers.Dense(units=128, activation='relu')(x)\n",
        "    out = keras.layers.Dense(units=10, activation='softmax')(x)\n",
        "\n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
        "\n",
        "    return model\n",
        "model = build_mlp()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05E5v3J55A71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "190fac63-9688-4463-db86-6c1c2761d1db"
      },
      "source": [
        "\"\"\"\n",
        "Compile 模型\n",
        "\"\"\"\n",
        "model.summary()\n",
        "\n",
        "optimizer = keras.optimizers.sgd(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "k15r8FuV5A8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb77061a-05a1-46e9-eb71-ee05eebb562e"
      },
      "source": [
        "\"\"\"\n",
        "設定要訓練的 Epoch 數\n",
        "\"\"\"\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=500, \n",
        "          batch_size=256, \n",
        "          validation_data=(x_test, y_test), \n",
        "          shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 13s 259us/step - loss: 2.2879 - acc: 0.1404 - val_loss: 2.2410 - val_acc: 0.1895\n",
            "Epoch 2/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 2.2138 - acc: 0.2061 - val_loss: 2.1871 - val_acc: 0.2271\n",
            "Epoch 3/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 2.1630 - acc: 0.2382 - val_loss: 2.1382 - val_acc: 0.2494\n",
            "Epoch 4/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 2.1164 - acc: 0.2576 - val_loss: 2.0958 - val_acc: 0.2669\n",
            "Epoch 5/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 2.0766 - acc: 0.2744 - val_loss: 2.0588 - val_acc: 0.2827\n",
            "Epoch 6/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 2.0419 - acc: 0.2902 - val_loss: 2.0268 - val_acc: 0.2966\n",
            "Epoch 7/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 2.0123 - acc: 0.3012 - val_loss: 1.9996 - val_acc: 0.3050\n",
            "Epoch 8/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.9868 - acc: 0.3097 - val_loss: 1.9776 - val_acc: 0.3087\n",
            "Epoch 9/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.9649 - acc: 0.3173 - val_loss: 1.9566 - val_acc: 0.3214\n",
            "Epoch 10/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.9466 - acc: 0.3231 - val_loss: 1.9396 - val_acc: 0.3257\n",
            "Epoch 11/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.9307 - acc: 0.3290 - val_loss: 1.9250 - val_acc: 0.3313\n",
            "Epoch 12/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.9166 - acc: 0.3331 - val_loss: 1.9121 - val_acc: 0.3361\n",
            "Epoch 13/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.9040 - acc: 0.3373 - val_loss: 1.9002 - val_acc: 0.3359\n",
            "Epoch 14/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.8925 - acc: 0.3415 - val_loss: 1.8899 - val_acc: 0.3488\n",
            "Epoch 15/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.8821 - acc: 0.3436 - val_loss: 1.8794 - val_acc: 0.3459\n",
            "Epoch 16/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.8722 - acc: 0.3485 - val_loss: 1.8713 - val_acc: 0.3472\n",
            "Epoch 17/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.8634 - acc: 0.3518 - val_loss: 1.8617 - val_acc: 0.3551\n",
            "Epoch 18/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.8548 - acc: 0.3536 - val_loss: 1.8554 - val_acc: 0.3499\n",
            "Epoch 19/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.8467 - acc: 0.3565 - val_loss: 1.8465 - val_acc: 0.3568\n",
            "Epoch 20/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.8395 - acc: 0.3589 - val_loss: 1.8412 - val_acc: 0.3596\n",
            "Epoch 21/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.8324 - acc: 0.3604 - val_loss: 1.8344 - val_acc: 0.3647\n",
            "Epoch 22/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.8258 - acc: 0.3638 - val_loss: 1.8267 - val_acc: 0.3643\n",
            "Epoch 23/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.8192 - acc: 0.3658 - val_loss: 1.8207 - val_acc: 0.3685\n",
            "Epoch 24/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.8132 - acc: 0.3670 - val_loss: 1.8141 - val_acc: 0.3726\n",
            "Epoch 25/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.8074 - acc: 0.3700 - val_loss: 1.8088 - val_acc: 0.3706\n",
            "Epoch 26/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.8018 - acc: 0.3718 - val_loss: 1.8034 - val_acc: 0.3710\n",
            "Epoch 27/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.7961 - acc: 0.3743 - val_loss: 1.7976 - val_acc: 0.3756\n",
            "Epoch 28/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.7908 - acc: 0.3770 - val_loss: 1.7925 - val_acc: 0.3728\n",
            "Epoch 29/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.7857 - acc: 0.3778 - val_loss: 1.7887 - val_acc: 0.3798\n",
            "Epoch 30/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.7808 - acc: 0.3796 - val_loss: 1.7833 - val_acc: 0.3754\n",
            "Epoch 31/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.7759 - acc: 0.3803 - val_loss: 1.7782 - val_acc: 0.3791\n",
            "Epoch 32/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.7711 - acc: 0.3827 - val_loss: 1.7736 - val_acc: 0.3800\n",
            "Epoch 33/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7665 - acc: 0.3845 - val_loss: 1.7690 - val_acc: 0.3825\n",
            "Epoch 34/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7621 - acc: 0.3849 - val_loss: 1.7639 - val_acc: 0.3823\n",
            "Epoch 35/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7577 - acc: 0.3873 - val_loss: 1.7600 - val_acc: 0.3848\n",
            "Epoch 36/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.7531 - acc: 0.3892 - val_loss: 1.7550 - val_acc: 0.3862\n",
            "Epoch 37/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.7489 - acc: 0.3909 - val_loss: 1.7523 - val_acc: 0.3889\n",
            "Epoch 38/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.7447 - acc: 0.3926 - val_loss: 1.7484 - val_acc: 0.3861\n",
            "Epoch 39/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.7405 - acc: 0.3939 - val_loss: 1.7428 - val_acc: 0.3892\n",
            "Epoch 40/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7364 - acc: 0.3954 - val_loss: 1.7399 - val_acc: 0.3921\n",
            "Epoch 41/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.7328 - acc: 0.3969 - val_loss: 1.7362 - val_acc: 0.3916\n",
            "Epoch 42/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.7287 - acc: 0.3983 - val_loss: 1.7320 - val_acc: 0.3954\n",
            "Epoch 43/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.7245 - acc: 0.4012 - val_loss: 1.7277 - val_acc: 0.3966\n",
            "Epoch 44/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.7208 - acc: 0.4016 - val_loss: 1.7237 - val_acc: 0.3963\n",
            "Epoch 45/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.7170 - acc: 0.4027 - val_loss: 1.7195 - val_acc: 0.3980\n",
            "Epoch 46/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.7132 - acc: 0.4041 - val_loss: 1.7170 - val_acc: 0.3985\n",
            "Epoch 47/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.7092 - acc: 0.4059 - val_loss: 1.7122 - val_acc: 0.4008\n",
            "Epoch 48/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.7057 - acc: 0.4067 - val_loss: 1.7111 - val_acc: 0.4033\n",
            "Epoch 49/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.7021 - acc: 0.4084 - val_loss: 1.7086 - val_acc: 0.4030\n",
            "Epoch 50/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6987 - acc: 0.4090 - val_loss: 1.7036 - val_acc: 0.4055\n",
            "Epoch 51/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6951 - acc: 0.4113 - val_loss: 1.6989 - val_acc: 0.4065\n",
            "Epoch 52/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6920 - acc: 0.4116 - val_loss: 1.6952 - val_acc: 0.4065\n",
            "Epoch 53/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6884 - acc: 0.4135 - val_loss: 1.6929 - val_acc: 0.4081\n",
            "Epoch 54/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6849 - acc: 0.4149 - val_loss: 1.6890 - val_acc: 0.4097\n",
            "Epoch 55/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6818 - acc: 0.4160 - val_loss: 1.6881 - val_acc: 0.4085\n",
            "Epoch 56/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6786 - acc: 0.4175 - val_loss: 1.6836 - val_acc: 0.4103\n",
            "Epoch 57/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6754 - acc: 0.4180 - val_loss: 1.6828 - val_acc: 0.4100\n",
            "Epoch 58/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6722 - acc: 0.4199 - val_loss: 1.6790 - val_acc: 0.4124\n",
            "Epoch 59/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6693 - acc: 0.4185 - val_loss: 1.6762 - val_acc: 0.4118\n",
            "Epoch 60/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6662 - acc: 0.4218 - val_loss: 1.6733 - val_acc: 0.4142\n",
            "Epoch 61/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6632 - acc: 0.4220 - val_loss: 1.6689 - val_acc: 0.4163\n",
            "Epoch 62/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.6603 - acc: 0.4248 - val_loss: 1.6663 - val_acc: 0.4138\n",
            "Epoch 63/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6573 - acc: 0.4231 - val_loss: 1.6638 - val_acc: 0.4156\n",
            "Epoch 64/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6544 - acc: 0.4247 - val_loss: 1.6606 - val_acc: 0.4174\n",
            "Epoch 65/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6517 - acc: 0.4257 - val_loss: 1.6600 - val_acc: 0.4220\n",
            "Epoch 66/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6485 - acc: 0.4265 - val_loss: 1.6584 - val_acc: 0.4195\n",
            "Epoch 67/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6460 - acc: 0.4276 - val_loss: 1.6545 - val_acc: 0.4221\n",
            "Epoch 68/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6430 - acc: 0.4282 - val_loss: 1.6501 - val_acc: 0.4234\n",
            "Epoch 69/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6404 - acc: 0.4296 - val_loss: 1.6496 - val_acc: 0.4216\n",
            "Epoch 70/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6377 - acc: 0.4293 - val_loss: 1.6452 - val_acc: 0.4231\n",
            "Epoch 71/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6349 - acc: 0.4310 - val_loss: 1.6444 - val_acc: 0.4247\n",
            "Epoch 72/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.6326 - acc: 0.4326 - val_loss: 1.6413 - val_acc: 0.4252\n",
            "Epoch 73/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.6298 - acc: 0.4329 - val_loss: 1.6380 - val_acc: 0.4275\n",
            "Epoch 74/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6270 - acc: 0.4331 - val_loss: 1.6356 - val_acc: 0.4288\n",
            "Epoch 75/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6245 - acc: 0.4341 - val_loss: 1.6319 - val_acc: 0.4273\n",
            "Epoch 76/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6222 - acc: 0.4354 - val_loss: 1.6310 - val_acc: 0.4291\n",
            "Epoch 77/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6194 - acc: 0.4362 - val_loss: 1.6323 - val_acc: 0.4307\n",
            "Epoch 78/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.6170 - acc: 0.4358 - val_loss: 1.6258 - val_acc: 0.4321\n",
            "Epoch 79/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.6146 - acc: 0.4382 - val_loss: 1.6256 - val_acc: 0.4309\n",
            "Epoch 80/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6122 - acc: 0.4382 - val_loss: 1.6219 - val_acc: 0.4326\n",
            "Epoch 81/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.6098 - acc: 0.4385 - val_loss: 1.6230 - val_acc: 0.4311\n",
            "Epoch 82/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6073 - acc: 0.4385 - val_loss: 1.6194 - val_acc: 0.4335\n",
            "Epoch 83/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.6049 - acc: 0.4402 - val_loss: 1.6156 - val_acc: 0.4339\n",
            "Epoch 84/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.6027 - acc: 0.4409 - val_loss: 1.6135 - val_acc: 0.4362\n",
            "Epoch 85/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.6001 - acc: 0.4427 - val_loss: 1.6128 - val_acc: 0.4371\n",
            "Epoch 86/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5978 - acc: 0.4428 - val_loss: 1.6117 - val_acc: 0.4324\n",
            "Epoch 87/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5955 - acc: 0.4429 - val_loss: 1.6081 - val_acc: 0.4385\n",
            "Epoch 88/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5933 - acc: 0.4439 - val_loss: 1.6050 - val_acc: 0.4386\n",
            "Epoch 89/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5911 - acc: 0.4452 - val_loss: 1.6028 - val_acc: 0.4395\n",
            "Epoch 90/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.5891 - acc: 0.4449 - val_loss: 1.6012 - val_acc: 0.4412\n",
            "Epoch 91/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5871 - acc: 0.4451 - val_loss: 1.6029 - val_acc: 0.4422\n",
            "Epoch 92/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5849 - acc: 0.4467 - val_loss: 1.5966 - val_acc: 0.4410\n",
            "Epoch 93/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5825 - acc: 0.4475 - val_loss: 1.5981 - val_acc: 0.4393\n",
            "Epoch 94/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5805 - acc: 0.4488 - val_loss: 1.5936 - val_acc: 0.4402\n",
            "Epoch 95/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5780 - acc: 0.4491 - val_loss: 1.5940 - val_acc: 0.4412\n",
            "Epoch 96/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5762 - acc: 0.4504 - val_loss: 1.5897 - val_acc: 0.4449\n",
            "Epoch 97/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5741 - acc: 0.4512 - val_loss: 1.5879 - val_acc: 0.4428\n",
            "Epoch 98/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5721 - acc: 0.4513 - val_loss: 1.5902 - val_acc: 0.4402\n",
            "Epoch 99/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5701 - acc: 0.4523 - val_loss: 1.5846 - val_acc: 0.4472\n",
            "Epoch 100/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5680 - acc: 0.4531 - val_loss: 1.5845 - val_acc: 0.4443\n",
            "Epoch 101/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5659 - acc: 0.4539 - val_loss: 1.5812 - val_acc: 0.4458\n",
            "Epoch 102/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5642 - acc: 0.4542 - val_loss: 1.5796 - val_acc: 0.4461\n",
            "Epoch 103/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.5621 - acc: 0.4547 - val_loss: 1.5799 - val_acc: 0.4430\n",
            "Epoch 104/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5599 - acc: 0.4556 - val_loss: 1.5794 - val_acc: 0.4425\n",
            "Epoch 105/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5582 - acc: 0.4573 - val_loss: 1.5743 - val_acc: 0.4460\n",
            "Epoch 106/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.5562 - acc: 0.4566 - val_loss: 1.5745 - val_acc: 0.4492\n",
            "Epoch 107/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5541 - acc: 0.4569 - val_loss: 1.5735 - val_acc: 0.4493\n",
            "Epoch 108/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5521 - acc: 0.4593 - val_loss: 1.5732 - val_acc: 0.4489\n",
            "Epoch 109/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5503 - acc: 0.4593 - val_loss: 1.5687 - val_acc: 0.4480\n",
            "Epoch 110/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5486 - acc: 0.4607 - val_loss: 1.5672 - val_acc: 0.4498\n",
            "Epoch 111/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5470 - acc: 0.4601 - val_loss: 1.5674 - val_acc: 0.4490\n",
            "Epoch 112/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5448 - acc: 0.4604 - val_loss: 1.5674 - val_acc: 0.4501\n",
            "Epoch 113/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5430 - acc: 0.4614 - val_loss: 1.5657 - val_acc: 0.4498\n",
            "Epoch 114/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5411 - acc: 0.4631 - val_loss: 1.5617 - val_acc: 0.4533\n",
            "Epoch 115/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5394 - acc: 0.4635 - val_loss: 1.5590 - val_acc: 0.4532\n",
            "Epoch 116/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5377 - acc: 0.4637 - val_loss: 1.5609 - val_acc: 0.4509\n",
            "Epoch 117/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5355 - acc: 0.4649 - val_loss: 1.5588 - val_acc: 0.4539\n",
            "Epoch 118/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5340 - acc: 0.4647 - val_loss: 1.5620 - val_acc: 0.4504\n",
            "Epoch 119/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.5321 - acc: 0.4656 - val_loss: 1.5532 - val_acc: 0.4548\n",
            "Epoch 120/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5301 - acc: 0.4661 - val_loss: 1.5525 - val_acc: 0.4525\n",
            "Epoch 121/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5288 - acc: 0.4679 - val_loss: 1.5538 - val_acc: 0.4519\n",
            "Epoch 122/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5268 - acc: 0.4672 - val_loss: 1.5510 - val_acc: 0.4530\n",
            "Epoch 123/500\n",
            "50000/50000 [==============================] - 12s 230us/step - loss: 1.5250 - acc: 0.4687 - val_loss: 1.5484 - val_acc: 0.4569\n",
            "Epoch 124/500\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 1.5233 - acc: 0.4693 - val_loss: 1.5454 - val_acc: 0.4572\n",
            "Epoch 125/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.5214 - acc: 0.4700 - val_loss: 1.5458 - val_acc: 0.4571\n",
            "Epoch 126/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.5201 - acc: 0.4700 - val_loss: 1.5442 - val_acc: 0.4567\n",
            "Epoch 127/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.5182 - acc: 0.4707 - val_loss: 1.5513 - val_acc: 0.4561\n",
            "Epoch 128/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.5163 - acc: 0.4722 - val_loss: 1.5445 - val_acc: 0.4555\n",
            "Epoch 129/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5148 - acc: 0.4714 - val_loss: 1.5390 - val_acc: 0.4569\n",
            "Epoch 130/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5130 - acc: 0.4734 - val_loss: 1.5415 - val_acc: 0.4572\n",
            "Epoch 131/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5113 - acc: 0.4736 - val_loss: 1.5381 - val_acc: 0.4581\n",
            "Epoch 132/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.5098 - acc: 0.4736 - val_loss: 1.5411 - val_acc: 0.4571\n",
            "Epoch 133/500\n",
            "50000/50000 [==============================] - 11s 230us/step - loss: 1.5080 - acc: 0.4741 - val_loss: 1.5355 - val_acc: 0.4589\n",
            "Epoch 134/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.5064 - acc: 0.4751 - val_loss: 1.5342 - val_acc: 0.4582\n",
            "Epoch 135/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.5046 - acc: 0.4760 - val_loss: 1.5327 - val_acc: 0.4595\n",
            "Epoch 136/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.5031 - acc: 0.4765 - val_loss: 1.5316 - val_acc: 0.4610\n",
            "Epoch 137/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.5013 - acc: 0.4777 - val_loss: 1.5287 - val_acc: 0.4617\n",
            "Epoch 138/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4998 - acc: 0.4771 - val_loss: 1.5325 - val_acc: 0.4595\n",
            "Epoch 139/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4982 - acc: 0.4781 - val_loss: 1.5308 - val_acc: 0.4575\n",
            "Epoch 140/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4965 - acc: 0.4793 - val_loss: 1.5268 - val_acc: 0.4609\n",
            "Epoch 141/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.4948 - acc: 0.4789 - val_loss: 1.5258 - val_acc: 0.4616\n",
            "Epoch 142/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4933 - acc: 0.4805 - val_loss: 1.5243 - val_acc: 0.4623\n",
            "Epoch 143/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4919 - acc: 0.4803 - val_loss: 1.5251 - val_acc: 0.4618\n",
            "Epoch 144/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4902 - acc: 0.4814 - val_loss: 1.5203 - val_acc: 0.4618\n",
            "Epoch 145/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4885 - acc: 0.4821 - val_loss: 1.5235 - val_acc: 0.4664\n",
            "Epoch 146/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4872 - acc: 0.4813 - val_loss: 1.5202 - val_acc: 0.4633\n",
            "Epoch 147/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4856 - acc: 0.4822 - val_loss: 1.5209 - val_acc: 0.4651\n",
            "Epoch 148/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4838 - acc: 0.4835 - val_loss: 1.5197 - val_acc: 0.4626\n",
            "Epoch 149/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4823 - acc: 0.4846 - val_loss: 1.5146 - val_acc: 0.4661\n",
            "Epoch 150/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.4810 - acc: 0.4834 - val_loss: 1.5140 - val_acc: 0.4629\n",
            "Epoch 151/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.4791 - acc: 0.4844 - val_loss: 1.5146 - val_acc: 0.4652\n",
            "Epoch 152/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4775 - acc: 0.4858 - val_loss: 1.5138 - val_acc: 0.4641\n",
            "Epoch 153/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.4762 - acc: 0.4856 - val_loss: 1.5127 - val_acc: 0.4642\n",
            "Epoch 154/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.4748 - acc: 0.4859 - val_loss: 1.5124 - val_acc: 0.4674\n",
            "Epoch 155/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4731 - acc: 0.4866 - val_loss: 1.5124 - val_acc: 0.4661\n",
            "Epoch 156/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4712 - acc: 0.4868 - val_loss: 1.5084 - val_acc: 0.4651\n",
            "Epoch 157/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4699 - acc: 0.4875 - val_loss: 1.5078 - val_acc: 0.4653\n",
            "Epoch 158/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4685 - acc: 0.4888 - val_loss: 1.5065 - val_acc: 0.4683\n",
            "Epoch 159/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4667 - acc: 0.4882 - val_loss: 1.5152 - val_acc: 0.4625\n",
            "Epoch 160/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4656 - acc: 0.4894 - val_loss: 1.5031 - val_acc: 0.4678\n",
            "Epoch 161/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4634 - acc: 0.4900 - val_loss: 1.5035 - val_acc: 0.4682\n",
            "Epoch 162/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4622 - acc: 0.4902 - val_loss: 1.5025 - val_acc: 0.4707\n",
            "Epoch 163/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4608 - acc: 0.4910 - val_loss: 1.5001 - val_acc: 0.4673\n",
            "Epoch 164/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4594 - acc: 0.4906 - val_loss: 1.5003 - val_acc: 0.4711\n",
            "Epoch 165/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4577 - acc: 0.4915 - val_loss: 1.4972 - val_acc: 0.4692\n",
            "Epoch 166/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4561 - acc: 0.4911 - val_loss: 1.4988 - val_acc: 0.4679\n",
            "Epoch 167/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4547 - acc: 0.4918 - val_loss: 1.5043 - val_acc: 0.4653\n",
            "Epoch 168/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4534 - acc: 0.4941 - val_loss: 1.4975 - val_acc: 0.4698\n",
            "Epoch 169/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4515 - acc: 0.4931 - val_loss: 1.5005 - val_acc: 0.4695\n",
            "Epoch 170/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4503 - acc: 0.4937 - val_loss: 1.4929 - val_acc: 0.4717\n",
            "Epoch 171/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4485 - acc: 0.4953 - val_loss: 1.4913 - val_acc: 0.4694\n",
            "Epoch 172/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4470 - acc: 0.4946 - val_loss: 1.4923 - val_acc: 0.4754\n",
            "Epoch 173/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4456 - acc: 0.4958 - val_loss: 1.4879 - val_acc: 0.4719\n",
            "Epoch 174/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4445 - acc: 0.4958 - val_loss: 1.4921 - val_acc: 0.4736\n",
            "Epoch 175/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.4429 - acc: 0.4967 - val_loss: 1.4869 - val_acc: 0.4717\n",
            "Epoch 176/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4412 - acc: 0.4966 - val_loss: 1.4876 - val_acc: 0.4723\n",
            "Epoch 177/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4397 - acc: 0.4971 - val_loss: 1.4932 - val_acc: 0.4725\n",
            "Epoch 178/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4382 - acc: 0.4985 - val_loss: 1.4867 - val_acc: 0.4706\n",
            "Epoch 179/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.4367 - acc: 0.4981 - val_loss: 1.4825 - val_acc: 0.4726\n",
            "Epoch 180/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4351 - acc: 0.4993 - val_loss: 1.4820 - val_acc: 0.4749\n",
            "Epoch 181/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.4336 - acc: 0.4995 - val_loss: 1.4813 - val_acc: 0.4727\n",
            "Epoch 182/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4320 - acc: 0.5003 - val_loss: 1.4840 - val_acc: 0.4721\n",
            "Epoch 183/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4311 - acc: 0.5001 - val_loss: 1.4813 - val_acc: 0.4738\n",
            "Epoch 184/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4296 - acc: 0.5021 - val_loss: 1.4790 - val_acc: 0.4784\n",
            "Epoch 185/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.4282 - acc: 0.4998 - val_loss: 1.4833 - val_acc: 0.4723\n",
            "Epoch 186/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4268 - acc: 0.5029 - val_loss: 1.4878 - val_acc: 0.4705\n",
            "Epoch 187/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4252 - acc: 0.5015 - val_loss: 1.4806 - val_acc: 0.4747\n",
            "Epoch 188/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.4235 - acc: 0.5035 - val_loss: 1.4727 - val_acc: 0.4794\n",
            "Epoch 189/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4218 - acc: 0.5025 - val_loss: 1.4744 - val_acc: 0.4796\n",
            "Epoch 190/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4207 - acc: 0.5044 - val_loss: 1.4766 - val_acc: 0.4794\n",
            "Epoch 191/500\n",
            "50000/50000 [==============================] - 14s 277us/step - loss: 1.4192 - acc: 0.5041 - val_loss: 1.4888 - val_acc: 0.4724\n",
            "Epoch 192/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.4183 - acc: 0.5051 - val_loss: 1.4739 - val_acc: 0.4796\n",
            "Epoch 193/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4169 - acc: 0.5062 - val_loss: 1.4714 - val_acc: 0.4764\n",
            "Epoch 194/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4152 - acc: 0.5047 - val_loss: 1.4722 - val_acc: 0.4769\n",
            "Epoch 195/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4141 - acc: 0.5060 - val_loss: 1.4725 - val_acc: 0.4801\n",
            "Epoch 196/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4122 - acc: 0.5076 - val_loss: 1.4667 - val_acc: 0.4823\n",
            "Epoch 197/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4109 - acc: 0.5078 - val_loss: 1.4696 - val_acc: 0.4796\n",
            "Epoch 198/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.4090 - acc: 0.5077 - val_loss: 1.4676 - val_acc: 0.4844\n",
            "Epoch 199/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4076 - acc: 0.5086 - val_loss: 1.4699 - val_acc: 0.4799\n",
            "Epoch 200/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.4067 - acc: 0.5082 - val_loss: 1.4636 - val_acc: 0.4799\n",
            "Epoch 201/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.4048 - acc: 0.5092 - val_loss: 1.4651 - val_acc: 0.4794\n",
            "Epoch 202/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.4037 - acc: 0.5096 - val_loss: 1.4697 - val_acc: 0.4809\n",
            "Epoch 203/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.4026 - acc: 0.5096 - val_loss: 1.4619 - val_acc: 0.4783\n",
            "Epoch 204/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.4008 - acc: 0.5103 - val_loss: 1.4655 - val_acc: 0.4812\n",
            "Epoch 205/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3995 - acc: 0.5103 - val_loss: 1.4630 - val_acc: 0.4820\n",
            "Epoch 206/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3982 - acc: 0.5124 - val_loss: 1.4721 - val_acc: 0.4769\n",
            "Epoch 207/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.3965 - acc: 0.5119 - val_loss: 1.4635 - val_acc: 0.4824\n",
            "Epoch 208/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.3951 - acc: 0.5127 - val_loss: 1.4610 - val_acc: 0.4831\n",
            "Epoch 209/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3941 - acc: 0.5124 - val_loss: 1.4565 - val_acc: 0.4839\n",
            "Epoch 210/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.3925 - acc: 0.5138 - val_loss: 1.4543 - val_acc: 0.4858\n",
            "Epoch 211/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3907 - acc: 0.5137 - val_loss: 1.4568 - val_acc: 0.4832\n",
            "Epoch 212/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3897 - acc: 0.5149 - val_loss: 1.4554 - val_acc: 0.4837\n",
            "Epoch 213/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3882 - acc: 0.5155 - val_loss: 1.4502 - val_acc: 0.4866\n",
            "Epoch 214/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3870 - acc: 0.5157 - val_loss: 1.4512 - val_acc: 0.4852\n",
            "Epoch 215/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3853 - acc: 0.5153 - val_loss: 1.4570 - val_acc: 0.4809\n",
            "Epoch 216/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3840 - acc: 0.5157 - val_loss: 1.4630 - val_acc: 0.4812\n",
            "Epoch 217/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3825 - acc: 0.5170 - val_loss: 1.4607 - val_acc: 0.4799\n",
            "Epoch 218/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3817 - acc: 0.5167 - val_loss: 1.4489 - val_acc: 0.4864\n",
            "Epoch 219/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3804 - acc: 0.5166 - val_loss: 1.4457 - val_acc: 0.4881\n",
            "Epoch 220/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3786 - acc: 0.5169 - val_loss: 1.4470 - val_acc: 0.4868\n",
            "Epoch 221/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3780 - acc: 0.5171 - val_loss: 1.4443 - val_acc: 0.4903\n",
            "Epoch 222/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3765 - acc: 0.5186 - val_loss: 1.4437 - val_acc: 0.4889\n",
            "Epoch 223/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3746 - acc: 0.5181 - val_loss: 1.4568 - val_acc: 0.4807\n",
            "Epoch 224/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3731 - acc: 0.5201 - val_loss: 1.4432 - val_acc: 0.4876\n",
            "Epoch 225/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3723 - acc: 0.5187 - val_loss: 1.4517 - val_acc: 0.4844\n",
            "Epoch 226/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3707 - acc: 0.5211 - val_loss: 1.4413 - val_acc: 0.4872\n",
            "Epoch 227/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3693 - acc: 0.5195 - val_loss: 1.4391 - val_acc: 0.4847\n",
            "Epoch 228/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3683 - acc: 0.5214 - val_loss: 1.4404 - val_acc: 0.4889\n",
            "Epoch 229/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3667 - acc: 0.5206 - val_loss: 1.4479 - val_acc: 0.4831\n",
            "Epoch 230/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3650 - acc: 0.5225 - val_loss: 1.4499 - val_acc: 0.4870\n",
            "Epoch 231/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3641 - acc: 0.5233 - val_loss: 1.4367 - val_acc: 0.4923\n",
            "Epoch 232/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3633 - acc: 0.5230 - val_loss: 1.4333 - val_acc: 0.4928\n",
            "Epoch 233/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3612 - acc: 0.5245 - val_loss: 1.4395 - val_acc: 0.4873\n",
            "Epoch 234/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3600 - acc: 0.5236 - val_loss: 1.4323 - val_acc: 0.4903\n",
            "Epoch 235/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3589 - acc: 0.5241 - val_loss: 1.4414 - val_acc: 0.4904\n",
            "Epoch 236/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3575 - acc: 0.5248 - val_loss: 1.4410 - val_acc: 0.4895\n",
            "Epoch 237/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3562 - acc: 0.5261 - val_loss: 1.4334 - val_acc: 0.4895\n",
            "Epoch 238/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3549 - acc: 0.5256 - val_loss: 1.4436 - val_acc: 0.4905\n",
            "Epoch 239/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3538 - acc: 0.5265 - val_loss: 1.4406 - val_acc: 0.4888\n",
            "Epoch 240/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3522 - acc: 0.5270 - val_loss: 1.4339 - val_acc: 0.4925\n",
            "Epoch 241/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3511 - acc: 0.5265 - val_loss: 1.4310 - val_acc: 0.4942\n",
            "Epoch 242/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3494 - acc: 0.5278 - val_loss: 1.4313 - val_acc: 0.4955\n",
            "Epoch 243/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3480 - acc: 0.5282 - val_loss: 1.4271 - val_acc: 0.4965\n",
            "Epoch 244/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3470 - acc: 0.5289 - val_loss: 1.4318 - val_acc: 0.4911\n",
            "Epoch 245/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3457 - acc: 0.5294 - val_loss: 1.4316 - val_acc: 0.4937\n",
            "Epoch 246/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3441 - acc: 0.5284 - val_loss: 1.4282 - val_acc: 0.4914\n",
            "Epoch 247/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3429 - acc: 0.5301 - val_loss: 1.4379 - val_acc: 0.4919\n",
            "Epoch 248/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3424 - acc: 0.5300 - val_loss: 1.4272 - val_acc: 0.4913\n",
            "Epoch 249/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3405 - acc: 0.5315 - val_loss: 1.4230 - val_acc: 0.4929\n",
            "Epoch 250/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3398 - acc: 0.5317 - val_loss: 1.4270 - val_acc: 0.4932\n",
            "Epoch 251/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3380 - acc: 0.5306 - val_loss: 1.4274 - val_acc: 0.4921\n",
            "Epoch 252/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3369 - acc: 0.5321 - val_loss: 1.4234 - val_acc: 0.4964\n",
            "Epoch 253/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3354 - acc: 0.5316 - val_loss: 1.4254 - val_acc: 0.4932\n",
            "Epoch 254/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3336 - acc: 0.5335 - val_loss: 1.4360 - val_acc: 0.4938\n",
            "Epoch 255/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3328 - acc: 0.5331 - val_loss: 1.4174 - val_acc: 0.4978\n",
            "Epoch 256/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3325 - acc: 0.5337 - val_loss: 1.4213 - val_acc: 0.4973\n",
            "Epoch 257/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.3304 - acc: 0.5347 - val_loss: 1.4250 - val_acc: 0.4932\n",
            "Epoch 258/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3290 - acc: 0.5358 - val_loss: 1.4186 - val_acc: 0.4950\n",
            "Epoch 259/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3278 - acc: 0.5350 - val_loss: 1.4168 - val_acc: 0.4988\n",
            "Epoch 260/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3270 - acc: 0.5365 - val_loss: 1.4144 - val_acc: 0.4961\n",
            "Epoch 261/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.3257 - acc: 0.5369 - val_loss: 1.4166 - val_acc: 0.4949\n",
            "Epoch 262/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3244 - acc: 0.5376 - val_loss: 1.4164 - val_acc: 0.4951\n",
            "Epoch 263/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3232 - acc: 0.5365 - val_loss: 1.4147 - val_acc: 0.4969\n",
            "Epoch 264/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3216 - acc: 0.5375 - val_loss: 1.4155 - val_acc: 0.4950\n",
            "Epoch 265/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3207 - acc: 0.5377 - val_loss: 1.4149 - val_acc: 0.4993\n",
            "Epoch 266/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3191 - acc: 0.5389 - val_loss: 1.4117 - val_acc: 0.4987\n",
            "Epoch 267/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3180 - acc: 0.5379 - val_loss: 1.4102 - val_acc: 0.4988\n",
            "Epoch 268/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3171 - acc: 0.5398 - val_loss: 1.4095 - val_acc: 0.4991\n",
            "Epoch 269/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3159 - acc: 0.5381 - val_loss: 1.4133 - val_acc: 0.4994\n",
            "Epoch 270/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3144 - acc: 0.5409 - val_loss: 1.4188 - val_acc: 0.4942\n",
            "Epoch 271/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3133 - acc: 0.5413 - val_loss: 1.4290 - val_acc: 0.4926\n",
            "Epoch 272/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.3114 - acc: 0.5407 - val_loss: 1.4073 - val_acc: 0.5004\n",
            "Epoch 273/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.3107 - acc: 0.5421 - val_loss: 1.4138 - val_acc: 0.4975\n",
            "Epoch 274/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.3091 - acc: 0.5423 - val_loss: 1.4133 - val_acc: 0.4978\n",
            "Epoch 275/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3083 - acc: 0.5420 - val_loss: 1.4199 - val_acc: 0.4929\n",
            "Epoch 276/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.3070 - acc: 0.5434 - val_loss: 1.4111 - val_acc: 0.4992\n",
            "Epoch 277/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.3055 - acc: 0.5433 - val_loss: 1.4165 - val_acc: 0.4968\n",
            "Epoch 278/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3048 - acc: 0.5450 - val_loss: 1.4048 - val_acc: 0.4991\n",
            "Epoch 279/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.3036 - acc: 0.5442 - val_loss: 1.4020 - val_acc: 0.5019\n",
            "Epoch 280/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.3021 - acc: 0.5449 - val_loss: 1.4243 - val_acc: 0.4933\n",
            "Epoch 281/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.3013 - acc: 0.5452 - val_loss: 1.4142 - val_acc: 0.4979\n",
            "Epoch 282/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2995 - acc: 0.5457 - val_loss: 1.4142 - val_acc: 0.4995\n",
            "Epoch 283/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2989 - acc: 0.5458 - val_loss: 1.4191 - val_acc: 0.4946\n",
            "Epoch 284/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2975 - acc: 0.5469 - val_loss: 1.4027 - val_acc: 0.5023\n",
            "Epoch 285/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2960 - acc: 0.5477 - val_loss: 1.4062 - val_acc: 0.5014\n",
            "Epoch 286/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2954 - acc: 0.5471 - val_loss: 1.4031 - val_acc: 0.5029\n",
            "Epoch 287/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2930 - acc: 0.5460 - val_loss: 1.4027 - val_acc: 0.4999\n",
            "Epoch 288/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2928 - acc: 0.5473 - val_loss: 1.4057 - val_acc: 0.5021\n",
            "Epoch 289/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2915 - acc: 0.5488 - val_loss: 1.3972 - val_acc: 0.5034\n",
            "Epoch 290/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2900 - acc: 0.5490 - val_loss: 1.3951 - val_acc: 0.5025\n",
            "Epoch 291/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2890 - acc: 0.5493 - val_loss: 1.3950 - val_acc: 0.5053\n",
            "Epoch 292/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.2884 - acc: 0.5502 - val_loss: 1.4017 - val_acc: 0.4992\n",
            "Epoch 293/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2868 - acc: 0.5504 - val_loss: 1.3947 - val_acc: 0.5061\n",
            "Epoch 294/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2861 - acc: 0.5504 - val_loss: 1.3985 - val_acc: 0.5017\n",
            "Epoch 295/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2844 - acc: 0.5511 - val_loss: 1.3919 - val_acc: 0.5079\n",
            "Epoch 296/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2835 - acc: 0.5512 - val_loss: 1.3986 - val_acc: 0.5053\n",
            "Epoch 297/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2824 - acc: 0.5518 - val_loss: 1.3924 - val_acc: 0.5069\n",
            "Epoch 298/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2809 - acc: 0.5518 - val_loss: 1.4040 - val_acc: 0.5034\n",
            "Epoch 299/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2797 - acc: 0.5528 - val_loss: 1.3998 - val_acc: 0.5018\n",
            "Epoch 300/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2784 - acc: 0.5537 - val_loss: 1.4204 - val_acc: 0.4981\n",
            "Epoch 301/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2775 - acc: 0.5541 - val_loss: 1.3966 - val_acc: 0.5031\n",
            "Epoch 302/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2762 - acc: 0.5549 - val_loss: 1.3909 - val_acc: 0.5065\n",
            "Epoch 303/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2747 - acc: 0.5540 - val_loss: 1.3897 - val_acc: 0.5078\n",
            "Epoch 304/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2745 - acc: 0.5556 - val_loss: 1.4094 - val_acc: 0.5010\n",
            "Epoch 305/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2733 - acc: 0.5542 - val_loss: 1.3851 - val_acc: 0.5071\n",
            "Epoch 306/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2725 - acc: 0.5558 - val_loss: 1.4057 - val_acc: 0.5020\n",
            "Epoch 307/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2714 - acc: 0.5555 - val_loss: 1.3943 - val_acc: 0.5068\n",
            "Epoch 308/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2701 - acc: 0.5567 - val_loss: 1.3942 - val_acc: 0.5024\n",
            "Epoch 309/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.2675 - acc: 0.5573 - val_loss: 1.3953 - val_acc: 0.5016\n",
            "Epoch 310/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2673 - acc: 0.5576 - val_loss: 1.3875 - val_acc: 0.5072\n",
            "Epoch 311/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2659 - acc: 0.5585 - val_loss: 1.3987 - val_acc: 0.5040\n",
            "Epoch 312/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.2641 - acc: 0.5588 - val_loss: 1.3889 - val_acc: 0.5046\n",
            "Epoch 313/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2631 - acc: 0.5588 - val_loss: 1.3824 - val_acc: 0.5083\n",
            "Epoch 314/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2623 - acc: 0.5597 - val_loss: 1.4196 - val_acc: 0.4956\n",
            "Epoch 315/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.2613 - acc: 0.5593 - val_loss: 1.3906 - val_acc: 0.5066\n",
            "Epoch 316/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2604 - acc: 0.5600 - val_loss: 1.3943 - val_acc: 0.5024\n",
            "Epoch 317/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2592 - acc: 0.5598 - val_loss: 1.4104 - val_acc: 0.4976\n",
            "Epoch 318/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2579 - acc: 0.5608 - val_loss: 1.3906 - val_acc: 0.5033\n",
            "Epoch 319/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2572 - acc: 0.5601 - val_loss: 1.3879 - val_acc: 0.5097\n",
            "Epoch 320/500\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 1.2560 - acc: 0.5621 - val_loss: 1.3938 - val_acc: 0.5022\n",
            "Epoch 321/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2543 - acc: 0.5615 - val_loss: 1.3845 - val_acc: 0.5039\n",
            "Epoch 322/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2540 - acc: 0.5614 - val_loss: 1.3845 - val_acc: 0.5056\n",
            "Epoch 323/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2522 - acc: 0.5620 - val_loss: 1.3878 - val_acc: 0.5097\n",
            "Epoch 324/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2512 - acc: 0.5627 - val_loss: 1.3807 - val_acc: 0.5087\n",
            "Epoch 325/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2503 - acc: 0.5644 - val_loss: 1.3918 - val_acc: 0.5047\n",
            "Epoch 326/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2488 - acc: 0.5636 - val_loss: 1.3866 - val_acc: 0.5051\n",
            "Epoch 327/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2473 - acc: 0.5648 - val_loss: 1.3995 - val_acc: 0.5007\n",
            "Epoch 328/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2462 - acc: 0.5665 - val_loss: 1.3952 - val_acc: 0.5034\n",
            "Epoch 329/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2454 - acc: 0.5646 - val_loss: 1.3768 - val_acc: 0.5107\n",
            "Epoch 330/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2448 - acc: 0.5645 - val_loss: 1.3814 - val_acc: 0.5110\n",
            "Epoch 331/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2433 - acc: 0.5654 - val_loss: 1.3905 - val_acc: 0.5063\n",
            "Epoch 332/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2419 - acc: 0.5671 - val_loss: 1.3938 - val_acc: 0.5034\n",
            "Epoch 333/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2412 - acc: 0.5673 - val_loss: 1.3768 - val_acc: 0.5113\n",
            "Epoch 334/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.2405 - acc: 0.5673 - val_loss: 1.3781 - val_acc: 0.5111\n",
            "Epoch 335/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.2398 - acc: 0.5665 - val_loss: 1.3824 - val_acc: 0.5115\n",
            "Epoch 336/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2380 - acc: 0.5688 - val_loss: 1.3882 - val_acc: 0.5096\n",
            "Epoch 337/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2364 - acc: 0.5695 - val_loss: 1.3951 - val_acc: 0.5056\n",
            "Epoch 338/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2363 - acc: 0.5676 - val_loss: 1.4025 - val_acc: 0.5029\n",
            "Epoch 339/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2347 - acc: 0.5689 - val_loss: 1.3796 - val_acc: 0.5093\n",
            "Epoch 340/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.2339 - acc: 0.5695 - val_loss: 1.4191 - val_acc: 0.4994\n",
            "Epoch 341/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2322 - acc: 0.5688 - val_loss: 1.3821 - val_acc: 0.5088\n",
            "Epoch 342/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2317 - acc: 0.5709 - val_loss: 1.3799 - val_acc: 0.5054\n",
            "Epoch 343/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.2298 - acc: 0.5698 - val_loss: 1.3953 - val_acc: 0.5051\n",
            "Epoch 344/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2296 - acc: 0.5708 - val_loss: 1.3944 - val_acc: 0.5077\n",
            "Epoch 345/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2286 - acc: 0.5717 - val_loss: 1.3794 - val_acc: 0.5095\n",
            "Epoch 346/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2261 - acc: 0.5716 - val_loss: 1.3767 - val_acc: 0.5106\n",
            "Epoch 347/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2256 - acc: 0.5711 - val_loss: 1.3714 - val_acc: 0.5140\n",
            "Epoch 348/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2246 - acc: 0.5731 - val_loss: 1.4200 - val_acc: 0.4978\n",
            "Epoch 349/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2246 - acc: 0.5731 - val_loss: 1.3683 - val_acc: 0.5105\n",
            "Epoch 350/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.2223 - acc: 0.5750 - val_loss: 1.3713 - val_acc: 0.5120\n",
            "Epoch 351/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.2215 - acc: 0.5743 - val_loss: 1.3706 - val_acc: 0.5141\n",
            "Epoch 352/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2206 - acc: 0.5735 - val_loss: 1.4146 - val_acc: 0.5049\n",
            "Epoch 353/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.2186 - acc: 0.5755 - val_loss: 1.3777 - val_acc: 0.5087\n",
            "Epoch 354/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2180 - acc: 0.5754 - val_loss: 1.3721 - val_acc: 0.5116\n",
            "Epoch 355/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.2167 - acc: 0.5752 - val_loss: 1.3635 - val_acc: 0.5151\n",
            "Epoch 356/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2156 - acc: 0.5764 - val_loss: 1.3661 - val_acc: 0.5135\n",
            "Epoch 357/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.2150 - acc: 0.5763 - val_loss: 1.3864 - val_acc: 0.5111\n",
            "Epoch 358/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.2137 - acc: 0.5766 - val_loss: 1.3736 - val_acc: 0.5102\n",
            "Epoch 359/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.2133 - acc: 0.5764 - val_loss: 1.3745 - val_acc: 0.5069\n",
            "Epoch 360/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.2112 - acc: 0.5767 - val_loss: 1.3671 - val_acc: 0.5123\n",
            "Epoch 361/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2104 - acc: 0.5776 - val_loss: 1.3821 - val_acc: 0.5088\n",
            "Epoch 362/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.2094 - acc: 0.5783 - val_loss: 1.3886 - val_acc: 0.5055\n",
            "Epoch 363/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2093 - acc: 0.5787 - val_loss: 1.3730 - val_acc: 0.5097\n",
            "Epoch 364/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.2077 - acc: 0.5799 - val_loss: 1.3607 - val_acc: 0.5158\n",
            "Epoch 365/500\n",
            "50000/50000 [==============================] - 11s 211us/step - loss: 1.2067 - acc: 0.5792 - val_loss: 1.3982 - val_acc: 0.5013\n",
            "Epoch 366/500\n",
            "50000/50000 [==============================] - 10s 207us/step - loss: 1.2057 - acc: 0.5804 - val_loss: 1.3753 - val_acc: 0.5108\n",
            "Epoch 367/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.2053 - acc: 0.5798 - val_loss: 1.3659 - val_acc: 0.5159\n",
            "Epoch 368/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2032 - acc: 0.5800 - val_loss: 1.3776 - val_acc: 0.5093\n",
            "Epoch 369/500\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.2025 - acc: 0.5802 - val_loss: 1.3723 - val_acc: 0.5128\n",
            "Epoch 370/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.2020 - acc: 0.5807 - val_loss: 1.3590 - val_acc: 0.5176\n",
            "Epoch 371/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.2000 - acc: 0.5801 - val_loss: 1.3846 - val_acc: 0.5020\n",
            "Epoch 372/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1993 - acc: 0.5830 - val_loss: 1.3643 - val_acc: 0.5177\n",
            "Epoch 373/500\n",
            "50000/50000 [==============================] - 11s 213us/step - loss: 1.1979 - acc: 0.5821 - val_loss: 1.3714 - val_acc: 0.5105\n",
            "Epoch 374/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.1974 - acc: 0.5829 - val_loss: 1.3742 - val_acc: 0.5090\n",
            "Epoch 375/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.1963 - acc: 0.5831 - val_loss: 1.3546 - val_acc: 0.5190\n",
            "Epoch 376/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1948 - acc: 0.5820 - val_loss: 1.3626 - val_acc: 0.5137\n",
            "Epoch 377/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1934 - acc: 0.5835 - val_loss: 1.3692 - val_acc: 0.5141\n",
            "Epoch 378/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.1930 - acc: 0.5832 - val_loss: 1.3795 - val_acc: 0.5109\n",
            "Epoch 379/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.1918 - acc: 0.5837 - val_loss: 1.4100 - val_acc: 0.5001\n",
            "Epoch 380/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.1912 - acc: 0.5849 - val_loss: 1.3611 - val_acc: 0.5155\n",
            "Epoch 381/500\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.1890 - acc: 0.5861 - val_loss: 1.3652 - val_acc: 0.5107\n",
            "Epoch 382/500\n",
            "50000/50000 [==============================] - 11s 215us/step - loss: 1.1894 - acc: 0.5849 - val_loss: 1.3695 - val_acc: 0.5103\n",
            "Epoch 383/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1876 - acc: 0.5861 - val_loss: 1.3932 - val_acc: 0.5048\n",
            "Epoch 384/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1864 - acc: 0.5864 - val_loss: 1.3672 - val_acc: 0.5152\n",
            "Epoch 385/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1850 - acc: 0.5870 - val_loss: 1.3584 - val_acc: 0.5165\n",
            "Epoch 386/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1846 - acc: 0.5866 - val_loss: 1.3597 - val_acc: 0.5168\n",
            "Epoch 387/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1838 - acc: 0.5882 - val_loss: 1.3605 - val_acc: 0.5152\n",
            "Epoch 388/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1812 - acc: 0.5886 - val_loss: 1.3767 - val_acc: 0.5095\n",
            "Epoch 389/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1816 - acc: 0.5886 - val_loss: 1.3616 - val_acc: 0.5139\n",
            "Epoch 390/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1792 - acc: 0.5886 - val_loss: 1.3665 - val_acc: 0.5169\n",
            "Epoch 391/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1802 - acc: 0.5883 - val_loss: 1.3884 - val_acc: 0.5062\n",
            "Epoch 392/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.1779 - acc: 0.5884 - val_loss: 1.3520 - val_acc: 0.5235\n",
            "Epoch 393/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1772 - acc: 0.5904 - val_loss: 1.3697 - val_acc: 0.5133\n",
            "Epoch 394/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1767 - acc: 0.5902 - val_loss: 1.3538 - val_acc: 0.5180\n",
            "Epoch 395/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1760 - acc: 0.5903 - val_loss: 1.3600 - val_acc: 0.5151\n",
            "Epoch 396/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1736 - acc: 0.5905 - val_loss: 1.3513 - val_acc: 0.5191\n",
            "Epoch 397/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1733 - acc: 0.5906 - val_loss: 1.3897 - val_acc: 0.5084\n",
            "Epoch 398/500\n",
            "50000/50000 [==============================] - 11s 212us/step - loss: 1.1727 - acc: 0.5910 - val_loss: 1.3803 - val_acc: 0.5113\n",
            "Epoch 399/500\n",
            "50000/50000 [==============================] - 11s 214us/step - loss: 1.1711 - acc: 0.5912 - val_loss: 1.3508 - val_acc: 0.5190\n",
            "Epoch 400/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1699 - acc: 0.5924 - val_loss: 1.3513 - val_acc: 0.5189\n",
            "Epoch 401/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1688 - acc: 0.5928 - val_loss: 1.3802 - val_acc: 0.5085\n",
            "Epoch 402/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1678 - acc: 0.5922 - val_loss: 1.3845 - val_acc: 0.5091\n",
            "Epoch 403/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1677 - acc: 0.5954 - val_loss: 1.3658 - val_acc: 0.5136\n",
            "Epoch 404/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1658 - acc: 0.5938 - val_loss: 1.3717 - val_acc: 0.5127\n",
            "Epoch 405/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1649 - acc: 0.5941 - val_loss: 1.3647 - val_acc: 0.5158\n",
            "Epoch 406/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1640 - acc: 0.5943 - val_loss: 1.3536 - val_acc: 0.5150\n",
            "Epoch 407/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1627 - acc: 0.5954 - val_loss: 1.3612 - val_acc: 0.5177\n",
            "Epoch 408/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1626 - acc: 0.5942 - val_loss: 1.3789 - val_acc: 0.5112\n",
            "Epoch 409/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1611 - acc: 0.5955 - val_loss: 1.3543 - val_acc: 0.5186\n",
            "Epoch 410/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1604 - acc: 0.5956 - val_loss: 1.3528 - val_acc: 0.5169\n",
            "Epoch 411/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1589 - acc: 0.5963 - val_loss: 1.3528 - val_acc: 0.5177\n",
            "Epoch 412/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1581 - acc: 0.5962 - val_loss: 1.3777 - val_acc: 0.5077\n",
            "Epoch 413/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1578 - acc: 0.5957 - val_loss: 1.3497 - val_acc: 0.5215\n",
            "Epoch 414/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1548 - acc: 0.5975 - val_loss: 1.3547 - val_acc: 0.5168\n",
            "Epoch 415/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1539 - acc: 0.5978 - val_loss: 1.3480 - val_acc: 0.5156\n",
            "Epoch 416/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1533 - acc: 0.5976 - val_loss: 1.3859 - val_acc: 0.5065\n",
            "Epoch 417/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1539 - acc: 0.5982 - val_loss: 1.3542 - val_acc: 0.5213\n",
            "Epoch 418/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1516 - acc: 0.5997 - val_loss: 1.3575 - val_acc: 0.5205\n",
            "Epoch 419/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1516 - acc: 0.5984 - val_loss: 1.4001 - val_acc: 0.5022\n",
            "Epoch 420/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1490 - acc: 0.5995 - val_loss: 1.3579 - val_acc: 0.5183\n",
            "Epoch 421/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1471 - acc: 0.6009 - val_loss: 1.3482 - val_acc: 0.5208\n",
            "Epoch 422/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1489 - acc: 0.5975 - val_loss: 1.3543 - val_acc: 0.5173\n",
            "Epoch 423/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1460 - acc: 0.5990 - val_loss: 1.3479 - val_acc: 0.5198\n",
            "Epoch 424/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1454 - acc: 0.6016 - val_loss: 1.3624 - val_acc: 0.5126\n",
            "Epoch 425/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1453 - acc: 0.6018 - val_loss: 1.3438 - val_acc: 0.5224\n",
            "Epoch 426/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1439 - acc: 0.6019 - val_loss: 1.3494 - val_acc: 0.5207\n",
            "Epoch 427/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1423 - acc: 0.6006 - val_loss: 1.3748 - val_acc: 0.5121\n",
            "Epoch 428/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1416 - acc: 0.6016 - val_loss: 1.3720 - val_acc: 0.5101\n",
            "Epoch 429/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1424 - acc: 0.6007 - val_loss: 1.3516 - val_acc: 0.5209\n",
            "Epoch 430/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1390 - acc: 0.6037 - val_loss: 1.3513 - val_acc: 0.5192\n",
            "Epoch 431/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1383 - acc: 0.6014 - val_loss: 1.3441 - val_acc: 0.5177\n",
            "Epoch 432/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1370 - acc: 0.6036 - val_loss: 1.3422 - val_acc: 0.5211\n",
            "Epoch 433/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1357 - acc: 0.6046 - val_loss: 1.3533 - val_acc: 0.5187\n",
            "Epoch 434/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1364 - acc: 0.6032 - val_loss: 1.3435 - val_acc: 0.5215\n",
            "Epoch 435/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1348 - acc: 0.6035 - val_loss: 1.3541 - val_acc: 0.5166\n",
            "Epoch 436/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1338 - acc: 0.6034 - val_loss: 1.3519 - val_acc: 0.5177\n",
            "Epoch 437/500\n",
            "50000/50000 [==============================] - 11s 217us/step - loss: 1.1320 - acc: 0.6054 - val_loss: 1.3577 - val_acc: 0.5161\n",
            "Epoch 438/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1309 - acc: 0.6066 - val_loss: 1.3525 - val_acc: 0.5172\n",
            "Epoch 439/500\n",
            "50000/50000 [==============================] - 11s 218us/step - loss: 1.1318 - acc: 0.6055 - val_loss: 1.3638 - val_acc: 0.5176\n",
            "Epoch 440/500\n",
            "50000/50000 [==============================] - 11s 219us/step - loss: 1.1293 - acc: 0.6051 - val_loss: 1.3439 - val_acc: 0.5218\n",
            "Epoch 441/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1279 - acc: 0.6084 - val_loss: 1.3576 - val_acc: 0.5187\n",
            "Epoch 442/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1278 - acc: 0.6069 - val_loss: 1.3920 - val_acc: 0.5117\n",
            "Epoch 443/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1276 - acc: 0.6052 - val_loss: 1.3396 - val_acc: 0.5216\n",
            "Epoch 444/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1243 - acc: 0.6075 - val_loss: 1.3644 - val_acc: 0.5149\n",
            "Epoch 445/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1250 - acc: 0.6079 - val_loss: 1.3910 - val_acc: 0.5086\n",
            "Epoch 446/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1233 - acc: 0.6084 - val_loss: 1.4071 - val_acc: 0.5090\n",
            "Epoch 447/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1225 - acc: 0.6082 - val_loss: 1.3441 - val_acc: 0.5234\n",
            "Epoch 448/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1197 - acc: 0.6088 - val_loss: 1.3487 - val_acc: 0.5151\n",
            "Epoch 449/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1211 - acc: 0.6090 - val_loss: 1.3749 - val_acc: 0.5153\n",
            "Epoch 450/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1189 - acc: 0.6101 - val_loss: 1.3553 - val_acc: 0.5222\n",
            "Epoch 451/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1180 - acc: 0.6106 - val_loss: 1.3455 - val_acc: 0.5198\n",
            "Epoch 452/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1182 - acc: 0.6083 - val_loss: 1.3398 - val_acc: 0.5235\n",
            "Epoch 453/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1165 - acc: 0.6105 - val_loss: 1.3387 - val_acc: 0.5240\n",
            "Epoch 454/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1151 - acc: 0.6110 - val_loss: 1.3718 - val_acc: 0.5134\n",
            "Epoch 455/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1155 - acc: 0.6109 - val_loss: 1.3384 - val_acc: 0.5261\n",
            "Epoch 456/500\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 1.1134 - acc: 0.6115 - val_loss: 1.3384 - val_acc: 0.5214\n",
            "Epoch 457/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.1116 - acc: 0.6123 - val_loss: 1.3610 - val_acc: 0.5148\n",
            "Epoch 458/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1106 - acc: 0.6131 - val_loss: 1.3483 - val_acc: 0.5186\n",
            "Epoch 459/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1107 - acc: 0.6117 - val_loss: 1.3432 - val_acc: 0.5245\n",
            "Epoch 460/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.1090 - acc: 0.6131 - val_loss: 1.3939 - val_acc: 0.5090\n",
            "Epoch 461/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1089 - acc: 0.6132 - val_loss: 1.3486 - val_acc: 0.5196\n",
            "Epoch 462/500\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.1073 - acc: 0.6142 - val_loss: 1.3443 - val_acc: 0.5204\n",
            "Epoch 463/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1058 - acc: 0.6132 - val_loss: 1.3686 - val_acc: 0.5147\n",
            "Epoch 464/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.1060 - acc: 0.6147 - val_loss: 1.3494 - val_acc: 0.5223\n",
            "Epoch 465/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1040 - acc: 0.6145 - val_loss: 1.3472 - val_acc: 0.5229\n",
            "Epoch 466/500\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 1.1033 - acc: 0.6149 - val_loss: 1.3726 - val_acc: 0.5121\n",
            "Epoch 467/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1019 - acc: 0.6155 - val_loss: 1.4016 - val_acc: 0.5091\n",
            "Epoch 468/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.1013 - acc: 0.6158 - val_loss: 1.3397 - val_acc: 0.5235\n",
            "Epoch 469/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.1000 - acc: 0.6166 - val_loss: 1.3449 - val_acc: 0.5193\n",
            "Epoch 470/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0997 - acc: 0.6165 - val_loss: 1.3454 - val_acc: 0.5189\n",
            "Epoch 471/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0987 - acc: 0.6157 - val_loss: 1.3367 - val_acc: 0.5229\n",
            "Epoch 472/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0972 - acc: 0.6164 - val_loss: 1.3430 - val_acc: 0.5222\n",
            "Epoch 473/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0967 - acc: 0.6177 - val_loss: 1.3422 - val_acc: 0.5197\n",
            "Epoch 474/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0962 - acc: 0.6178 - val_loss: 1.3554 - val_acc: 0.5184\n",
            "Epoch 475/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0953 - acc: 0.6179 - val_loss: 1.3401 - val_acc: 0.5244\n",
            "Epoch 476/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0937 - acc: 0.6194 - val_loss: 1.3366 - val_acc: 0.5232\n",
            "Epoch 477/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0917 - acc: 0.6194 - val_loss: 1.3434 - val_acc: 0.5244\n",
            "Epoch 478/500\n",
            "50000/50000 [==============================] - 11s 220us/step - loss: 1.0923 - acc: 0.6191 - val_loss: 1.3512 - val_acc: 0.5181\n",
            "Epoch 479/500\n",
            "50000/50000 [==============================] - 11s 221us/step - loss: 1.0886 - acc: 0.6201 - val_loss: 1.3792 - val_acc: 0.5161\n",
            "Epoch 480/500\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.0902 - acc: 0.6193 - val_loss: 1.4064 - val_acc: 0.5107\n",
            "Epoch 481/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0903 - acc: 0.6195 - val_loss: 1.3493 - val_acc: 0.5226\n",
            "Epoch 482/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0872 - acc: 0.6210 - val_loss: 1.3395 - val_acc: 0.5216\n",
            "Epoch 483/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0873 - acc: 0.6214 - val_loss: 1.4121 - val_acc: 0.5061\n",
            "Epoch 484/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0848 - acc: 0.6221 - val_loss: 1.3608 - val_acc: 0.5203\n",
            "Epoch 485/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0849 - acc: 0.6206 - val_loss: 1.3474 - val_acc: 0.5242\n",
            "Epoch 486/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0840 - acc: 0.6220 - val_loss: 1.3437 - val_acc: 0.5238\n",
            "Epoch 487/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0831 - acc: 0.6226 - val_loss: 1.3404 - val_acc: 0.5229\n",
            "Epoch 488/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0817 - acc: 0.6231 - val_loss: 1.3307 - val_acc: 0.5237\n",
            "Epoch 489/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0815 - acc: 0.6235 - val_loss: 1.3776 - val_acc: 0.5152\n",
            "Epoch 490/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0823 - acc: 0.6222 - val_loss: 1.3455 - val_acc: 0.5198\n",
            "Epoch 491/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0800 - acc: 0.6237 - val_loss: 1.3744 - val_acc: 0.5129\n",
            "Epoch 492/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0797 - acc: 0.6249 - val_loss: 1.3308 - val_acc: 0.5262\n",
            "Epoch 493/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0770 - acc: 0.6251 - val_loss: 1.3550 - val_acc: 0.5209\n",
            "Epoch 494/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0772 - acc: 0.6233 - val_loss: 1.3522 - val_acc: 0.5174\n",
            "Epoch 495/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0746 - acc: 0.6232 - val_loss: 1.3793 - val_acc: 0.5106\n",
            "Epoch 496/500\n",
            "50000/50000 [==============================] - 11s 223us/step - loss: 1.0741 - acc: 0.6239 - val_loss: 1.3600 - val_acc: 0.5180\n",
            "Epoch 497/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0729 - acc: 0.6255 - val_loss: 1.3455 - val_acc: 0.5238\n",
            "Epoch 498/500\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0741 - acc: 0.6249 - val_loss: 1.3448 - val_acc: 0.5225\n",
            "Epoch 499/500\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.0697 - acc: 0.6274 - val_loss: 1.3458 - val_acc: 0.5206\n",
            "Epoch 500/500\n",
            "50000/50000 [==============================] - 11s 222us/step - loss: 1.0717 - acc: 0.6240 - val_loss: 1.3925 - val_acc: 0.5121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff94563d908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCKjErxX5A8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "24b22a13-f20d-4760-86c0-4692e6f4665c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# 以視覺畫方式檢視訓練過程\n",
        "\n",
        "train_loss = model.history.history[\"loss\"]\n",
        "valid_loss = model.history.history[\"val_loss\"]\n",
        "\n",
        "train_acc = model.history.history[\"acc\"]\n",
        "valid_acc = model.history.history[\"val_acc\"]\n",
        "\n",
        "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
        "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}