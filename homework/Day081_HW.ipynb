{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Day081_HW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc8m_HCB3biQ",
        "colab_type": "text"
      },
      "source": [
        "## Work\n",
        "1. 請比較使用 l1, l1_l2 及不同比例下的訓練結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3FKaO413biT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "4f60f582-a3ab-4c67-c0a7-f4dedfb1ad2d"
      },
      "source": [
        "import os\n",
        "import keras\n",
        "\n",
        "# Disable GPU\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0_8Y99v3bih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7ee43301-6364-4d6e-ba8a-c5590616a0d8"
      },
      "source": [
        "train, test = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDVqQFCK3biq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 資料前處理\n",
        "def preproc_x(x, flatten=True):\n",
        "    x = x / 255.\n",
        "    if flatten:\n",
        "        x = x.reshape((len(x), -1))\n",
        "    return x\n",
        "\n",
        "def preproc_y(y, num_classes=10):\n",
        "    if y.shape[-1] == 1:\n",
        "        y = keras.utils.to_categorical(y, num_classes)\n",
        "    return y    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-UvVClS3bi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train = train\n",
        "x_test, y_test = test\n",
        "\n",
        "# Preproc the inputs\n",
        "x_train = preproc_x(x_train)\n",
        "x_test = preproc_x(x_test)\n",
        "\n",
        "# Preprc the outputs\n",
        "y_train = preproc_y(y_train)\n",
        "y_test = preproc_y(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amlKDZrW3bjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l1, l2, l1_l2\n",
        "\n",
        "def build_mlp_l1(input_shape, output_units=10, num_neurons=[512, 256, 128], ratio=1e-4):\n",
        "    \"\"\"Code Here\n",
        "    建立你的神經網路\n",
        "    \"\"\"\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "    for i, n_units in enumerate(num_neurons):\n",
        "      if i== 0:\n",
        "        x = keras.layers.Dense(units=n_units,\n",
        "                               activation='relu',\n",
        "                               name='hidden_layer'+str(i+1),\n",
        "                               kernel_regularizer=l1(ratio))(input_layer)\n",
        "      else:\n",
        "        x = keras.layers.Dense(units=n_units,\n",
        "                               activation='relu',\n",
        "                               name='hidden_layer'+str(i+1),\n",
        "                               kernel_regularizer=l1(ratio))(x)\n",
        "    \n",
        "    out = keras.layers.Dense(units=output_units, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])  \n",
        "\n",
        "    return model\n",
        "\n",
        "def build_mlp_l2(input_shape, output_units=10, num_neurons=[512, 256, 128], ratio=1e-4):\n",
        "    \"\"\"Code Here\n",
        "    建立你的神經網路\n",
        "    \"\"\"\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "    for i, n_units in enumerate(num_neurons):\n",
        "      if i== 0:\n",
        "        x = keras.layers.Dense(units=n_units,\n",
        "                               activation='relu',\n",
        "                               name='hidden_layer'+str(i+1),\n",
        "                               kernel_regularizer=l2(ratio))(input_layer)\n",
        "      else:\n",
        "        x = keras.layers.Dense(units=n_units,\n",
        "                               activation='relu',\n",
        "                               name='hidden_layer'+str(i+1),\n",
        "                               kernel_regularizer=l2(ratio))(x)\n",
        "    \n",
        "    out = keras.layers.Dense(units=output_units, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])  \n",
        "\n",
        "    return model\n",
        "\n",
        "def build_mlp_l1l2(input_shape, output_units=10, num_neurons=[512, 256, 128], ratio=1e-4):\n",
        "    \"\"\"Code Here\n",
        "    建立你的神經網路\n",
        "    \"\"\"\n",
        "    input_layer = keras.layers.Input(input_shape)\n",
        "\n",
        "    for i, n_units in enumerate(num_neurons):\n",
        "      if i== 0:\n",
        "        x = keras.layers.Dense(units=n_units,\n",
        "                               activation='relu',\n",
        "                               name='hidden_layer'+str(i+1),\n",
        "                               kernel_regularizer=l1_l2(ratio))(input_layer)\n",
        "      else:\n",
        "        x = keras.layers.Dense(units=n_units,\n",
        "                               activation='relu',\n",
        "                               name='hidden_layer'+str(i+1),\n",
        "                               kernel_regularizer=l1_l2(ratio))(x)\n",
        "    \n",
        "    out = keras.layers.Dense(units=output_units, activation='softmax', name='output')(x)\n",
        "\n",
        "    model = keras.models.Model(inputs=[input_layer], outputs=[out])  \n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDP5B7KW3bjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Code Here\n",
        "設定超參數\n",
        "\"\"\"\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "MOMENTUM = 0.95\n",
        "EXP = [1e-2, 1e-4, 1e-8, 1e-12]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pSpLvQCD3bjX",
        "colab_type": "code",
        "outputId": "5dafc20b-3fb4-4feb-ad92-24eb24552a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "results = {}\n",
        "\"\"\"Code Here\n",
        "\n",
        "\n",
        "\n",
        "撰寫你的訓練流程並將結果用 dictionary 紀錄\n",
        "\n",
        "\"\"\"\n",
        "for regulizer_ratio in EXP:\n",
        "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
        "    print(\"Experiment with Regulizer = %.6f\" % (regulizer_ratio))\n",
        "    model = build_mlp_l1(input_shape=x_train.shape[1:], ratio=regulizer_ratio)\n",
        "    model.summary()\n",
        "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
        "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "\n",
        "    model.fit(x_train, y_train, \n",
        "              epochs=EPOCHS, \n",
        "              batch_size=BATCH_SIZE, \n",
        "              validation_data=(x_test, y_test), \n",
        "              shuffle=True)\n",
        "    \n",
        "    # Collect results\n",
        "    train_loss = model.history.history[\"loss\"]\n",
        "    valid_loss = model.history.history[\"val_loss\"]\n",
        "    train_acc = model.history.history[\"acc\"]\n",
        "    valid_acc = model.history.history[\"val_acc\"]\n",
        "    \n",
        "    exp_name_tag = \"exp-l1-%s\" % str(regulizer_ratio)\n",
        "    results[exp_name_tag] = {'train-loss': train_loss,\n",
        "                             'valid-loss': valid_loss,\n",
        "                             'train-acc': train_acc,\n",
        "                             'valid-acc': valid_acc}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment with Regulizer = 0.010000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 14s 275us/step - loss: 198.7315 - acc: 0.2493 - val_loss: 41.0647 - val_acc: 0.2733\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 19.0432 - acc: 0.1189 - val_loss: 7.2462 - val_acc: 0.1000\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 4.0997 - acc: 0.1000 - val_loss: 2.6486 - val_acc: 0.1000\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4864 - acc: 0.0992 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0997 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.4626 - acc: 0.0960 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 13s 260us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4624 - val_acc: 0.1000\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 2.4626 - acc: 0.0986 - val_loss: 2.4627 - val_acc: 0.1000\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 2.4626 - acc: 0.0993 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0998 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0966 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 2.4626 - acc: 0.0986 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0985 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.4626 - acc: 0.0961 - val_loss: 2.4627 - val_acc: 0.1000\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 2.4626 - acc: 0.0986 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.4626 - acc: 0.0998 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 2.4626 - acc: 0.0975 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0974 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0959 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0986 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4625 - val_acc: 0.1000\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4626 - acc: 0.0995 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4626 - val_acc: 0.1000\n",
            "Experiment with Regulizer = 0.000100\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 5.9899 - acc: 0.2809 - val_loss: 5.7996 - val_acc: 0.3449\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 5.7079 - acc: 0.3700 - val_loss: 5.6303 - val_acc: 0.3852\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 5.5642 - acc: 0.4008 - val_loss: 5.4979 - val_acc: 0.4164\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 5.4448 - acc: 0.4201 - val_loss: 5.3982 - val_acc: 0.4242\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 5.3372 - acc: 0.4327 - val_loss: 5.2947 - val_acc: 0.4323\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 5.2383 - acc: 0.4461 - val_loss: 5.1974 - val_acc: 0.4479\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 5.1451 - acc: 0.4581 - val_loss: 5.1217 - val_acc: 0.4533\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 5.0550 - acc: 0.4679 - val_loss: 5.0276 - val_acc: 0.4639\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 4.9680 - acc: 0.4763 - val_loss: 4.9654 - val_acc: 0.4647\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 4.8841 - acc: 0.4839 - val_loss: 4.8775 - val_acc: 0.4652\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 4.8033 - acc: 0.4906 - val_loss: 4.8136 - val_acc: 0.4685\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 4.7242 - acc: 0.4999 - val_loss: 4.7223 - val_acc: 0.4828\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 4.6464 - acc: 0.5054 - val_loss: 4.6582 - val_acc: 0.4884\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 4.5706 - acc: 0.5105 - val_loss: 4.5841 - val_acc: 0.4940\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 4.4975 - acc: 0.5166 - val_loss: 4.5224 - val_acc: 0.4982\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 4.4238 - acc: 0.5224 - val_loss: 4.4596 - val_acc: 0.4975\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 4.3540 - acc: 0.5274 - val_loss: 4.4196 - val_acc: 0.4873\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 12s 250us/step - loss: 4.2833 - acc: 0.5330 - val_loss: 4.3427 - val_acc: 0.5000\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 4.2162 - acc: 0.5358 - val_loss: 4.2656 - val_acc: 0.5100\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 4.1508 - acc: 0.5418 - val_loss: 4.2443 - val_acc: 0.4939\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 4.0857 - acc: 0.5443 - val_loss: 4.1750 - val_acc: 0.5026\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 4.0190 - acc: 0.5527 - val_loss: 4.0993 - val_acc: 0.5141\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 3.9582 - acc: 0.5543 - val_loss: 4.0407 - val_acc: 0.5170\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 3.8948 - acc: 0.5600 - val_loss: 3.9937 - val_acc: 0.5164\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 3.8340 - acc: 0.5622 - val_loss: 3.9642 - val_acc: 0.5055\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 3.7750 - acc: 0.5665 - val_loss: 3.8911 - val_acc: 0.5117\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 3.7153 - acc: 0.5717 - val_loss: 3.8436 - val_acc: 0.5130\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 3.6598 - acc: 0.5742 - val_loss: 3.8647 - val_acc: 0.4978\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 3.6085 - acc: 0.5747 - val_loss: 3.7679 - val_acc: 0.5113\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 3.5514 - acc: 0.5797 - val_loss: 3.7214 - val_acc: 0.5102\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 3.4930 - acc: 0.5826 - val_loss: 3.6345 - val_acc: 0.5267\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 3.4407 - acc: 0.5866 - val_loss: 3.7171 - val_acc: 0.4974\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 3.3895 - acc: 0.5873 - val_loss: 3.5450 - val_acc: 0.5245\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 3.3394 - acc: 0.5902 - val_loss: 3.6199 - val_acc: 0.4820\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 3.2883 - acc: 0.5929 - val_loss: 3.4469 - val_acc: 0.5236\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 3.2372 - acc: 0.5964 - val_loss: 3.4083 - val_acc: 0.5213\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 3.1927 - acc: 0.5977 - val_loss: 3.4154 - val_acc: 0.5160\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 3.1442 - acc: 0.6017 - val_loss: 3.3604 - val_acc: 0.5209\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 3.0964 - acc: 0.6040 - val_loss: 3.3115 - val_acc: 0.5215\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 3.0495 - acc: 0.6069 - val_loss: 3.2601 - val_acc: 0.5249\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 3.0061 - acc: 0.6084 - val_loss: 3.2439 - val_acc: 0.5197\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.9606 - acc: 0.6102 - val_loss: 3.3224 - val_acc: 0.4879\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 2.9198 - acc: 0.6126 - val_loss: 3.1571 - val_acc: 0.5236\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.8760 - acc: 0.6141 - val_loss: 3.1066 - val_acc: 0.5287\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.8348 - acc: 0.6163 - val_loss: 3.1383 - val_acc: 0.5114\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.7960 - acc: 0.6179 - val_loss: 3.0448 - val_acc: 0.5192\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.7551 - acc: 0.6197 - val_loss: 3.0015 - val_acc: 0.5284\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.7168 - acc: 0.6228 - val_loss: 2.9442 - val_acc: 0.5373\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 2.6842 - acc: 0.6233 - val_loss: 2.9852 - val_acc: 0.5107\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.6475 - acc: 0.6250 - val_loss: 2.9368 - val_acc: 0.5175\n",
            "Experiment with Regulizer = 0.000000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 2.0511 - acc: 0.2608 - val_loss: 1.8892 - val_acc: 0.3314\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.8275 - acc: 0.3553 - val_loss: 1.7806 - val_acc: 0.3670\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.7382 - acc: 0.3908 - val_loss: 1.7092 - val_acc: 0.3934\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.6762 - acc: 0.4107 - val_loss: 1.6617 - val_acc: 0.4155\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.6263 - acc: 0.4300 - val_loss: 1.6184 - val_acc: 0.4318\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.5851 - acc: 0.4445 - val_loss: 1.5868 - val_acc: 0.4362\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.5499 - acc: 0.4551 - val_loss: 1.5497 - val_acc: 0.4528\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.5176 - acc: 0.4664 - val_loss: 1.5278 - val_acc: 0.4564\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.4889 - acc: 0.4770 - val_loss: 1.4992 - val_acc: 0.4674\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.4633 - acc: 0.4872 - val_loss: 1.5107 - val_acc: 0.4710\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.4406 - acc: 0.4967 - val_loss: 1.4776 - val_acc: 0.4741\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.4171 - acc: 0.5031 - val_loss: 1.4912 - val_acc: 0.4736\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.3965 - acc: 0.5095 - val_loss: 1.5029 - val_acc: 0.4683\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.3753 - acc: 0.5142 - val_loss: 1.4413 - val_acc: 0.4850\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.3584 - acc: 0.5220 - val_loss: 1.4329 - val_acc: 0.4907\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.3390 - acc: 0.5284 - val_loss: 1.4121 - val_acc: 0.5012\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 1.3188 - acc: 0.5359 - val_loss: 1.4008 - val_acc: 0.5059\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.3025 - acc: 0.5417 - val_loss: 1.3964 - val_acc: 0.5013\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.2880 - acc: 0.5459 - val_loss: 1.4063 - val_acc: 0.4981\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.2702 - acc: 0.5518 - val_loss: 1.4109 - val_acc: 0.4949\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.2544 - acc: 0.5579 - val_loss: 1.3789 - val_acc: 0.5054\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.2393 - acc: 0.5634 - val_loss: 1.3779 - val_acc: 0.5085\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.2240 - acc: 0.5689 - val_loss: 1.4209 - val_acc: 0.4964\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.2080 - acc: 0.5748 - val_loss: 1.4255 - val_acc: 0.4948\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.1972 - acc: 0.5789 - val_loss: 1.3645 - val_acc: 0.5148\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.1812 - acc: 0.5857 - val_loss: 1.3474 - val_acc: 0.5195\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.1677 - acc: 0.5892 - val_loss: 1.4490 - val_acc: 0.5000\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.1513 - acc: 0.5938 - val_loss: 1.3728 - val_acc: 0.5164\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.1382 - acc: 0.6002 - val_loss: 1.4118 - val_acc: 0.5024\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.1251 - acc: 0.6060 - val_loss: 1.3547 - val_acc: 0.5188\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.1131 - acc: 0.6079 - val_loss: 1.4355 - val_acc: 0.4976\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.1002 - acc: 0.6123 - val_loss: 1.3334 - val_acc: 0.5304\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 1.0887 - acc: 0.6170 - val_loss: 1.3702 - val_acc: 0.5225\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.0731 - acc: 0.6222 - val_loss: 1.5108 - val_acc: 0.4909\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 1.0617 - acc: 0.6238 - val_loss: 1.3612 - val_acc: 0.5197\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 1.0466 - acc: 0.6303 - val_loss: 1.3349 - val_acc: 0.5234\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.0373 - acc: 0.6335 - val_loss: 1.3790 - val_acc: 0.5185\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 1.0217 - acc: 0.6399 - val_loss: 1.4195 - val_acc: 0.5083\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 1.0087 - acc: 0.6444 - val_loss: 1.3721 - val_acc: 0.5165\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 12s 250us/step - loss: 1.0003 - acc: 0.6490 - val_loss: 1.4322 - val_acc: 0.5091\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.9867 - acc: 0.6532 - val_loss: 1.3605 - val_acc: 0.5267\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 0.9738 - acc: 0.6557 - val_loss: 1.3860 - val_acc: 0.5308\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 0.9566 - acc: 0.6631 - val_loss: 1.3841 - val_acc: 0.5279\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.9439 - acc: 0.6681 - val_loss: 1.3832 - val_acc: 0.5292\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.9339 - acc: 0.6727 - val_loss: 1.3683 - val_acc: 0.5341\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.9233 - acc: 0.6728 - val_loss: 1.4269 - val_acc: 0.5153\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.9123 - acc: 0.6788 - val_loss: 1.5848 - val_acc: 0.4825\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 0.8994 - acc: 0.6853 - val_loss: 1.3895 - val_acc: 0.5236\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 0.8869 - acc: 0.6883 - val_loss: 1.4214 - val_acc: 0.5235\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.8764 - acc: 0.6913 - val_loss: 1.4523 - val_acc: 0.5134\n",
            "Experiment with Regulizer = 0.000000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 12s 250us/step - loss: 2.0415 - acc: 0.2750 - val_loss: 1.8612 - val_acc: 0.3431\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.8069 - acc: 0.3674 - val_loss: 1.7608 - val_acc: 0.3783\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 1.7249 - acc: 0.3965 - val_loss: 1.6873 - val_acc: 0.4088\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 1.6658 - acc: 0.4187 - val_loss: 1.6441 - val_acc: 0.4211\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.6181 - acc: 0.4349 - val_loss: 1.6034 - val_acc: 0.4366\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 250us/step - loss: 1.5783 - acc: 0.4459 - val_loss: 1.5805 - val_acc: 0.4397\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.5434 - acc: 0.4594 - val_loss: 1.5499 - val_acc: 0.4534\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.5150 - acc: 0.4692 - val_loss: 1.5428 - val_acc: 0.4575\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.4895 - acc: 0.4775 - val_loss: 1.5132 - val_acc: 0.4687\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.4626 - acc: 0.4878 - val_loss: 1.4919 - val_acc: 0.4703\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.4412 - acc: 0.4959 - val_loss: 1.4689 - val_acc: 0.4816\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 1.4184 - acc: 0.5038 - val_loss: 1.4925 - val_acc: 0.4727\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 1.3983 - acc: 0.5087 - val_loss: 1.4747 - val_acc: 0.4712\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.3759 - acc: 0.5170 - val_loss: 1.4380 - val_acc: 0.4932\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.3569 - acc: 0.5245 - val_loss: 1.4266 - val_acc: 0.4971\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.3391 - acc: 0.5304 - val_loss: 1.4059 - val_acc: 0.5017\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 259us/step - loss: 1.3204 - acc: 0.5384 - val_loss: 1.4209 - val_acc: 0.4923\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 1.3039 - acc: 0.5419 - val_loss: 1.4048 - val_acc: 0.5029\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 1.2835 - acc: 0.5493 - val_loss: 1.3895 - val_acc: 0.5010\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.2716 - acc: 0.5532 - val_loss: 1.3822 - val_acc: 0.5092\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.2540 - acc: 0.5589 - val_loss: 1.3740 - val_acc: 0.5120\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.2399 - acc: 0.5639 - val_loss: 1.3585 - val_acc: 0.5176\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 1.2248 - acc: 0.5697 - val_loss: 1.3880 - val_acc: 0.5119\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.2098 - acc: 0.5732 - val_loss: 1.3706 - val_acc: 0.5104\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.1958 - acc: 0.5801 - val_loss: 1.3588 - val_acc: 0.5153\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.1809 - acc: 0.5856 - val_loss: 1.3429 - val_acc: 0.5228\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 1.1702 - acc: 0.5894 - val_loss: 1.3841 - val_acc: 0.5082\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.1525 - acc: 0.5957 - val_loss: 1.3525 - val_acc: 0.5168\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.1434 - acc: 0.5984 - val_loss: 1.3687 - val_acc: 0.5156\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.1266 - acc: 0.6040 - val_loss: 1.3528 - val_acc: 0.5194\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.1151 - acc: 0.6081 - val_loss: 1.3428 - val_acc: 0.5230\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.0990 - acc: 0.6146 - val_loss: 1.3491 - val_acc: 0.5210\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.0872 - acc: 0.6184 - val_loss: 1.3491 - val_acc: 0.5267\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.0771 - acc: 0.6212 - val_loss: 1.3758 - val_acc: 0.5131\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 1.0607 - acc: 0.6285 - val_loss: 1.3566 - val_acc: 0.5211\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.0512 - acc: 0.6293 - val_loss: 1.3409 - val_acc: 0.5242\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.0373 - acc: 0.6368 - val_loss: 1.3657 - val_acc: 0.5249\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 1.0244 - acc: 0.6401 - val_loss: 1.3685 - val_acc: 0.5226\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.0096 - acc: 0.6445 - val_loss: 1.3773 - val_acc: 0.5163\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9998 - acc: 0.6506 - val_loss: 1.3542 - val_acc: 0.5258\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 12s 250us/step - loss: 0.9910 - acc: 0.6530 - val_loss: 1.3455 - val_acc: 0.5285\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 0.9759 - acc: 0.6572 - val_loss: 1.4107 - val_acc: 0.5175\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 0.9638 - acc: 0.6637 - val_loss: 1.4162 - val_acc: 0.5076\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.9543 - acc: 0.6667 - val_loss: 1.3889 - val_acc: 0.5275\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.9407 - acc: 0.6712 - val_loss: 1.4199 - val_acc: 0.5104\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 12s 250us/step - loss: 0.9301 - acc: 0.6736 - val_loss: 1.3604 - val_acc: 0.5313\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9143 - acc: 0.6800 - val_loss: 1.3583 - val_acc: 0.5300\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 0.9073 - acc: 0.6826 - val_loss: 1.4378 - val_acc: 0.5065\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.8976 - acc: 0.6863 - val_loss: 1.3871 - val_acc: 0.5255\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 0.8784 - acc: 0.6924 - val_loss: 1.4346 - val_acc: 0.5200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4L93kqZ3bje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "e248b38c-f3d8-4547-81f1-925b74a19fea"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\"\"\"Code Here\n",
        "將結果繪出\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, cond in enumerate(results.keys()):\n",
        "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
        "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
        "plt.title(\"Loss\")\n",
        "plt.ylim([0, 5])\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, cond in enumerate(results.keys()):\n",
        "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
        "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdoAAAF1CAYAAABPriuUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNgACOTa7gAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAF1CAYAAADbSIJmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3hUVf7H8fdJ770QEmog1FCkKV1Q\nQMEGoij2jrq6urLrqqu4xbbW365l7QoqggpKR6QLSEJPgVTSe5tkMn2+vz8mBBCQqEACnNfz3CeZ\nW8+9ycxn7jn3nqtEBE3TNE3TWo9baxdA0zRN0853Oow1TdM0rZXpMNY0TdO0VqbDWNM0TdNamQ5j\nTdM0TWtlOow1TdM0rZXpMNY0TdO0VqbDWNPaGKXUeqVUjVLKu7XLomnamaHDWNPaEKVUZ2AUIMCV\nZ3C7HmdqW5qmHUuHsaa1LbcA24CPgVsPjVRK+SqlXlFK5Sml6pRSm5VSvk3TRiqltiilapVSBUqp\n25rGr1dK3XXEOm5TSm0+4rUopR5QSmUCmU3j3mhah0EptUMpNeqI+d2VUk8opbKVUvVN0zsopd5U\nSr1y5E4opb5TSj1yOg6Qpp2LdBhrWttyC/BZ0zBRKRXdNP5lYBAwHAgD/gw4lVKdgBXAf4BIYACw\n+1ds72pgGNC76XVS0zrCgM+BhUopn6ZpjwI3AJcDQcAdQCPwCXCDUsoNQCkVAVzStLymaS2gw1jT\n2gil1EigE7BARHYA2cCNTSF3B/CwiBSJiENEtoiIBbgRWCMiX4iITUSqROTXhPHzIlItIiYAEZnX\ntA67iLwCeAM9mua9C3hKRA6Iy56mebcDdcD4pvlmAOtFpOx3HhJNO2/oMNa0tuNWYLWIVDa9/rxp\nXATggyucf67DCca3VMGRL5RSjyml0puqwmuB4Kbtn2xbnwA3Nf1+EzD3d5RJ0847+qINTWsDmtp/\nrwPclVKlTaO9gRAgBjAD8cCeny1aAAw9wWqNgN8Rr9sdZ57mx7Y1tQ//GdcZbqqIOJVSNYA6Ylvx\nQMpx1jMPSFFK9Qd6AYtPUCZN045DnxlrWttwNeDA1XY7oGnoBWzC1Y78IfCqUqp904VUFzXd+vQZ\ncIlS6jqllIdSKlwpNaBpnbuBqUopP6VUN+DOk5QhELADFYCHUuppXG3Dh7wP/EMp1V259FNKhQOI\nSCGu9ua5wNeHqr01TWsZHcaa1jbcCnwkIvkiUnpoAP4LzAQeB/bhCrxq4EXATUTycV1Q9aem8buB\n/k3rfA2wAmW4qpE/O0kZVgErgQwgD9fZ+JHV2K8CC4DVgAH4APA9YvonQCK6ilrTfjUlIiefS9M0\n7SSUUqNxVVd3Ev3Bomm/ij4z1jTtd1NKeQIPA+/rINa0X0+HsaZpv4tSqhdQi+tCs9dbuTiadlbS\n1dSapmma1sr0mbGmaZqmtTIdxpqmaZrWylqt04+IiAjp3Llza21e0zRN086oHTt2VIpI5PGmtVoY\nd+7cmeTk5NbavKZpmqadUUqpvBNN09XUmqZpmtbKdBhrmqZpWivTYaxpmqZprUyHsaZpmqa1Mh3G\nmqZpmtbKWhTGSqlJSqkDSqkspdTjx5n+mlJqd9OQ0fRQck3TNE3TWuCktzYppdyBN4FLgUIgSSn1\nnYikHZpHRB45Yv4/AANPQ1k1TdM07ZzUkjPjoUCWiOSIiBWYD1z1C/PfAHxxKgqnaZqmaeeDloRx\nLEc/YLywadwxlFKdgC7A2t9fNE3TNE07P5zqC7hmAF+JiON4E5VS9yilkpVSyRUVFad405qmaZp2\ndmpJGBcBHY54Hdc07nhm8AtV1CLyrogMFpHBkZHH7Z5T0zRN0847LQnjJKC7UqqLUsoLV+B+9/OZ\nlFI9gVBg66ktoqZpmqadWRZLCVVVK87Y9k56NbWI2JVSDwKrAHfgQxFJVUr9HUgWkUPBPAOYLyJy\n+oqraZqmaadHcXEjaWmLMRo/JTDwe+x2P8aPL8fd3fe0b7tFT20SkeXA8p+Ne/pnr+ecumJpmqZp\n2ulhtcL+/bBnD+zZ46S2diOxsZ8ydOhX+PvXYzJ1ZN26J6iuvpnx409/EEMrPkJR0zRN004nESgu\nhr17Dw/79sGBAw46dEhhzJiFTJgwl+jofKzWQOrrp+PndwuXXDKKGTPObAeVOow1TdO0c4bRCAsX\nwmefwc6dUF0NAQE19O69jYsu2sqjj24lLu4nPDzqATdCQi4lJuYFIiKuwt3dr9XKrcNY0zRNO6uJ\nwI4d8P77sGRJJWFh+xk2LI0ZM34iNnYrPj7pTXO64e+fSHDwTQQFXURo6Hi8vdu3atkP0WGsaZqm\nnVVEBJMpi/Ly/Wzbtp+DB/cTELCfyy47wIwZVc3zeXiEERR0EcHBMwkKuojAwCF4eAS2YslPTIex\npmmadlawWIopKZlLbu6HKJUBQLt24OcXjbt7Tzp2nEZISE/8/Hrg59cTH58uKKVaudQto8NY0zRN\na7OcTiuVlUvJyPgQm20FSjnZu3cUW7Y8QvfuA7nmmh6MHRvS2sX83XQYa5qmaW1OQ8M+MjM/orJy\nLp6elVRUtGfNmr9gNt/GlCkJfPwx+J6Zu47OCB3GmqZp2hkhAqmpsHat6ypnpcx4e+fg45OJr28m\nvr5Z+Pll4u+fia9vATabJz/+eBV5eXcwbNgEnnvOnfDw1t6L00OHsaZpmnbalJfDmjWwerWQnr6P\nTp2+Z9CgNfTsmUZUVAFuboc7bayrC6ekpBt7946hsnIoHTvewC23RNC1ayvuwBmiw1jTNE07ZaxW\n2LwZVq+GrVtL8fJaw5Ahq7nqqu+57bZSADw9exEaOho/v+74+nbD19f109MztJVL33p0GGuapmm/\nS3U1rFhhZ9OmDAoL99KhQzKDB69h0qQ9TXNEEBl5KWFhlxIaeik+PnGtWt62SIexpmma9qtYreUc\nOLCX3bv3UlW1F3//vXTqlMqMGVYARLwIChpBRMTzhIVNICBgAEqd2e4lzzY6jDVN07STstvryMn5\ngoyM9wgI2AlAhw4QFBSDzdYPP79LiI/vR2BgP/z8euLm5tXKJT676DDWNE3TjktEMBi2kJ7+Pg0N\nC/DwaKSsrB/btr1IfPxgxoxJpGvXyNYu5jlBh7GmaZp2FKu1ktLST8nOfh+l0mlsDGD9+ptQ6i5u\nvnkwd955dvRqdTbRYaxpmnaeE3HQ0LCX2tr1VFWto6ZmJUrZSEu7kE2bPiAx8Tpmzw4gUp8EnzY6\njDVN084zTqeDgoLdHDy4gfr69Xh7b8TTsw6AoqJ4tm69n6ysu7jhhr588gl4e7dygc8DOow1TdPO\nUSJOLJZiqqoySEvLoKgoA6s1ndjYLfj7GwCoqelOSsp0KirGIjKGuLg4pk2DsWPhLHnGwjlBh7Gm\nado5wHWx1TaqqpZhMBygujoDkUzc3U0AeHpCu3a+1NR0p7R0Bh4eY4mOHsOoUe2ZORPc9J1HrUqH\nsaZp2lnMZMqmuHgeBQXzgCwcDndKSrpSUJBAcfF4PDwSiItLoH//7owcGUtAgE7dtkiHsaZp2lnG\naq0mLW0BxcVz8fPbgtOp2L37YtaseZLGxmmMHBnI2LFw0UXg79/apdVaQoexpmnaWaCiooyffvqB\n2tqviI5ehqenlbKyPiQnv4C3942MGtWBzz+HkLP/0b7nJR3GmqZpbZDZbCQpaSO5uWvw9FxDTMxe\nAgLAZoti3777CQ6+hdGjB3DbbUpfaHUO0GGsaZrWBjgcRjIydrN37zpstjVER2/B09NGu3Ze5OeP\nJDv7ebp3v4TJkwfi5eXe2sXVTjEdxpqmaWeY3W6goWE39fU7qK3dSUnJTjw89uPm5iQyUpGfP5Cs\nrEeIjb2EESNGMGGCX2sXWTvNdBhrmqadZiJCbe06Sko+pL5+OyZTZvO0qqr27N8/iKqq6SQkXMDF\nFw9n3LiIViyt1hp0GGuapp0mTqeV8vIvKSx8lYaG3bi7h1NVNYrNm29h8+YLKCi4gEsuacedd8Ko\nUbqTjfOZDmNN07RTzGarJTv7f5SU/Aeliqip6cXKle/x6ac3YTb7MHQo3HEHzJgBwcGtXVqtLdBh\nrGma9juJQHIyrFmTi4/P6/Tq9QE+PkZ27hzPggXvUVw8kf793XjsMbjuOkhMbO0Sa22NDmNN07ST\ncDjMVFQsxGhMweGox+Gox26vx2Kpp7y8HoOhHnf3eoYOLQHcyMm5AYvlUfr1G8DNN0NUVGvvgdbW\n6TDWNE07AYulhOLitykufgebrQKlvPDwCMJqDaS6OpDS0gCMxjC8vTvRuXMgsbGd6NLlLsaPj23t\nomtnGR3GmqZpP2MwJFFY+AYVFQsQsRMUNAU/v4dZtWoc77+vyM52tfXedBPcdRcMGNDaJdZ+C4vd\nQklDCSX1JRTXF1PS4Pp56HeH08GaW9ackbLoMNY07bxXUwNr1tipq/uG0NA3CA/fgtkcyObNs/ji\niz+Qk9Oted4xY2DOHJg2DXx9W6/M2tFEhLy6PPaU7mF36W5SKlIwWAyY7WZMNhNmu/mowWQ30WBt\nOGY9Hm4etAtoR/vA9nQM7oiIoM7AZe46jDVNO+/Y7Qays9PYvj2VoqJUPDxSiY/fRbduFZSUdOXL\nL18nJ+d2wsKCuPpqiImB9u1hyBDo3r21S39+ExFqzbXk1uY2B++eMtfPOksdAApFfFg84b7h+Hj4\nEO7n+unj4YOvh2/z72G+YbQPbE9MQIzrZ2AMEX4RuKkz/2QrJSJnfKMAgwcPluTk5FbZtqZp5w+L\npYi6ui0YDNspLU2hoSEVH5+C5ulWqw9mcy9CQvrSpcu1xMVNRind3WRrMNlMlDaUNlcXFxmKKKpv\nGgyHf5rspuZl/D396Rfdj/7R/RnQbgAD2g2gb1Rf/L3a3uOqlFI7RGTw8abpM2NN084ZTqcNo3Fv\nU/huobZ2C1ZrPgBWqzf5+T05eHAUIn3o0qUPI0b0oWfPLjp8z4AGawM5NTlkV2eTU5NDUX1Rc/CW\n1JdQ2lDafGZ7JC93L2IDY4kNimVQzCCuTLiS2KBYOgZ3pH90f+LD4lvlTPZU02GsadpZzWotp7T0\nU6qrl2EwbMfpbATAYIhl584RpKQ8Snb2cDp3HsAVV3jy0EP6VqNTzeqwUtlYSbmxnHJjOSX1JeTU\n5JBT6wrf7Jpsyo3lRy3j7+lPTGAM7QLa0S+6HxPiJxAT4HodExhDTEAMsUGxhPuGn5E229amw1jT\ntLOOiJOamh8oKXmPiorFgI3KyoFs334XycnDSUkZTmxsByZOhAcfhOHDwcurtUt9dhIRShpKyKjK\naB4O1h5sDt5yYzk15ppjllMoOgR3ID40nisTrqRraFfiw+KJD42na2hXQn1DW2Fv2i4dxpqmnTUs\nlmLy8z+ioOAD3NxyMRrDWL78AZYtu5uGht5MmAC33goTJrguutJaxmAxUGQootBQSKGhkJyaHDKq\nXcGbWZWJ0WZsntfb3ZvOIZ2bz2ij/KOah2j/6ObfOwZ3xNvDuxX36uyiw1jTtDbLYoH8/GqKitZT\nVfUpoaFLcXNzsHv3xaxe/S9ErmHcOB++/hoGDgS3s7/p8JRxOB1Um6opN5ZTZixrPostayijuKG4\nOXiLDEXUW+uPWtZNudElpAsJ4QmM6TSGhPCE5iEuKO6caKNta3QYa5rWqgwG+P57yMmBggKori7F\n23sTUVEb6NZtI/Hx+wBQKor16x/D3f1ORozozqxZ+j5fh9NBTk0O+8r3sa9sH/vK95FRlUGZsYzK\nxkqc4jxmGXflTkxgDLGBsfSJ7MPE+InEBsYSFxRHbJDrZ1xQHF7uul7/TGpRGCulJgFvAO7A+yLy\nwnHmuQ6YAwiwR0RuPIXl1DTtHGIywfLl8MUXsH59DQMHLqd//w0MG7aB2NgMAGw2f+rrR1BdfT1B\nQWMYNWoYU6d6tnLJW4fVYSWvNo+s6izSK9ObwzetIq35Np9D99b2iujFRXEXER0QfVQV8qEhzDdM\nn9m2QScNY+W65v9N4FKgEEhSSn0nImlHzNMd+CswQkRqlFL6WkVN045it8MPP7gCeMUKA/37f8vE\niQu4//5VuLnZcHcPJiRkFMHBdxMSMpqAgIG4uZ0/4SsiZFRlsL9yP1nVWWRVZ5Fdk01WdRZ5dXlH\nneVG+0fTN6ov9w66l8ToRBKjEukd2btN3lurtUxLzoyHAlkikgOglJoPXAWkHTHP3cCbIlIDICLl\nx6xF07TzjggkJcGnn8J339WTkLCESy9dwM03r8Td3YK3dwciIx8iKmo6gYGDz6v7fe1OO7tKdrEp\nfxOb8jexOX8zlY2VzdNDfULpFtaNC+MuZGbiTLqFdSM+LJ6E8ASi/PX5zrmmJWEcCxQc8boQGPaz\neRIAlFI/4qrKniMiK3++IqXUPcA9AB07dvwt5dU07SxQXi4sWFDIhg1piKQzYMAmPvxwOR4eZry8\nYomKmkVk5HUEBQ1DneNVpg6ngxpzDZWNlRQaCtlSsIVN+ZvYWrC1+SrlrqFdmdx9MiM7jmzuyCLM\nN6yVS66dSafqAi4PoDswFogDNiqlEkWk9siZRORd4F1wdYd5irataVorslrLMRi209CQRlZWGlVV\naQQGptO3bwN9+7rm8fSMJSrqbiIjryM4ePg5FcCNtkZ2lexie9F20ivTqWisoLKxsnmoaqxCOPxx\np1AkRidy24DbGNVxFCM7jiQ2SD9y8XzXkjAuAjoc8TquadyRCoGfRMQG5CqlMnCFc9IpKaWmaW2K\n02mlqmopJSUfUV29AnAAUFPTnrKyXhiNt5OY2Jvu3Xvj59cLL6/I1i3wKWJ32kmrSGN70fbmIaU8\nBYe49v/QvbYRfhEkRiUS4RdBhF8EkX6RRPhFEOUfxaD2gwjxCWnlPdHampaEcRLQXSnVBVcIzwB+\nfqX0YuAG4COlVASuauucU1lQTdNaX339LvLyPqa8/DPc3KqoqYlhxYrH2Lr1Srp1683MmSHcd9/Z\n39uVU5zk1+WTXpFOWkWaa6hMY2/ZXhptru42Q31CGRo7lCt7XMmQ9kMYEjuEdgHtWrnk2tnqpGEs\nInal1IPAKlztwR+KSKpS6u9Asoh81zRtglIqDddX5NkiUnU6C65p2plhMlWQnPw5dXUfERCwB6vV\nix9/vJqNG28jLOxSLr3Ug6efhri41i7pr3codFPKU0gpT2kO3vTK9ObQBdfVy70je3P3BXczNHYo\nQ2OHEh8af170maydGfoRipqmNXM6hdzcDNLTt1BTsxVv7y1ERKTh5ibs3z+Y9PTbCQ+fwbhxYQwb\nBp5nyZ1HNoeNKlMVaRVp7Cvb5wrfClcAH/mA+bigOHpH9qZ3RG96Rfaid2RvekX0ItwvvBVLr50r\n9CMUNU07LrPZxubNP1JYuAWncwuRkdsIDKwiIACczlCKii6irGwGMTFXM316X8LbWCaVNpSyKW8T\nG/M2klnt6kPZaDUe89PmtB21XLhvOInRidw+4Hb6RvWlb1Rf+kT2IdgnuJX2RDvf6TDWtPOM02ll\n//417Nq1kODgbwkIqKFzZygp6UVJyVUYDMPp2nU4l17aA1/ftnXVc35dPhvzNrIxbyMb8jaQUeXq\nrcvP04/ekb0J8AqgfWB7/L38CfAMwN/LH39Pf/y9/AnxCaFXRC/6RvUlyj9KVzFrbYoOY007Dzid\nViorv2f37oU4nd/i41NLcHAQBQVX0rnzNIYOHc3YsW3nvtZDbbmHqpT3le9jS8EW8uryAAj2DmZU\np1HcNfAuRncazQUxF+DpfpbUmWvacegw1rRzlOuZv2vJzZ1LTc23eHjUYbUGs3PnVYSGTueqqy5l\nypTWf8Sd2W5ma8FW9pbtZV+5K3xTK1KPasvtGNyRobFD+dNFf2J0p9H0jeqLu9v501uXdu7TYaxp\n55j6+hqSkz/BZHobP78M6utD2Lz5GurrpzNhwnieeMIbj1Z+55fUl7A8czlLM5fyffb3zT1RRfpF\nkhidyB0D7jjclhvVhyDvoNYtsKadZjqMNe0s19gIW7bAjh27cHd/i759P8PHx0Ru7kXs2TOXyMjp\n3HuvN127tl4ZRYRdpbtYcmAJSzOXklzsupOiQ1AHbu1/K5d3v5whsUN0n8vaeUuHsaadhaqq4Kuv\nYOFCM56eXzFlypsMG7YNq9WX0tKZREbez003DeSBB07P9k02E5nVmRyoPEBGVQYVjRWY7WYsDgtm\nu9n1u/3w7wdrD1LSUIJCcWHchfxr3L+4IuEK+kb11RdSaRo6jDXtrGE0CsuX5/HTT9sxmbbTo8dP\nzJ69E2/vRpzOBOLiXqdTp1vx9Dx1XS1aHVa2FGwhpTyFA5UHOFDlGvLr8o+aL8g7CB8Pn+bB2927\n+Xd/L3/Gdh7LxPiJXN79ciL9z42uMTXtVNJhrGltlOsK6PXs2bONkpLtBAVtJzKygilTwOHwxsvr\nAtq1u5vw8MmEho4/ZQ9faLA2sDJrJYv3L2ZpxlLqLHUABHoF0iOiB6M6jqJHeA96RPQgITyB7mHd\n9XN0Ne130mGsaW2I02mnuno9e/fOx2b7Bm/vGtzdFdCLqqrJhIQMZeDAYQQG9sXN7dR1AF1uLGfJ\ngSUs2r+INTlrsDgshPuGM7XXVK7qcRXD4oYR7R+tq5Q17TTRYaxprUzESVXVj+zZMx+bbSE+PhWY\nTIH89NPVmM3XMWLEaK6/PgjvU3gXks1hY3vRdtbmrmV1zmp+zP8RQegc0pn7h9zP1T2vZniH4Xi4\n6Y8ITTsT9DtN01qBiIOqqq3s2rUIq/VL/P2LsNl8SU6egtk8g8GDL+Ovf/XF1/fUbM/hdLCnbA9r\nc9eyNnctG/M2YrQZUSgGxgzkmTHPcHXPq+kX3U+f/WpaK9BhrGlniN1uoLx8Namp3+FwLMfHpwrw\nJCXlMkymfzNo0BU89lgAPj6/fRsiQmlDKbm1ueTU5JBbk8uu0l2sP7ieGnMNAL0ienHbgNsY12Uc\nYzqN0Q9B0LQ2QIexpp1GJtNBysuXkJW1BFiPu7uNxsYwdu26HLiCIUMm8sc/Bv+mKuhyYzmL9y9m\nT+kecmtzya3N5WDtQcx281HzdQnpwjU9r2F81/Fc3PliYgJjTsm+aZp26ugw1rRTzGQ6SFnZl+Tk\nzMfNbTcARUU92LHjj/j4XMGYMRfxxBMeeP2G669qTDV8k/4NX6Z+yQ+5P+AUJ8HewXQJ7ULvyN5M\n7j6ZLiFd6BLaha6hXekU3Alfz1NU161p2mmjw1jTTgGLpZjy8oXk5s7H6dwGQHr6hWzf/jLBwVdy\n2WXd+fe/+U0BbLAY+O7Ad8xPmc/q7NXYnDa6hnbl8RGPc33f60mMStTtvJp2ltNhrGm/kdVaSWXl\nN+Tnz8dkWo9SQmbmADZufAEPj+u4+uou3H33yQPYKU6qGqsobSilpKGE0oZS1+/1JWTXZPN9zveY\n7WY6BHXgoWEPMaPvDAbFDNIBrGnnEB3GmtYCIoLZnEtd3Y/U1f1ITc1mzOZUAAoKEvjhh6epq7ue\nSZN68X//B6Ghv7y+0oZSXtz8IgvTFlLaUIpDHMfMc+jZvHdfcDfX97meizpchNsp6thD07S2RYex\nph2HiNDQsJPa2k0YDK4AtlpLALBYgti7dzh7986gqGgyY8cO4OmnVYsexFBhrOClH1/izaQ3sTqs\nXNPrGhLCEmgX0I52Ae2ICYxp/j3AK+A076WmaW2FDmNNO4LTaaGs7HMKC1/DaNwHgEgncnMvZtWq\nkSQnj8Bo7MP117vz4IMwdCi0pLa4qrGKV7a+wv/99H+Y7CZmJs7kb6P/Rvfw7qd5jzRNOxvoMNY0\nwGqtoLj4bYqK3sJmK8PpTGTPnvd4//1JpKXFERgIU6fCO+/AxRfT4ucB15preXXrq7y+7XUarA1c\n3/d6nhnzDD0jep7eHdI07ayiw1g7rxmNaeTlvU55+aeAhQMHLueDDx4lKWkcXl6Kyy+HZ5+FyZM5\naW9YNoeNg7UHyajKIKMqg/2V+/ky9UvqLHVc2/tanhnzDH2j+p6R/dI07eyiw1g7r4g4aWzMIC3t\nJwoL5xMauhKLxYdVq25j0aKHiYzsxcUXwz/+ASNGQMAJmm2rTdV8d+A79pbtbQ7f3Npc7E578zwh\nPiGM7zqep0c/Tf92/c/QHmqadjbSYayd0yyWYgyG7dTXb6esbDtGYxIeHgYARKJZtuwfKHUfY8dG\n8PTTEPILjwI2280sz1zO3L1zWZaxDJvThq+HLwnhCfRv15/pvaeTEJ7geqxgeHfCfcP17UeaprWI\nDmPtnNPQkEJBwcvU1KzBai0CwOHwIDu7H+npN+JwDKV//6FMntyTqVPdf3FdTnGyKW8T8/bO46v0\nr6g119IuoB0PDn2QmYkzGRgzUN9upGltUJGhiPaB7c+aL8Q6jLVzhsGwnby856iq+han05/U1CvZ\nsGEY6elDCQgYwLXX+vLII9Cx44nX4XA6yKnJIbUilW2F2/h83+cUGArw9/RnWu9pzEycybgu4/Sj\nBTWtjcqvy+eB5Q+wNGMpL13yErNHzG7tIrWI/kTRzmoiQm3tevLzn6OmZg02WyiLFz/DvHl/IDo6\nnBtugH/+E3r+7OJlpzjJrckltSKV1PJU18+KVPZX7m9+0IK7cmdit4m8eMmLXNnjSvy9/FthDzXt\n3CHSslsBfwuH04G7mzv+nv7sLdtL/+j+PLP+Gab1nkbX0BZ0AtDKdBhrZyURoapqKfn5z2EwbMNk\nasdnn/2bb765l7FjA/nmGxg37ug3voiwvWg7C1IXsDBtIQWGguZpHYI60CeqD+O7jKdPZB/6RPWh\nd2Rv3fGGpv1OpaWwfDksWwYZGbB3r2vczTfDf/4DvXqdeFmn0woIbm4nfqxZhbGCf236F0nFSWy6\nfRPhfuFkP5RNWUMZvd7sxaxls1g5c2Wbr67WYaydVSyWUsrL51Na+gFGYwp1dZ358MO3WLv2dm64\nwYfkZOjd+/D8IsKOkh0sSF3AgtQF5NXl4enmyaRuk3hq9FP0i+5H78jeBHkHtd5Oab/bt9/C4sXw\n8MMwYEBrl+bsIgJZWbBhg2uYOBFuugnMZtdtfYmJ0Levq3bpZP2s22yuL8AeHvDdd667EpKTXdNi\nY123CJpMrnWnpMCkSbB1K7fVLqEAACAASURBVLRvf3gddnsD4MDDI5iqqiWkpl6Lu3sgnp4RTUM4\n3bq9jsO9Pa9ufZWXt75Mo62R2wfcjslmwt/LHw83D2KDYvnXuH+xMnslRpuxzX+xViLSKhsePHiw\nJB/6K2naL7DbG6isXERZ2TxqatYATvLzBzFv3sPs2zeD++7zZNYsiIpyzS8i7CzZyVdpX7EgbQE5\nNTl4uHlwaddLub7P9VzV8ypCfH7hsmntrGMyuXpDS0mByy6Dv/4VRo1q7VK1DY2NWRiNezEa02hs\nTMdsziM6+ibatbuXW29VrF0LJa6eXomKgr/8BR59FNLToV8/sDfdrefhAQkJ8OKLMGWKK2TnzIHK\nysNDXR2Me3YOHu0/ZJRzKcs/7sfkya75+/U7uqZqxw4YMwa6dYONGyEoyPXeTUu7DqMxjcGDd2Iy\nZVNZuQibrfKoQUX+jUlf3oXRUsGkhKn8a9y/jtuRjlOcKFSbOStWSu0QkcHHm6bPjLU2yem0U1Pz\nPWVl86isXIzT2YjB0JmlS59g5cqZhIX15A9/cH379vGBRlsjSw78wJKMJSzLXEZxfTHuyp3xXcfz\nxMgnuKbXNYT5hrX2bmm/QVlDGTO+nsG0XtN4cOiDx0x3Ol0dsmzaBG+9Ba+/DqNHw8iRMH++CS+v\nFZSXz8dkyiQ+/hVCQ8e1wl64gkbEgdtpvPjPZMqhtPRjrNZyevR4B4Ds7EeoqloKgJtbJ6qrA/Hy\n+p727e+lpsYViIeGnj0PB2avXmA0uqqWU1Jg3z7Xz0MPQXE4IK/Qgt2nlLheHkzuGotPUAO2ju9w\nZecy7tl5IR9/uYbhHYYft6yDBsFXX7mC+tprYelSKCl5kYqKr4iPfxk3N2/8/Xvj79+7+fgV1RcR\nFxSH1WHltp79uTx4GxcMeJygoOP3aHfoTofcmlyWZy7ngaEPNE8zGtMBJ35+vdtEWOszY61NsViK\nKSr6LyUlH2CzlWOzhbJp0/UsWnQThYXDmTlTcccdcMEFUFBXwNKMpSzNXMra3LWY7WYCvAKYGD+R\nKQlTmNx9MpH+ka29S9rvICIM/3A4O4u34e3uQ+oDGXQI7tA8vboahg2D115zfagDNDbCBx9AdfUz\njBv3Kg5HAw7CMNhNdI+dSd9e7/3m8qzOXk27gHbEh8bj7+WP02lFKQ/AjX37vqa29lMCAxtwOo04\nnY04HEYGDdqBp2cI2dmPU1DwIp6e0fj6dsPXNx5f33g6dvwLbm7eTevy/FXBICIopThQvoulyTfQ\nz+cAbgpq7f5UhrzEtX2ux8uRBwhlZT0YMyYAHx8hPb0RLy9/GhszqK5eRWzsA6gW3qJX1VjFGz+9\nwbcHvmVv2V4A7hp4F+9d+R7Fxe+TkXE3ASGXc+OmTMqMZfxw8w8Mjj3uySAAH38ML70E3323ksLC\ny4mKup5evT4/6jhsL9rOY6sfI7smm8w/ZOLn6YfNVktycn/c3LwZNGgnHh6Hq6FFXF/U27eHIUPg\nseVP8Mr7BfxtzFP0jOyBt/d2wsIuRqlG/Px6Ehl5LVFRNzQH/+miz4y1Nq++fjeFha9SXj4fp9NO\nRsaVzJ17Oz/9dBljx3rxxBNwzTVQYsplfsp87vzfAnaX7gaga2hX7h10L1MSpjC602i83E/SsKUB\nUF+/g4KCV6ir28zgwXvw9DzJcx/PMIuliIMHn+WFXpU44xUiZvbu6IFP4lwiI6dhsZTw5ZeLiYjo\nSFxcJ6qrS6io+Ipu3V7jD3/wo7AwEqNxBn6BU4nvPRDPoHyefn8nfXuByZSLt3f7X7ww6JjyWGt5\navlkOvvZifeHngHexPraeOmtVezaeAkXXGDkuusOEhMTSGxsMCLt8fT0a14+LGwi7u6+mM35mEzZ\n1NT8QEXF13Tq9DcAMjJmUVHxNf5Bo/APuxY3v2EEeAUTExiDU5ysylqFyW4irzaP5JJkkouTeXDI\ng9zeZzTlGRMY5FfJfnNnsmQMizI3kVPzAP3aDeSiDhexNTWf6Zd7YTbDqlUKr6Y7A0pLPyI//wUq\nKhbSo8cH+Pmd/MEl9yy9h8X7FzOiwwhevvRlruhxBQnhCdTUrCczcxahoRNITPyWH7qU8PLKQdQU\n/xNpv+iEXzJuuw2uuSabfftuwN8/kR493m+eN7cmlyfWPsH8lPlE+0fz7Nhnm9/fnp4h9Or1Kbt3\nX0x29iP06HH4S9amTXD11fDnP7vC+I+DnuSVyf78Y5Fr+i23rGTixGjq6h7hoosWk5f3HCIOunZ9\nDqfTitGYSkDAgDN6xqzPjLVWI+Kkqmo5hYWvUlu7DqfTnw0b7uT99x/CzS2eO+90vVF9I8pYkLqA\nL1K+YGvhVgAuiruIqb2mMiVhCj3Ce7SJaqazgeuYL2sK4Q0oFYjd/iTjxv3ltN1ycjJWawUGw1YM\nhm0YDD8RHn4F7iHXserAQrqb/05g4BCCgoayNncd2RVbuXP0IuJjriAnZxn5+VOOWpe7eyD9+39P\nUNCw5nFv/vQ2D768Hr7+nIjx8yhZMZ3k5L54ebWnb9+v8fKKblE5N22eh8N+MwAWAik3h7Lx6xvY\nsvNGhvbrR5+BBmZvupvYvjlMHzYSr3338fLjCVx4oWpuN01MPLrd1Om04Obmjd1p5/Fvh+Nu2cWF\nYXZCvaDaCgUyhIcnbscpTtz/friDmg5BHRgR248b+t/D5G4T2L//Njp0+BNBQUMA1xlzakUqvSN7\nU1nhRs9BpdSU+9Hp4Tu4cWICj498nCDvIESE0tJPyMr6IyJWunT5J3FxD6PUiTvDyarOIr0inSt6\nXNE8zmIpJikpES+vKAYO3IqnZwgiQmbWwxQX/YcOHf5CTIen8fPyO+46LZYi0tPv5s03/8ugQV25\n7z5Iq0hj4P8G4q7ceWz4Y8wePptA78Bjls3JeYL8/Ofp0+cbIiOvAeDGG2HFCjhwwNUO7nDAh2vX\ncc+Se3h46KPcN3gWBkMNffqE4u8PGzaU09goXHZZNFVVK9i373J8fOLp3ftzgoKGtuj/oyV+6cy4\nqR3jzA+DBg0S7fxktxulsPBt2bYtQdatQ1atipN7731J/P1rpE8fkblzRSoMtfLRro/k0k8vFbdn\n3YQ5SL+3+8nzm56X3Jrc1t6F383pdEp9/R4pL/9KbLbaE85TYayQ6sbqU7bd/Py5sm4dsmVLB8nP\nf1nGjKkVEPnnP0XKyhZKVtZfxOl0nLLt/ZzT6RCLpbzpd6ds354o69Yh69Yha9d6SFLSIEnNekG6\n/193CXguQIrqipqXNZgNklOd0/x69myHREYWyZ49W6WsbL5UVHwrdrvpmG2abWb5MuVLGXFFprh7\nWiUjp1HKyubLhg2+smVLnBgMO45bVpOpQDIyHpL8/Nfkka9ekICgRhk1arU880xZ8zy1R/zpjFaj\nfLDzA5ny+RTx+oeX8GCC+F3ykiQkGsRVcSrSsaNIfoFdtuRvkSd/eFIeXvFw8/JTv5wq9y+9X17f\n8orM2zpLlm++QDbtmtl83DanPiW7ijZJfsU22bfvGtmypZPY7Y0nPebLlokEBjnk4Xe+kvGfjBe3\nZ93kviX3HX2MzEWyd+8UWbcOyc9/9aTr/Dmn0yl5eS9IY2PWMeMPHJgl69YhD30eJFlVx053Ou0i\nImKziYyfaBI3N6csXuya9vym56WwrvAXt+1wWCQ5ebBkZz8pIiJlZSKeniIPP3z0fHZ7o7y3Mk56\nveopmVWZR02bMsX195k6VSQ3t0qKi9+XrcljxGwu/dXH4pcAyXKCTNRnxtoZ43A0Ulz8Dvn5L2Kz\nlVNfP5gPPniUpUuv5cILPXlsth2VsIJ5KZ+y5MASLA4LXUK6cGPijdzQ9wb6RPVp7V04ZXbvvoTa\n2h8AUMqLsLBJtG9/D1sqnazMWsm+8n2klKdQY64hJiCG4j8VAzBtwTTW5a7D19MXXw9f/Dz9uCLh\nCv5+8d9xdzv2bMZsLiQ19QPS0jozf/6t/PijiaFDv+Xrr6cRGOjJtm2uC56+/BKWLn0Ef//XiYqa\nQc+eH7eoCre8fCnbtv0Ff/9sfHzC8PIKx8urHf37f980fSFmcw5Op6XpzHcrfn49ueACVw1HTs5f\ncXcP5Z//vIhFiwbzzeo67vxxFGUNZay8aeUJL/7Zn1/BBT0jmToV5s07cflMNhO+nq7HbR086Loa\n+Lbb4N13ob5+FykpV2GzVdKz50dERV0PuK4+Lih4kdLSTwAhKOIOLrhlCG57bic9zZ2EhJMeFuot\n9azIWsGi/Yt4dcKr0BDDM+9u5YedBzGMfIjKxkrcTBFc2ncQK2auOGHNjjS1CdfVbWXXruGANw6H\nE3f3KCIjP8TNLQ44eZWG0wluTU3C1aZq6i31xAbFHtOTnMNhxM3NF6XccDptKOXe3JZsd9qpNlUT\n6hOKp7tnc/nA0dRufiKCxVqJOBtpdCiCfNs3b9duN+B0mlHuIRgs9TRYjdDQDuX0IjoavFvYinDo\nOIHriu7aWld7safn4TLYbJU4HI1YxJdAn4ijurEVAYPBtSwI7r4N2D2raRfQDm+PljdlHOLj40Nc\nXByehwsA6DZjrZU5HCaKi98hL+9F7PYySkou4fXX/8b27aOYMgXe+eoAe73f4u6UL6jcXUmEXwT3\nDLqHmYkzGRo79KyvgjYa0ygvX0Bd3Qb691+DUu5ERl5LBb35KiuJcElnimcydXV9WJ1dzxcpc5nW\nqT2JfaaSEJFIsE9w87omxk+kfUB7THYTjbZGKhoryKrJOiqIDYbtVFZ+S1XVMozGPQDs2HE/mZm3\ncsstvkyaNKP5Q+7CC+GTT6C4GKZNe5Xvv29HefnjWCzF9O27+LjtyK4PYCdKufPtt/l4eCiWL/8D\nPXrUMGZMNW5uzuZ5y8vnU1n5DQB+fn2IjJxOSMhYAL7+GlJSnueZZ+Cpp+DrbxxcMtmAz31GVt+5\nmgvjLjzu8Xx01aMsTP2KrxdnkhB/4g/Kb/d/y4MrHmTNzWvoEdGDzp3hT38SKq1FNFhDCAwcyKBB\nyaSmTqO4+B0iI6dTUPAKOTmPo5QnMTH30LHjbB78eBnsuoM7H2ggIaFl96MHegdyXZ/ruK7PdU0j\nIHFSMpsi3mJS+0lc4HU9f7t+MomzFMarT/x0MKUUe/ZARsaFTJqUTHHxJ3z2GcTEzCIwMJK4uHAi\nIhTuP/se5nRCdjaEh0PYz24isDqs1JnriPCL+MUvAY2NqYjY8faOw8MjjEJDIRajhR5RPZoDymzO\nx2arxt+/J25unsdd16H1GRuzKDPV0+iA+Ih43MSMyWTE7Awhz2jDV/nS0a8j4d7R5GR6IwI9ehz+\nEtESDoeR2loTtbURxMcfHm82F2CzNeLtnYCXV7tjlrM6rK7boBw+HMxzUG9wJzSmlo7t/Ju/eLSU\niFBVVUVhYSFdunT5dQu2xqCrqc99Nluj/PTT67JqVTtZtw559dVxkpi4UYKCRKbNaJCHPnpPev63\npzAH8f6Ht0xfMF2WHFgiVru1tYv+u9XX75PMzD/JTz/1aaqGVbJz5xgxm0uk3lIv9y25T5iDdHqt\nk8z8eqZUGSvFbm+QRmujVFYul3XrkI0bAyU19UbJzf27FBX9TywWV/Wo3d4odruxeVsmS4VUVq6Q\n9Ip0eWTlI7Jz10RZt85ddu4cLRkZL8nbb2dIVtaJSuqqXr1vwZMSGFMi3ad/JHd93kVW/4AsXx8t\nNludVBgr5C/f/0XMNrNUVa2S5OQhUlT0joiIVFXZ5MMP7fLxx66qwe7dRXJzD6/b6XSK3W4Um80g\nIiK1plqpMdXIF/Md4u4uMny4iNnsmvfPb38vKLtcckWlOJ0nLu/63PXCHOQfG/5x4uNvqZcOr3aQ\nvm/1Per/KakoSZiDfLDzg+ZxDodFrFZXU0BNzUbJypotZnOJiIjYHDYJu3uGBHXKOqpK+veqrBS5\n6y5X1WhcnMjXX8sx+5ycLHLVVa55OnUSsbtqc8VqFUlKSpOUFKckJYns2iVisRxezuEQycwUSUoS\nqaj47WW02xukoSFVDIYkaWhIk5TSHZJdnd083WIpE4MhSUym/Batz+l0Sr2lXnYU75CMij1iMOwU\nQ/1e2V2yUwrrCo/6O9XWiuzeLWI0/sIKj6OxMUsMhuSj3h8WS2lTOfPE2XSQjRaj7K/YL9WN1ZJZ\nlSlJRUlHVaHX1Tl/8X+wJfualpZ2zHh+oZpah7F2SpnNIt98Y5KXXnpDvvkmpimEx8o112yQex+u\nlllvfiEj3h0rao4S5iAjPxwp7ya/KzWmmtYu+lF2FO+QP6/+s1QaK084T0NDmpSUfCxZWbNlz57L\nZcuWTlJZuVxERCorl8v69d6yc+coKSj4j5jNxSIiUt1YLfFvxIuao+SxVY+JyXZsG6fDYZOqqu8l\nPf1O2bw5urlNtb5+t4iIFBa+1RTWAbJ1axdZt85d1q1D3tr6T2EOMuytOPnvV2uk8QTNiWUNZfLa\n1tfkre1viYiI1W6VgOcCpOMLfWTwu4Nl0rxJ8th3l8qK7deKiMjHuz6WxNeQT1eGNrU3d5R33lkg\npp8VfdMmkXHjROrqDo/LqsqSiXMnSrHBtf8Pr3hYmHqDoOzi0flH6fxiogx5d0jzh+STcxrE11ck\nPf3Ef5s//1mk+xWLxe+f/lJkKDruPLNXzxbmIJvzNh813ul0Ss//9JIeD86WvXtPvI1DFqUvEuYg\ni9O/PfnMv8GPP4r06+f6JL7ySleQpqSITJ7sGhcSIvLssyI1P3t7pKWlidMpYjCI5OcfDvLKSpGs\nLFcQl5Udu70jlTeUn/T6C6fTKRZLudQZdkhdXZI0mF3pbrPVicGQJEZjRvPfrqUMpnIxGJLEYEgS\nu90kjuNco+B0uo7Fr1Vfb5X6+t3S0JAiTqdDnE6nGI0HpLEx86hyGq1GSSpKkqSiJNlVsksK6grE\nbDP/+g3+gl8bxrqaWjsl9uypY/Xq1TQ0LGPgwGUMGVJJUdFocspf5mD7PA5cMotFFWlQAf2i+zFn\n7Bxu6ndTm+vAvdpUzVNrn+Kd5HcQhJEdRx511eghBkMyO3e6rlxVygs/vx4EB1+Eh4erZ6/Q0EsZ\nPdrYfFWqiGCxwMH9oVzbazqXJ1zG1vmjueTv8MYbrg4QDnFz8yAs7BLCwi4BXP3zWq3leHm5uhgL\nCrqQLl2ex2Yrw2otJyrqBsLDpzAmaCh9Y0Yz882XefDhC/nvuI1sW9yfYJ9grA4rSzOW8smeT1ie\nuRy7085VPa5i1pBZeLp7Uv/X+ubtJyW52pHHf+x6fXlsEJ0GQKWlhkWlXTm4YBffLQoiMhKmTj1c\n7pEjYc0a19XCjY3w/Id7edM4FoDc2lxiAmMISJ+FWtydjv0OMvHpr2ggEYvd0lxd+o+n/bnjZuh6\ngn+LwkLX8bpy+sXkiY0n1z7JR1d9dNQ8+8r28dq217hz4J2M6DjiqGlKKW7ueT9Pzr6RB9Lr2bjm\n2KtzD2lshOWfd2Z0p0uYnHD5Cef7PYYPd/VE9Z//QFWVq0q2oQG2bYN//QsefNDVM9XxKAWBga4B\nXFXThYWuLiljYw/3SHciNqeNykZXs9CJuopUSuHuEcbB6iIifLyI8QrH6bRjseTj5uaLr2/XX92M\nFOAdjlVZcHcPxt3d54T7ppRrnywWV6cuJ2O1wv79nnTo0Bk/v0wslkJ8fDri69uteV8O8fP0o1tY\nN5ziJMQnpG08BvVEKX26B31mfHZzOp1SUpIm8+f/W957b6x8/72HrFuHrFgRKl9+N0GeXHKFxLzc\nTpiDuD/rLhd/fLG8vvX1o66GPR1sNpHNm0XmzBGZP//XLfvRro8k4qUIcXvWTR5e8bBkVGYcXq/D\nJjU1m6S4+H0Rce1/cfH70tCQLg6H7bjrS08XeeUVkSumV4tfXIZ4eDgFRHKaDsGXX4rExrqqd19+\n+bedCfxcSYlIbJxDAiOrRT0WI8+se0ZERG5ffLswB4l5OUZmr54tKWUpJ1zHJ5+4zsruvNN1hpKZ\n+Yjk5f1bFuxeIG49lgiIPPviia/wdjqdMuX+jQIiYRd/IgfKD1f/zZsnMmFCy6ofP/5YpKDg6HH3\n3y/i4eGqCp+9era0e7md1JqOrj/+06o/SfiL4Ses1ShvKBe3Sx8XENm48cTbf+YZ13H48ceTl/VU\nO1GtxiHHO+sScf3/19e3bBt2h112leyS/RX7TzpfkaFI6i2uFTscNmloSBGH49SeSYqI5ObmSp8+\nfUREpLKyUoYNGyu+vv5y//0P/OJyzz33nHTuHC8dOybId9+tFJMpTwyGpKPKmJOTI0OHDpX4+Hi5\n7rrrxNJUt79hwwYZOHCguLu7y8KFC0/ZvpyWampgEnAAyAIeP87024AKYHfTcNfJ1qnD+OxkMKTI\nDz/8Qb79tktz9em8ef3kvx/eJQ99cY2EPh8kzEECnguQaxdcK3P3zJWqxqrTXq6PPhK59lqR4GBp\nvo3kqadc0xobXcHyxReuarwT+eOKP8qID0bI7pLdzeOcTqes2Pe8vLPET9atQ7Zu7SIOR8vatOfO\ndbjKElgkXj2+lxn35cr8+UdX41ZViVxzjau8kyaJlP6OOylMJpFhw0T8/FztiMlFyWK0ulJvR/EO\nWZG5Qmwn+OLwc0895SrTCy8cXvfll7vGdbjheSmtP3FBX9v6mvA3d4m/zBXckyeLHPm51JJazeJi\nkYAAkQsvPNymnJfn+uJy772u1wazQerMdccs63Q6T/qlb+q8m8Q9qFRGjDh+22Benoi3j0Ound6y\n43WmnSiMf63S+lJJKko67nH8Jb+2arqljgzjhoYGWbVqkzz++Nty++0nDuPU1FTp16+fJCWZZc2a\nHOnatavYbFYxm4uOCuPp06fLF198ISIi9957r7z11lvN29yzZ4/cfPPNbTuMAXcgG+gKeAF7gN5y\nbBj/92TrOnLQYXx22b9/myxceJWsW4esXOkjL700Rf7693/Kda//QQKfcwVwyAshctvi22TJgSWn\nvP3lEIfDJjU1P8r69W/Ihx8evphk6FCR9u1F7rhDZMECkerqwxe87N7tansDEaVEhg2zyZNPiuw5\nUCSr13rKus2dZPfuCZKadrvk5MyRurqfRETEYNglO3eOknXrkK9XKblrXohkVOz7xfKtXu06o1uX\nu06GvDtU+FO0XD3/ailrOHEDntMp8s47rvD5pTO1k5k1y7WPX3/929dxZJlmzHCtb+FCkYwMkchI\nkf/97/AHsdVulX1lxx6P6sZqeX3r6+JwOuTttw9/Odqy5deVYeFC13KzZrle33OPiJeXq430SDaH\nTbKqsqTSWCn5tS27mKjYUCxv/NciILJ06bHTp1/nEDwaZfJbs35doc+QUxXGDqdD9pTukbTytOMG\nbK2pVqobq08YvnPnzpUhQ4ZI//795Z577pGDBw9Kt27dpKKiQhwOh4wcOVJWrVolubm50qNHD7nx\nxhulZ8+eMm3aNDEep3rkyDA+5LnnPpLrr3+g+f38c88995z87W/PSVKS630/YcIE2fKzfzan0ynh\n4eFis7m+XG3ZskUmTJhw1Dy33nprq4ZxS9qMhwJZIpIDoJSaD1wFpP3+SnKtLWtsFFas+J76+hfo\n3HkdXl6h/LD+L/xkCmWr/8s0yFLCLGFM730t0/tMZ1yXcaetK0qbrYoDB+6huvoHnM46AOLiZlNW\ntojo6MtZtsx1G8fxmq/694eKCkhKMpKV9Qx2+3buunstHzXOZNogG4P92lFWWE1o6B68vMpobAyi\nT5+hKOWB2XyQbt3+Q5m6gEWfXcnyTyfywy0/HPOEmIoK15Nu5s2DgQNhStx6ShqK+fTmf3NTv5t+\nsV1NKbj3Xpg+/fBtKMuWwf+3d+fhUVRZA4d/NwtkY0kIS0ggYcdA2GQVARFBQIQBI6I4woAiMM4n\nuIGOIiAqCCI6IqKsrhFRAZURFIFRRPawg5CQBMKaBEgge/p+f9w0WSEJdOikOe/z9FPd1dVVp6ur\n63R13bqnZ8+iS9bl9swzZtm5z+NeL6Vg8WKIjjbXIIeGwpEjUKUKWK9rnbR+Eu9tfY/lDy6nilsV\n3tr0FmGhYXi7e/N0x6cBGD3aXJ7yyy+mP/GSCA2F55+HmTNN/9PjxplzrHXq5J1u6LdD2Ra7jc51\nO/PjXz9y7OljeS4HK4xfJT/GjIJvv9ZkZOT9bH77Db5e5gTdZvDk3X1KFrQ9jBsH4eHX9VInINiS\nCShU7uvUW7VCv/MOJxJPoNGFVjk7ePAgX331FZs2bcLV1ZWxY8eyceNGJkyYwJgxY2jfvj3BwcH0\n6tWLqKgoDh8+zMKFC+ncuTMjRozggw8+4LnnnisyRm9vc+743DmoVfCqJGJjY2nQoCOurmb7DAgI\nIDY2Ns808fHxVK1aFRcXk/IKm8beipOM/YHjuR6fADoUMt0DSqmuwF/AeK318fwTKKVGAaMA6tat\nW/JoRanTGnbsyGLt2u+oUWM6DRvuwMmpNgcOv84m57N8qd6isndlhgQ/yIPNHqR7UPcSX4d3Necu\nn2Nj9EZqeVTmtkoZnI37kRVHfuNQZhs8nDzolrWTnX8OYteuexnQP4Tu3edSrZppoOPlFYPWta/a\n+UBi4lqUGk2dOseIyLgN1xd8CQhszsge4ez9pSUvTzE1XV1d03ByyqJqVdi3rzkdOkQSEeFCVSdY\nP2wD93zag25LurFz1E78K/ujtenofvyzmSQmah4cE8Ens5uS5fQ8L3WbiJtL4Q1UCmNNxIcOwf33\nm0ZdX3wBjYroLvjQIZPwGjY0N1txczNF4a0NhKrky2/jOo7jp4if6B/WH4WibpW6nL50mqCqQXmm\n697d3K7HG2+YUn1jxpjrZocNKzjNqDajWLZ/GccuHOOFO14oMhFbbTv9B6dDR9Ci22rMH3+GmxtU\nb/0nLr0/o0+jl68v8HIkf8cfVolpiaRkphBUNajQH5Pr1q1jx44dtGtnGjKmpKRQo0YNJk+ezNdf\nf82HH35IeK4fCXXq2YxCfQAAIABJREFU1KFzZ/N9ffTRR3nvvfeKlYzd3MyP0osXoWbNwn9w+/qW\n/JrkssZWram/B77UWqcppZ4ElgIF6pRprT8CPgLTA5eNli1sZNeuDD755DNat57OHXf8xcWLjUjL\nmMvuKqeYefB1MrIyGNdxHC93fdkm5Qi11qw4tIL1UetZH7We1m776OILPl6KvUqjnNzJTHdjY0wS\niWeq8eGsA1DvV56fFs1Tg4OJS57CF/tX8mjIw+zZY1q7Nmz4Nj4+915ZRkbGBY4e/RdnznyGu3sT\nYj1e4PH/vsVzdz3HGz3ewNXZlZaPmmLqFy/C7t0V2bXLJDhzpO3C1KnmiLdy5eY0bnYMp9rhbPCr\nzdChsGpjNCNGBEKdP/Ea9ix9HhuNm1tTwPO610vTpvDttzBiBLRqZfoz9vODsDDTI9HWrXDmjBl3\n6ZIp2D5xIrzyyo1+IgVVvUbZ55peNdk4fCNDvx2Ks3Jm0YBFNi9T6eJijsz/+MO838L0qN+DB4Mf\nJPx0OJO6TSr2vOtWqcuRhCPM/3MJjU9O5bHHTI9Nvg2PETfgDiZ1nHTVRFWmzJlzw7OwWCzEJsXi\nWcHzymd4Ou4wFZwrXPUz1VozbNgw3nzzzTzjk5OTOXHiBACXLl2iUvavufwJXSnFli1bePLJJwGY\nOnUqLVq0KHRZlSub3tOUgu+++44pU6YAsGDBAmrX9ufEieO4Zf/uPXHiBP7+/nleX61aNS5cuEBm\nZiYuLi6FTmN3V/v/2noDOgFrcj1+EXjxGtM7AxeLmq+cMy47Tp5M1dOnz9dffBGk169H//hjax0R\nEaYX7vhY+83y00xGhy4LLdCvbElZLBa9PXa7/mr3PH3ixDy9f/9QvfBHd+3xurvu+UlPHbahnd7w\nZ1t9NOJlnZDwi05MTNELF+Y0+Dl0SOvMrKwrjZDe+N8bmsnoLovu1NuPzNGbNzfQ69ejd+/urS9d\n2q+1Nh1kbNnSTO8//OyVaxrzX3talL17tf7oI3PusmNHrd3dtW7eXOs1R9eYDkse76knrn3Jpn1I\na23OjY4apXXPnlq3aZOzHoYNyzkPa+004tQpmy663MmyZBV6zXZR7vv8Pu39+MMatJ4xQ+vnn9d6\n2k8faKcpTsU+/2wPtjpnbGWxWPT+s/v1ntN7dJYlSyelJeltsduu2VBv//79umHDhvpM9gXN8fHx\nOioqSj/11FP69ddf15999pm+7777tNbmXDBw5VzuyJEj9axZswrMs7BzxosXL9b//KdpwJWRofOc\nO87K0nrFin26WbMWOjU1VUdGRup69erpzEJOMIeGhuZpwDV37tw8z9v7nHFxkrELEAnUI6cBV7N8\n0/jluj8Q+LOo+Uoytr/k5BS9ePF/9LJlAXr9evS337bXUVE/6LVH1ugW81poJqM7LuioN8Vc/7Ud\nFotF7zy5U0/8eaKu/2597TUNHfZfJ71+PXrTplp6y84+OjmtYIcfP/5oeh0CrXcU3o+/zrJk6YU7\nF+pqM6ppl6kuesLa8frIsTf0//5XRW/c6K4zMi7ojKwMPWHts9r3LV+b7VwzM01r36HfDNX/t/r/\nrrnDKg2nT2u9ZYvWK1dq/fHHWkdF3dTFO5TvDn6neRXdtHX8lQZ+27dbirzcx95snYy1No21tsVu\n02cundEXUi7oA2cP6Mysq7SayhYWFqZbtmypQ0JCdJs2bfSGDRt0hw4driTDgQMH6kWLFl1pwDV0\n6FDdtGlTPWjQoGI14AoMDNTe3t7a09NT+/v76+XL9+vYXP28JCSYDk7+/e9pun79+rpx48Z69erV\nV57v06ePjs1+QUREhG7Xrp1u0KCBDg0N1anZzfS3bt2q/f39tYeHh/bx8dHBwcHXvQ5zK61Lm/pi\nzgVHAP/OHjcV6J99/01gf3aiXg80LWqekoztJyPjsv7hh9n6u+/8si9N6qy37/xeL921RN+x8A7N\nZHTQnCAdtjfsui5hMJVYzOumbZx25Vrjez/tpX/4rZVev8FFJyT8WmDeyclaz5yp9e23my3ztttM\nr05FOXf5nB65cqRmMvrJ75/UaWnndGTkJB1x6kfdZVEXzWT06O9HX9eRk3Bs6ZnputasWvqOV8x1\nxyNGlM4lO7ZWGsnYYrHog+cO6vBT4TrLFhe951LYEe/1OHJE6507zRGy1lofPqz17t3Fu1zuZiuV\nHri01quB1fnGTcp1/8Xsv69FGWaxZLBt2/ucOzcdL6+zHD7cnUu8zTafzTy19u9cSL1A42qNmXPv\nHEa3HV2iaiVam/qpy/YvY9n+ZcztO5ce9Xsw8LaB1PSqyd+a/o1q7t5ERU3F1XU43t6mRc+pU6bh\nVJcuppHG7NkQEGB6WXryyeJVbfH18GVB/wX8o9U/CKwaSIUKvkSr7gxcOpD0rHQ+H/Q5j4Q8cr2r\nTTgwV2dXpveYTqWKlZhzP7xx+BFe+bUhr939mr1Du+mUUvhX8udw/GEupF2w+fl/W6hdGw4cgLNn\nTYPHxEQzrpzXkgGkatMtIzb2D7ZvH02VKnuJiLiHE+mhbKr6OZt3P0IF5wo8cNsDjLp9FN0Cu5Wo\ne7vL6ZeZ+cdMlu1fxsG4gzgpJ+4KuutKC+vg6sEEVw9Ga1PirF69KVy4APPnm4Y5GzaYhjnHj4Oz\ns/miXavR0LXk7vpw9ubZ+Hn5sXzwcoKrB1/fDMUtYVgr00T72PljrFz9Fa0CXrVzRPZTqWIlqntU\nJyMrw6bzDQoKYt++fTc8Hw8Pc6nTmTOm+0swLakdgSRjB5eensAvv0zEw+NjUlPrsGz9G/xQZT6J\nTqNp7N6YWT1nMazVMHw9ir9FH447TPTFaHo16EVFl4rM3zGfpr5N+Vf7f/FA8APU8MzbKW56ehx7\n9/alQYO3SUzsQvfuEBlpLkWYNAkeeijnkoTrTcT5fTLwEzxcPUrtumfhWGITY2n2gamXPbLNSDtH\nY1+BVQPtHcI11a4N58+bo+E6dUp2LX5ZJsnYQWmtCQ//jJMnn8XNLYGVa0byUWI46bUmERocyujb\nl9I1sGuBo+DExG1curSbmjUfLdCJu0VbmLR+Eq//9jpBVYOI/L9IXJxciPi/CDxcPa4Sh4VDhx7j\n0qXdODt7EBUFKSmwfj1061Z6fy8V1kmBEFezMXojKZkp1PeuT0DlAHuHI67B3R2aN+fKpUyOQpKx\nA4qPP8TGjWPw8dlAdEw7Zm/txumGXzP6rscZ1/E76lSpU+A1FksaUVFTiImZAViIjn6N+vVnULPm\nEABSM1P5x8p/ELYvjBGtRvDa3a9dSeRXS8QAMTEzSEj4L0FBH1Cp0u107Wo6byhOFRYhbpZBtw3i\nweAHee6OojuhEPbnaIkYJBk7lMzMRH5ZNwMX55m4unry9lfD2VJjK+NHtGF024/wdve+6mtPnVpA\nTMyb1Ko1Al/fgURHTyEl5TAAyenJ9PzsHv44vpkZ98zg+TueL9Z55QsXNnLs2Mt4eQ2hZ8/RTJwI\nI0dKIhZlj5uLG8seXGbvMMQtrBx3HiasMjMvsmfvFNb+XBe3im+wfnMvJv52N/0fv4OYV3bwYpcX\nC03EFksGyckm4fr5jaJly3U0bboQX99+tGmzlbp1TQP5yxd/4tmgGL4bMJUXOr9Q7AZeZ858gatr\nQ4YN+4izZxXNm9vuPQshHE9UVBTNs3cU8fHxdO/eHS8vL5566qlrvu7NN9+kYcOGNGnShDVr1hQ6\nzbFjx+jQoQMNGzbkoYceIj27Bdj//vc/2rRpg4uLC8uXL7ftGyoBOTIuxzIzLxIdM5ujEbOp6HqJ\nXbvu479RwfzfP+9gasj9OOfu+D2fy5cPcOjQMNLSYgkI+Is9e7zYvftuwsPh5ElYtUqxL2kzW9YE\ncSFac+edFjwuTCIsbAsxMa8xcmQLqlW7+vwBPDw+5KmnznHiRCXWrjWd/QshRHG4ubnx2muvsW/f\nvmu2xD5w4ABhYWHs37+fkydPcs899/DXX3/h7Jx3/zRhwgTGjx/PkCFDGD16NAsXLmTMmDHUrVuX\nJUuWMGvWrNJ+S9ckR8blUEbGBSIiJ7HhN3+Ox0xl+9a7GTftM3zbPMdv82cwuOXfCk3EWVmwb18W\nK1bMYvv2NqSmRnHkyH8IDPTi/vvh5Zdh1y5zPubrg1/S89OeLPp9NcuXP8DTTx/liy/epFKl32nf\nvg2xsYMBWLkSfvllMPv2/Z2jR58jJmYmR46MIz7+GN27KyIja7BmjSRiIRzRZ599Rvv27WnVqhVP\nPvkk0dHRNGrUiLi4OCwWC126dGHt2rVERUXRtGlThg4dym233UZoaCjJycnXnLenpyd33nknbkWc\nIF65ciVDhgyhYsWK1KtXj4YNG7J169Y802it+fXXXwkNDQVg2LBhrFixAjCXXbVo0QInO1eZkCPj\nciQzM5HomJlExbyNMyls3nQ/n4dNoOdDldixJgRnZ0VGxnnS0mJISztFevppzp49xYYN9Vm16iG2\nb7cwf34DatWKJj39b3TqNB9v7xq8/35OQYJKlTSTN0xmzLqp3F3vbr55/mGqugF4ABPJyBjFqVPL\n8PAwnay/+abm0UdjiY8/iY/PGVxdU7KjtfDUU+/RsSN07GinFSbEreKuuwqOGzwYxo6F5GTo27fg\n88OHm1tcnKlXmduGDUUu8maVUCxKbGwsHXPtZBy5hKKwM60tnD69lAN/jcdZX2TT1u588tFsatSr\nxS8/1SQgwJzDTU6+xB9/NMDF5Xye1yckPMTFiw/x6KNOeHndS+XK3QkJeQhXV4Vv4Fn6PnKZet71\nSEpLIujd5sRcjGFEqxHM6zevwHW6rq4+1K07+srjjRsV69Zt4rvvYOVKzeXLSQwefIFFi+owblzp\nrxshhH3crBKKtwpJxmVcYuI29hwYSWbqXg7F1OE/0//L2bjWfDyvIg88YJJwSkoEu3fXZ8QILzw9\nw/APOE+XXu506wup2otej1Ulu+IYq48M4MeTO5j6zUB2nNrBicQThAaH8vWDX1OpYiX6NOxDx4CO\nDGs5rFgNtSpWND+6+/aFDz9UbNpUGXf3yg7RPZ0Q5ca1jmQ9PK79vK9vsY6E89M3sYRibvlLKPr7\n+3P8+PErz5fXEoqSjMuo9PSzHDryHPFnP+V8qgsfL36dNcsnEnTX/2g8ZiBTz51k4ntJ9Kh2ltBa\nqcyauYikpMdw7vMzKyvPYuVZYImZVxu/NuxosAOAV9a/wq5Tu2ji24SugV253e927qx755Xlftjv\nw+uO2dkZuna9gTcthCg3evTowYABAxg/fjw1atQgISGBpKQkZs2axdChQwkMDOSJJ57ghx9+ACAm\nJobNmzfTqVMnvvjiC+688046dOiQ5+g5KiqqyOUOHDiQgQMHXnns7u7OI488wjPPPMPJkyc5cuQI\n7du3z/MapRTdu3dn+fLlDBkyhKVLlzJgwADbrAgbkWRcxlgsGcTGzuWviJfQlhSW/9mJz6b/gKdH\nFVatcuKsfyRf7M2gmYcvvaueoLrLZSLi7qBRo74sWwa/n+lOXHIIbi5uVHSuiJuLW54O378d/C0+\n7j5UqljJju9SCFHeBQcHM23aNHr16oXFYsHV1ZXZs2ezbds2Nm3ahLOzM9988w2LFy+me/fuNGnS\nhLlz5zJixAiCg4MZM2ZMkcsICgoiMTGR9PR0VqxYwdq1awkOztvXfLNmzRg8eDDBwcG4uLgwd+7c\nKy2p+/bty4IFC6hduzYzZsxgyJAhvPzyy7Ru3ZqRI023p9u2bWPgwIGcP3+e77//nldffZX9+/fb\nfoUVQZmqTjdf27Zt9fbt2+2y7LLqwoXf2XNgGJb0SLad9mThu2Ec/rMfLi2/5q23Uxjf4zEAjh2b\nT2Tk/2GxVKZlyw+oUeNBO0cuhLiZDh48yG233WbvMIotKiqKfv362aRYRHlR2GeklNqhtW5b2PRy\nZFwGaK2JinmHY5HPcSZVs3DNQ2yc9ylUuAQPhtKt3wXuaz6VtLRT/PmnH+++60+rVv1ITp5Hz541\nil6AEEKIMk2SsZ1ZLGn8uXsI6RdXsPm0B4tmbSJyZytq3rGAjg+/yj9aNaSW60lOHuzM4jUvMX36\n6zRo0I+nn+5Ht272jl4IIYpmqxKKjkySsR2lpsaybktnPHU0YX/cxadv/ADak449TvHKs+PxcL+E\nJT0ZjypdsVjGcPx4H958E/71L/D0tHf0QgghbEWSsZ1EnV7N3v0DcbFkMuX9d6jmqvjPfzryr6c2\nsX2jH1/5f4q/fxCDBoUQEmIaI3TqZOeghRBClApJxnawJvxpVMJ7JF7wZfLE/zLooVn0uecrIqJ7\n8+WXTvTsCe7uf7N3mEIIIW4SScY3SWJaIq9tfJWmTuto4LKX7bu78t4783hjxnAC/LYRGPgK3bpN\nRinpLlwIIW41sue/CeKS4+j/aXsCkj6ggctevvrqWT7/5GcWLvw31X32sXTpVwQGTpVELIS4pdmj\nhGJaWhoPPfQQDRs2pEOHDnk6HrnafEeMGEGNGjWuxGoLsvcvZScuHmfCt02YEHiEhu4VmPHWJ9Sr\nN4Nvv63ASy/9hwkTfmfUqMHYuWCIEEKUKdYSikWVNsxdQvGnn35i7NixZGVlFZjOWkLx6NGjeHt7\ns3DhQgAWLlyIt7c3R48eZfz48UyYMKHI+Q4fPpyffvrJpu9XUkApOnRyHSs21ufvAQnsDe/B1Nd2\nMO21CO66ayC9emXx118BfPhhG2mYJYQolxyhhOLKlSsZNmwYAKGhoaxbtw6t9TXn27VrV3x8fLAl\nOWdcCrS2EBUzm5iICQRVcGHZsvFU9a7O3P+MISnpVw4eHEZCQhZr1zpLnV8hxA0Z99M4wk+HFz1h\nCbSq1Yo5vedccxpHKaEYGxtLnTp1AHBxcaFKlSrEx8cXa762JMnYhpKTjxIf/z2R0TPQmWfYeag5\na77+N6+++jAAGRkBNGjwDs2bP02HDoo2bewcsBBCXCcpoWhbkoxtQGtNVNRUoqMnZz+GNZt7MuPf\naxg//hKnT//KunUtSEqqxtKlpuygr699YxZCOIaijmBLi6OUULS+PiAggMzMTC5evEi1atWKNV9b\nknPGNhAZ+cKVRLwrzpVH/u8H3np5DbVqKd55pxIPP9ydFSuqoTVER9s3ViGEsIUePXqwfPlyzp49\nC0BCQgLR0dFMmDCBoUOHMnXqVJ544okr01tLKAIFSiiGh4fTv3//Yi134MCBV17Ttm1b+vfvT1hY\nGGlpaRw7dqzIEopAnhKK/fv3Z+nSpQAsX76cu+++G6VUseZrU1pru9xuv/127QiysjL0b1va6vXr\n0cOfelzjdUp7emXpV1/Vuk8frWfN0jo8XOusLHtHKoRwFAcOHLB3CFprrcPCwnTLli11SEiIbtOm\njd6wYYPu0KGDzszM1FprPXDgQL1o0SJ97Ngx3aRJEz106FDdtGlTPWjQIH358uUC8zt27Jhu1qzZ\nlceBgYHa29tbe3p6an9/f71///5C45g2bZquX7++bty4sV69evWV8X369NGxsbFaa60jIiJ0u3bt\ndIMGDXRoaKhOTU3VWmudkpKiQ0NDdYMGDXS7du10REREkfMdMmSIrlWrlnZxcdH+/v56wYIFBWIq\n7DMCtuur5EQpoXidsrJSOX/+V/6Kfpf0pLV8vPgVvvhkMj4+8MsvTrRube8IhRCOSkooln1SQvEm\n2H1yM/v2DaC26zmUgg/mv87yZROpXduJzZuhbl17RyiEEKI8kXPGJbD95HaGfNWHP3fccSURvzd3\nNt998yJenk78/LMkYiGEyE9KKBZNknExTdkwhT5L29Gv8loaeYEG9qUNYOvmcWiLYsUKCA62d5RC\nCCHKI0nGV2HRFr49+C2R5yMB6NOoD8+2aIGfmwUNXKr4IruWrSA2VrFwIdx9t33jFUIIUX7JOeN8\n0jLT+Hzv57y16S0Oxx9mYueJvHrnWNb89Q0+WXtAw1szvuTkySHs2weTJkF2T2pCCCHEdZFknMv7\nW99n+u/TiU2KpXWt1nw1aAnNXdax6c8mVL6YQtPKzrw+7WuOHBnIiRPw6KMwebK9oxZCCFHeyd/U\nuew9s5fG1Rqz5tE1bHxkMUEp0zlz5jP2XEihZVV4/z9ziYkZyJkz0K0bLFgA+TqVEUIIcZ2khOIt\nznqt9ft932fdY+to5hbJzp0dSEmPY0FUBVpWgR07hrB//yji46F+ffjuO9OtpRBCCNuTEoq3mNTM\nVDos6MC3B7/F1dkVpRRJSVvwqNSJCXtceKB2BhXd6tG370ekpipcXWH1avD2tnfkQghhX1JC0XZu\n+XPGH2z7gG0nt1GF01y6tA8vr+b4B83ink97MdjvHFVdXWjU4FsGDarEuXOwfr05MhZCiLLiriV3\nFRg3uNlgxrYbS3JGMn0/71vg+eGthjO81XDikuMIXRaa57kNwzcUuUwpoWhbt/SR8cXUi7z+2+vc\n16A7bgmTiYh4jixLFn9fMZJGLru43TuLOe+8R58+rdi0CZYuhVyfjRBC3LJyl1Bs1aoV69atIzIy\nkscff5zExEQ+/PDDPH8x5y+h+Pvvv9sr9DKpWEfGSqnewLuAM7BAaz39KtM9ACwH2mmty3zH0zP/\nmElCSgIvtaxPevx66tV7jefWPkfk6ZW829KJ338fzM6do4iNhSlTYPBge0cshBAFXetI1sPV45rP\n+3r4FutIOD8tJRRtqsgjY6WUMzAX6AMEAw8rpQr0NaWUqgQ8DWyxdZClIT45nnf+fId/hPQn8/yX\n1KgxhE8ObWHxzjlMb+FFfHx95sz5iNhYxZAh8Mor9o5YCCHKDimhaGNXK+dkvQGdgDW5Hr8IvFjI\ndHOA+4ANQNui5mvvEooWi0WvObpGb939kN6wwVX/sP9j7TxF6cU/1dC//FJRN2y4U1esqHW7dlon\nJ9s1VCGEyENKKOZ1S5RQVEqFAr211o9nP/470EFr/VSuadoA/9ZaP6CU2gA8p4v4m9qeJRS11iil\n0Fpz5MhYMrULXVd+yfB6FelX/SQWywcMGjSGSpVg61bw87NLmEIIUSgpoVj2lbSE4g034FJKOQGz\ngWeLMe0opdR2pdT2c+fO3eiir9vIVSN5df2rKKVo3Hgen5+ohJ9rPP2qn8HHZzAvvTSajAxYtUoS\nsRBCiNJXnGQcC9TJ9Tgge5xVJaA5sEEpFQV0BFYppQpkf631R1rrtlrrttWrV7/+qG/ArlO7WBy+\nGHfLcRITt3Iy6SRzt77D6yGexMUF8dhjH7Nli+Kzz6B1a7uEKIQQDkVKKBatOK2ptwGNlFL1MEl4\nCPCI9Umt9UXA1/q4uH9T28uL617Ex92buyvvZv/+UJbE9aK/XzqVXSyMf/1jdu+uzBtvwMCB9o5U\nCCHEraLII2OtdSbwFLAGOAgs01rvV0pNVUoVr/lbGbH+2HrWRKzhrU73kXx5J26+Y/lu/yL+XseF\n3377G+Hh3Xn0UZg40d6RCiGEuJUU6zpjrfVqYHW+cZOuMu1dNx5W6Xh5/csEVvEn2HUTLm4hTNu5\nhVFBriitmT9/Fm3bwscfS/EHIYQQN9ct1QPXx/d/zKLufyMt9RhplYez78QK7qmVzooV44iNbcC7\n70IR3aAKIYQQNndLJePg6sE0rtYUX9+BvPjHN4xv4oqLS3XWrHmZLl3gjjvsHaEQQty6rqeEYklK\nLV7N0qVLadSoEY0aNbrSAQjAl19+SUhICC1atKB3797ExcVd1/yL45ZIxj/89QMPLX+IuOQ4AgKe\n4pjLcFyT/6CpVwanT7/O0aOV5TyxEEKUIcUtoVjc6a4mISGBKVOmsGXLFrZu3cqUKVM4f/48mZmZ\nPP3006xfv549e/bQokUL3n///etaRnHcEsn4P1v/w8FT/yMz6RcysjJ4Zf0ExtStzNGjLXnmmRGE\nhECfPvaOUgghypeyUELxWtOtXbuWTp060aZNGx588EEuXbpUYJo1a9bQs2dPfHx88Pb2pmfPnvz0\n009Xesa6fPkyWmsSExOpXbt2yVZQCTh8CcUj8UdYG7GWL7u15vChYUR5nSDEKYbqlZL5fOEcjh93\nZvp0abQlhCifxo2D8HDbzrNVK5gz59rTlJUSilcTFxfHtGnT+OWXX/D09GTGjBnMnj2bSZPytj3O\nXUIRckolurq6Mm/ePEJCQvD09KRRo0bMnTu31OJ1+CPj+TvmE+TpTC12U9PvSWb98TZD62Xx22+D\niIq6i6AgqcYkhBAlVdZLKP75558cOHCAzp0706pVK5YuXUp0dHSxX5+RkcG8efPYtWsXJ0+epEWL\nFgUqVNmSQx8Zp2SksGjXIl5vWQcnp9P8eKYK/dwUTmjOnJnJ7t0wdy64OPRaEEI4sqKOYEuLLiMl\nFNu2LbSrZ7TW9OzZky+//DLP+PzL9Pf3Z8OGDVeeP3HiBHfddRfh2X83NGjQAIDBgwczfXqh1YNt\nwqHTUHpWOuPaDuU253l4V/8HYb+8w8yQy/z55wSOHKlP9erwj3/YO0ohhCh/evTowYABAxg/fjw1\natQgISGBpKQkZs2axdChQwkMDOSJJ57ghx9+AHJKKHbq1KlACUWrqKioIpc7cOBABhaji8SOHTvy\nz3/+k6NHj9KwYUMuX75MbGxsgWUmJCTw0ksvcf78ecCcZ37zzTdJTU3lwIEDnDt3jurVq/Pzzz+X\nanEOh07GVdyq8HTbhzl8+BeWHYfhdS+jnKvRu/e/efFFmDYN3N3tHaUQQpQ/wcHBTJs2jV69emGx\nWHB1dWX27Nls27aNTZs24ezszDfffMPixYvp3r07TZo0Ye7cuYwYMYLg4GDGjBlT5DKCgoJITEwk\nPT2dFStWsHbtWoKDg4s93ZIlS3j44YdJS0sDYNq0aTRu3DjPa318fHjllVdo164dAJMmTcLHxweA\nV199la5du+Lq6kpgYCBLliy5wbV2dUWWUCwtpV1C8eC5gxxNOErfRn25mHqRIe+15aWOx6hXbyEv\nvjiC77+HmBjuMEPVAAAc6ElEQVTw9i61EIQQolRICcWyr6QlFB32yHjWH7PYFf05dwYcY8fJ3Yxs\nmExEZCsqVRrGV1/BM89IIhZCCFE2OGRr6vMp51lx8HOmh2hOx0zkp9X7qel7hgruT7NwoTMuLjB+\nvL2jFEKIW4OUUCyaQybjJeFL6Fk9jQoqndq1n+L4rgwAunS6k0WL4LHHoBSv3RZCCCFKxOGSsUVb\n+HjHXIYGuuLtfQ87drSjhtdp0jIr8NFH9UlPh+eft3eUQgghRA6HO2d8IvEE7aucp5JLBnXrvkiG\nJY0GLddwWddk7lwnHngA8jWmE0IIIezK4Y6M61apy/Nt7sWrUjuqVu0ONfZSP+gQZ0+2JzERJkyw\nd4RCCCFEXg6VjJPSkkjLTCM4+HNatljLxx8r1m/bQRVX2PRrF+65B67SWYsQQgg7kxKKDmLmH28R\nMrculzMuEx1dlTFjIPw3s/L2hLdm5Eg7ByiEEKJYpIRiOZWelc72iPeZ2yIOS+oBZs0CV1cIuP0L\nACIiWtC6tZ2DFEIIByIlFG3HYZLxioPf0bf6BZxdfLl0qTWLF8Pw4Rp3179ISKxBVlZVGja0d5RC\nCGF7d91V8PbBB+a55OTCn7f27BgXV/C54shdQjE8PBxnZ+c8JRTffvvtKyUUAQ4fPszYsWM5ePAg\nlStX5gNrgKUkdwnFnTt30rZtW2bPnl1guuKUUKxduzYHDhxgZCn+veowyfjHvW/SvAo0qvcy773n\nSmYmPDTqOHXdM4mNbUFwMDg72ztKIYRwDFJC0bYc4tKmw3GHaVZxNxl4UdvvcbQ2HXucd9tMXQ9Y\nefB2QkLsHaUQQpSOXBUAC/DwuPbzvr7Xfv5qpISibTlEMq7j4Up7H0XNgHE4O7szYwZoDTM3rKO9\nE+zf15r77rN3lEII4TikhKJtOUQy9vCoT7t2B9Daj02boHNnUAriL26DqqbxlhwZCyGE7UgJRdty\nqBKKH34IY8bA1q3Qrh288FVlelZLpfe9ycTGulCrlk0XJ4QQdiElFMu+kpZQdJgGXJmZMHMmtG9v\nOvaIT46numsSZ+Ia4ePjQs2a9o5QCCGEKJzDJONvvoHISJg40fxFvfvMbhp4QXR0a0JCzDghhBA3\nn5RQLJpDJGOtYfp0aNIEBgww4/ad+g2fCrB/t7SkFkIIUbY5RDKOioLjx+GFF8Ap+x2dSjDXsB06\n1FKSsRBCiDLNIVpT16sH0dGm+0urlOT94CUtqYUQQpR9DpGMATw9c+6nZabhoU+TmFyNpCRfmjWz\nX1xCCCFEURzib+r8Dpw7QD0PzalTIdSvD15e9o5ICCFEUexVQrF3795UrVqVfv365Rk/dOhQmjRp\nQvPmzRkxYgQZGRnXNf/icMhkHH5qO4GeEHFEGm8JIUR5dLNKKAI8//zzfPrppwXGDx06lEOHDrF3\n715SUlJYsGDBdS+jKA6ZjCPObqSCE4TvbCXJWAghSokjlFAE07WntQ/t3Pr27YtSCqUU7du3v9Ln\ndmlwmHPGuV1I2gFucPRoS554wt7RCCFE6TlyZByXLoUXPWEJeHm1olGjOdecJncJRVdXV8aOHZun\nhGL79u2vlFCMiori8OHDLFy4kM6dOzNixAg++OADnnvuOZvGnVvuEoqenp7MmDGD2bNnM2nSpBLP\nKyMjg08//ZR33323FCI1HC4Za61R6ZFkWZyJiWkqR8ZCCFEKcpdQBEhJSaFGjRpMnjyZr7/+mg8/\n/DBPQYb8JRTfe++9Uk3GuUsoAqSnp9OpU6frmtfYsWPp2rUrXbp0sWWIeThcMo66EIW/Wzpx5xvj\n6upKw4b2jkgIIUpPUUewpcVRSij279//msubMmUK586dY/78+UXGdiMcLhlbu8E8fqg1wcHg4nDv\nUAgh7M9RSihey4IFC1izZg3r1q3Dyal0m1g5XKrad/oP7qwIa/ZKS2ohhCgtjlJCEaBLly4cOnSI\nS5cuERAQwMKFC7n33nsZPXo0gYGBV/7eHjRo0HWdcy4OhyqhCPDUt50J9fmD559fw5AhvXj2WZsv\nQggh7EpKKJZ9t2wJRau05IOAdIMphBCi/ChWMlZK9VZKHVZKHVVKTSzk+dFKqb1KqXCl1O9KqYL/\nI9wE51PO4+18nsupVTl/vpYkYyGEKAOkhGLRikzGSilnYC7QBwgGHi4k2X6htQ7RWrcC3gJm2zzS\nYth9Zjf1PeHcuRCqVYNatewRhRBCCFEyxTkybg8c1VpHaq3TgTBgQO4JtNaJuR56AnY5ER1+aif1\nPCEqsg0tWkC+lvRCCCFEmVScZOwPHM/1+ET2uDyUUv9USkVgjoz/zzbhlUzkud+o6Aw7d7SWv6iF\nEEKUGzZrwKW1nqu1bgBMAF4ubBql1Cil1Hal1PZz587ZatFXJCbtAuDgQWm8JYQQovwoTjKOBerk\nehyQPe5qwoC/FfaE1vojrXVbrXXb6tWrFz/KYkjPSqdC1nEs2ono6NskGQshRDkjJRSvbRvQSClV\nTylVARgCrMo9gVKqUa6H9wFHbBdi8Rw8d5BADwvnE+uRkeFGs2Y3OwIhhBC2IiUU89FaZwJPAWuA\ng8AyrfV+pdRUpZS1U8+nlFL7lVLhwDPAsFKL+CrCT4fTwAvOnGpN/frg5XWzIxBCiFuLlFC0nWJ1\nh6m1Xg2szjduUq77T9s4rhLbd3oL97nB5oOmJbUQQtwqdu26q8C4GjUG4+8/lqysZPbs6Vvg+Vq1\nhuPnN5z09Dj27w/N81zr1huKXKaUULQth+mb+uyFzVALtm5tSc+e9o5GCCEcm5RQtC2HSMZaazJS\nDwNw9GgLnnnGzgEJIcRNdK0jWWdnj2s+X6GCb7GOhPOTEoq25RDJOOZiDH4VUkjLqERcnL+0pBZC\niFImJRRtyyGScfjpcOp7QXxCCBUrKho2tHdEQgjh2KSEom05RAnF1X/9gPOJAezePpawsP+wc6dN\nZiuEEGWSlFAs+27JEord69xGRScL4eGtpCW1EEKIcschkvGlS7sB2LlTusEUQoiyRkooFs0hkrFz\nCpB0B1FRzSQZCyFuCfY6xSiKdj2fjUMkY5/tsKf/7aSleUgyFkI4PDc3N+Lj4yUhl0Faa+Lj44vs\nOSw/h2hNjZ8fewmhWuV0atWqYO9ohBCiVAUEBHDixAlKo/qduHFubm4EBASU6DWOkYxr1WIvihC/\neJTys3c0QghRqlxdXalXr569wxA25BB/U1tq+rGP5oT4lF4n3kIIIURpcYhkHHXajct40cLtpldu\nFEIIIW6YQyTjvXvNMOSJjvYNRAghhLgODpGMnZzg9tuh2f317R2KEEIIUWIOkYzvvx+2f3IAr19X\n2TsUIYQQosQcIhkDsGABPPwwyHV3QgghyhnHScZ+fpCcDElJ9o5ECCGEKBHHSMZaQ3YBa06dsm8s\nQgghRAk5RjKePx+stTFPn7ZvLEIIIUQJOUYyrlMn574cGQshhChnHCMZW7uFmzQJ7r3XvrEIIYQQ\nJeQYyTgoyAwrVABvb7uGIoQQQpSUYyRjDw+oUQM2bIDVq+0djRBCCFEijpGMwfxVvXUrzJlj70iE\nEEKIEnGsZJyZKa2phRBClDuOk4yDgiAlRVpTCyGEKHccJxnXq2c6/4iLg4wMe0cjhBBCFJtjJWOr\nM2fsF4cQQghRQo6XjGfONP1UCyGEEOWE4yTjOnVAKbh0CZyd7R2NEEIIUWyOk4wrVoTatWHVKvjj\nD3tHI4QQQhSb4yRjMC2qd+2Cn3+2dyRCCCFEsTlWMq5fH5yc5FpjIYQQ5YpjJeN69cBigdhYe0ci\nhBBCFJvjJWOA6Gj7xiGEEEKUgGMlY2v1JvmbWgghRDniWMnYemQ8ebJdwxBCCCFKwrGSsb8/uLjA\n8eP2jkQIIYQoNsdKxi4uULMmfP21nDcWQghRbjhWMgaoUQOOHoUjR+wdiRBCCFEsxUrGSqneSqnD\nSqmjSqmJhTz/jFLqgFJqj1JqnVIq0PahFlODBmYojbiEEEKUE0UmY6WUMzAX6AMEAw8rpYLzTbYL\naKu1bgEsB96ydaDFdtttZih/UwshhCgninNk3B44qrWO1FqnA2HAgNwTaK3Xa62Tsx/+CQTYNswS\naNLEDOVvaiGEEOVEcZKxP5C7efKJ7HFXMxL4b2FPKKVGKaW2K6W2nzt3rvhRloT18qazZ0tn/kII\nIYSN2bQBl1LqUaAtMLOw57XWH2mt22qt21avXt2Wi85hTcb33Vc68xdCCCFszKUY08QCdXI9Dsge\nl4dS6h7g30A3rXWabcK7DjVrmnKKUVF2C0EIIYQoieIcGW8DGiml6imlKgBDgFW5J1BKtQbmA/21\n1vb9f9jJCXx8ICzMrmEIIYQQxVVkMtZaZwJPAWuAg8AyrfV+pdRUpVT/7MlmAl7A10qpcKXUqqvM\n7ubw8oITJyAlxa5hCCGEEMVRnL+p0VqvBlbnGzcp1/17bBzXjfH3N62pT50yNY6FEEKIMszxeuCC\nnEZcR4/aNw4hhBCiGBwzGVs7/ti7175xCCGEEMXgmMk4JMQMT52ybxxCCCFEMThmMm7b1gwD7NcR\nmBBCCFFcjpmMq1UzLaqPHbN3JEIIIUSRHDMZK2U6/vj+e3tHIoQQQhTJMZMxgLOznDMWQghRLjhu\nMvb1hbQ00NrekQghhBDX5LjJ2N/fJGKp3iSEEKKMc9xkHBRkhrt22TUMIYQQoiiOm4xbtzbDiAj7\nxiGEEEIUwXGT8SOPmOHly/aNQwghhCiC4ybjKlXA21uuNRZCCFHmOW4yzsiA1FTYuNHekQghhBDX\n5LjJ2NUVMjPlWmMhhBBlnuMmY4BKlSAxESwWe0cihBBCXJVjJ+Nq1UwiPnPG3pEIIYQQV+XYybh2\nbTOURlxCCCHKMMdOxnfeaYaSjIUQQpRhjp2MX3rJDCUZCyGEKMMcOxl7eEDNmhAVZe9IhBBCiKty\n7GS8eTPEx8POnfaORAghhLgqx07GlSuba41PnLB3JEIIIcRVOXYy9vMzw/h4k5SFEEKIMsixk7G3\nN7i4mGuNY2PtHY0QQghRKMdOxkqBj4+5Ly2qhRBClFGOnYwBHnjADKVFtRBCiDLK8ZPxnDnmCFmO\njIUQQpRRjp+MK1QAf39JxkIIIcosx0/G06ebS5siIuwdiRBCCFEox0/G1gZckZH2jUMIIYS4CsdP\nxtZrjU+fhrQ0+8YihBBCFOLWScYAMTH2i0MIIYS4CsdPxrVq5dyXy5uEEEKUQY6fjGvWhFGjzP3P\nPgOt7RuPEEIIkY+LvQModa6uMH++ScqvvQYNGsCkSfaOSgghhLjC8ZMxwOXLMGaMOWf86qtQpw78\n4x/2jkoIIYQAbpVkPHAgXLwIv/8OJ0/CE09A7dpw7732jkwIIYS4Bc4Zg2lRfeqU+ct6+XIICTF9\nVu/cae/IhBBCiFskGdeqZa4z1hoqV4Yff4Rq1aBvX2lhLYQQwu6KlYyVUr2VUoeVUkeVUhMLeb6r\nUmqnUipTKRVq+zBvkJ8fZGRAQoJ5XLs2/Pe/phOQ3r1zxgshhBB2UGQyVko5A3OBPkAw8LBSKjjf\nZDHAcOALWwdoE9ZrjU+fzhkXHAwrV5oCEv37Q2qqfWITQghxyyvOkXF74KjWOlJrnQ6EAQNyT6C1\njtJa7wEspRDjjWvXDt55B3x9847v2tVce7xpEzz6KFjKZvhCCCEcW3FaU/sDx3M9PgF0KJ1wSkmD\nBjBuHHzyCcyYUfD5yZPNzc8PLl0y9Y+dnHJujz1mzjHv3Glurq6mNKNS5vV79oCzs7mOOSws77zd\n3ODbb80R+MyZsHevea319T4+8NtvZtp//Qt+/TXv6+vUgZ9+MveHD4c//zQxWZfdpImZP8BDD8G+\nfXlfHxwMzz5rqlZNnQpnzpjXVqgAFStCx46wZAl4eECPHnn/PQDT4nz2bPM3f4cOplV6ZmbOOurR\nA555BtzdoU8f8xqlcuL7+99h4kRISYG2bQuu+9GjzfuOjzc/jvJ75hkYOdJclmadf24vvwwPPwyH\nDplGefm9+ab552PHDvM55maxmKpeXbqYlvYvvJDTKYx1OHmy2X5+/RXmzTOvyX3r3x+qVIEDB8xn\no3XeW7t25rTIqVOwe7fZTpyccobvvQetWsEPP5j557d5s2nn8PbbsGhRwec3bTJxzJ6dsx1Y172b\nm3nfABMmwKpVeWOvVMlsk+npZhvYvRtcXHJen3vbGzECtmzJu+yitr02beDTT839++8vWKzlzjth\n1ixIToZBg+DcubzPd+2a0yfA3/5mtiGnXMcPgwaZ7xyYRpn5f0zf7G3PYjHfDTCf/bhx0K2bWS8v\nv5wzPivLTBsaavY5e/bA6tVmXFaW2TZcXU18vXqZ5b/xRsHlh4WZ9/3NN4X3nbBqldl2r7bf++UX\ns/x58+D99ws+X9S2V9R+z7rtTZwI33+f9/mS7PcK2/aCgsx3p0YNePzx4m97mZnm9GTdumabsFhM\nbCkp5r04O5vvQI8eZp24uhZ836VE6SJ6pMo+B9xba/149uO/Ax201k8VMu0S4Aet9fKrzGsUMAqg\nbt26t0dHR99Y9CX1449mp5PfvHnw+efmKDk62nwhMjNzbkoVXmTC3R08PaFfP2jUCI4cge3bzXXN\n1lty8tV7/XJ3h6pVzcbSqJFJ1JGRZsNITTXDrCyz4cbGwtmzOa+1fmG9vEzC9fbOeW1KivlRcfly\nzs7Bys3NbIDp6XnH+/ub8RUrmkSdmmpuTk4mhri4kvVeVqGCia1xY5PQAwPNl8PLyyzDqk8fs8OK\nijLXgKelmdjS081y69c3HbYkJJh1m5WVszNTysTt52fGHT6ck+ScnMw0gYEmljNnzA+ijAxzy8oq\n/nu5Ficns06dnMx8cy/f2dkk4pQUs/6Skq69Dt3czI8i683d3SSEtDSzY9q9O+dzsd6u9T6cnMx8\nLBazHRaXq6v5jCpXNj9UatY0y05IMM9Ztz1/f3juOfOZvv02HD1qYrXePDzM5xcXZ3aWKSlme8z9\nGZaUs7NZT25u5rPt3Nl8/t99l/MZZGaaYe3aJsbz580PJeuyrT9GKlY0r0lLM+vHYjHz9fQ07+mO\nO0wjz6pVTcdBbm7m80tONp9ls2YmnvBw2LXLvL/rYU0Crq7mlp5e8PNycsqJq2JFs+136GD2DSdP\nmvWb+0dwZia0aGHiPXYMjh/Pu09zdoaAALPfSEnJ+WxdXU0y0tr8QElOhv37TRla63fHuh59fEw8\n1m3RxSUnmVWoYH6g1a5t1s+xYzmfm5OT2bYWLjSxzphhEr/1e5+ebqbr188cHPz3v2aYe7vPzXpw\nZJ2/u7t5bw8/bPabYWFm35mUlPf74u5uXpuYePXPxs/PrF8bUUrt0FoX8suweMm4EzBZa31v9uMX\nAbTWbxYy7RKukYxza9u2rd6+fXvR0ZcVmZlmpxIZaY4yrUPr/dxHlNWrm51QvXp5b4GB5sjyyBFz\nO3o0ZxgXV3CZvr5mZ5L75u1tNp7z5wveEhLMc7VqmV/EDRuaofVWr57ZWAEuXDCx547Bev/iRTOP\n3Dc/v5z7vr5mfVh/MFi/INb7ycnmy2+dZ0xM3iRUpYrZUcfFmS93YZydcxKS9Zb7sZtbTgxpaTnD\n3PcrVDDLqlLFfPnz3/fwKHikmvvm7Gx2NtadYGH3XUp4qX5qqvmMLl40w7g4s6OLiTHrzDo8frzg\nzt3Hp+DnUrOmWRfWnaQ1EeUeKpUTrzX+3EMXFxPHmTNmOz59uuD9a+2wrsbHx3wXqlc3262XV94f\nG9abp2fOTtr6jwLkHVosZps9dcrcTp/OGV68WHDZSuX9zKtUMct3c8v5wZl/6OxsdryRkeZ24kTe\neXp65hxZWVWpYv4haNLE/PCsW9esz9zbUP5tqkoVk+CtNw+PnCRqlZ5uDgwK29/Ex+ccRVt/WFjv\nW5ONl5f558M6zH3fw8O8h8TEgrekJDNUquD3JfewQgWzfVoPOKxD6/2kJLPd5D8YUMpsD9ZGtfHx\nZr91tf2Ai4vZxvNv87Vqmfdy7lzB7eHUqZxtwsnJHEVbPx/rsHFjsz91cjLrOj7efAfy3zIyzD+K\nNnKjydgF+AvoAcQC24BHtNb7C5l2CY6ajIty+bLZCGrVMht9SV24YBJhWprZSGrXznsEWZ6lpZlf\nxrmTf0qK+VL6+uYMc9+vVKngDupWorXZQZw6ZXbYNWrYd3uwHl0nJZnbpUs595OSzBGGNfH6+ppE\nXNIfKtcrOdnshFNSchKIp2fev7SvR2qq+ccmdzKsUCHvjr16dcfbTq054Ubfl8ViEtrJk4XfKlQw\n20m1ajm33I99fc3wej5H679R9v7e5HNDyTh7Bn2BOYAzsEhr/bpSaiqwXWu9SinVDvgO8AZSgdNa\n62bXmqfDJWMhhBDiGq6VjIv101VrvRpYnW/cpFz3twEBNxKkEEIIcau6NXrgEkIIIcowScZCCCGE\nnUkyFkIIIexMkrEQQghhZ5KMhRBCCDuTZCyEEELYmSRjIYQQws4kGQshhBB2JslYCCGEsDNJxkII\nIYSdSTIWQggh7EySsRBCCGFnxaraVCoLVuocEG3DWfoChRQFFtdB1qXtyLq0HVmXtiPr0jZKuh4D\ntdbVC3vCbsnY1pRS269WmkqUjKxL25F1aTuyLm1H1qVt2HI9yt/UQgghhJ1JMhZCCCHszJGS8Uf2\nDsCByLq0HVmXtiPr0nZkXdqGzdajw5wzFkIIIcorRzoyFkIIIcolh0jGSqneSqnDSqmjSqmJ9o6n\nPFFKLVJKnVVK7cs1zkcp9bNS6kj20NueMZYHSqk6Sqn1SqkDSqn9Sqmns8fLuiwhpZSbUmqrUmp3\n9rqckj2+nlJqS/b3/CulVAV7x1peKKWclVK7lFI/ZD+WdXkdlFJRSqm9SqlwpdT27HE2+Y6X+2Ss\nlHIG5gJ9gGDgYaVUsH2jKleWAL3zjZsIrNNaNwLWZT8W15YJPKu1DgY6Av/M3g5lXZZcGnC31rol\n0ArorZTqCMwA3tFaNwTOAyPtGGN58zRwMNdjWZfXr7vWulWuS5ps8h0v98kYaA8c1VpHaq3TgTBg\ngJ1jKje01v8DEvKNHgAszb6/FPjbTQ2qHNJan9Ja78y+n4TZ8fkj67LEtHEp+6Fr9k0DdwPLs8fL\nuiwmpVQAcB+wIPuxQtalLdnkO+4IydgfOJ7r8YnsceL61dRan8q+fxqoac9gyhulVBDQGtiCrMvr\nkv23ajhwFvgZiAAuaK0zsyeR73nxzQFeACzZj6sh6/J6aWCtUmqHUmpU9jibfMddbBGdcFxaa62U\nkib3xaSU8gK+AcZprRPNQYgh67L4tNZZQCulVFXgO6CpnUMql5RS/YCzWusdSqm77B2PA7hTax2r\nlKoB/KyUOpT7yRv5jjvCkXEsUCfX44DsceL6nVFK+QFkD8/aOZ5yQSnliknEn2utv80eLevyBmit\nLwDrgU5AVaWU9QBCvufF0xnor5SKwpzCuxt4F1mX10VrHZs9PIv5kdgeG33HHSEZbwMaZbcOrAAM\nAVbZOabybhUwLPv+MGClHWMpF7LPwy0EDmqtZ+d6StZlCSmlqmcfEaOUcgd6Ys7BrwdCsyeTdVkM\nWusXtdYBWusgzL7xV631UGRdlphSylMpVcl6H+gF7MNG33GH6PRDKdUXc17EGViktX7dziGVG0qp\nL4G7MNVHzgCvAiuAZUBdTGWtwVrr/I28RC5KqTuB34C95Jybewlz3ljWZQkopVpgGsI4Yw4Ylmmt\npyql6mOO7nyAXcCjWus0+0VavmT/Tf2c1rqfrMuSy15n32U/dAG+0Fq/rpSqhg2+4w6RjIUQQojy\nzBH+phZCCCHKNUnGQgghhJ1JMhZCCCHsTJKxEEIIYWeSjIUQQgg7k2QshBBC2JkkYyGEEMLOJBkL\nIYQQdvb/e6UL5UsWr3YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXHdW2x0AKW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f961039c-d97d-4f4f-b1bb-2481a7744f19"
      },
      "source": [
        "for regulizer_ratio in EXP:\n",
        "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
        "    print(\"Experiment with Regulizer = %.6f\" % (regulizer_ratio))\n",
        "    model = build_mlp_l2(input_shape=x_train.shape[1:], ratio=regulizer_ratio)\n",
        "    model.summary()\n",
        "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
        "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "\n",
        "    model.fit(x_train, y_train, \n",
        "              epochs=EPOCHS, \n",
        "              batch_size=BATCH_SIZE, \n",
        "              validation_data=(x_test, y_test), \n",
        "              shuffle=True)\n",
        "    \n",
        "    # Collect results\n",
        "    train_loss = model.history.history[\"loss\"]\n",
        "    valid_loss = model.history.history[\"val_loss\"]\n",
        "    train_acc = model.history.history[\"acc\"]\n",
        "    valid_acc = model.history.history[\"val_acc\"]\n",
        "    \n",
        "    exp_name_tag = \"exp-l2-%s\" % str(regulizer_ratio)\n",
        "    results[exp_name_tag] = {'train-loss': train_loss,\n",
        "                             'valid-loss': valid_loss,\n",
        "                             'train-acc': train_acc,\n",
        "                             'valid-acc': valid_acc}"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment with Regulizer = 0.010000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 15s 295us/step - loss: 15.0789 - acc: 0.2740 - val_loss: 13.9557 - val_acc: 0.3383\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 13.0133 - acc: 0.3565 - val_loss: 12.1194 - val_acc: 0.3694\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 11.3388 - acc: 0.3814 - val_loss: 10.5866 - val_acc: 0.3937\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 9.9262 - acc: 0.3969 - val_loss: 9.2850 - val_acc: 0.4021\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 8.7267 - acc: 0.4079 - val_loss: 8.1820 - val_acc: 0.4124\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 7.7038 - acc: 0.4177 - val_loss: 7.2380 - val_acc: 0.4249\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 6.8322 - acc: 0.4224 - val_loss: 6.4414 - val_acc: 0.4245\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 6.0886 - acc: 0.4293 - val_loss: 5.7600 - val_acc: 0.4306\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 5.4521 - acc: 0.4335 - val_loss: 5.1698 - val_acc: 0.4335\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 4.9093 - acc: 0.4404 - val_loss: 4.6697 - val_acc: 0.4440\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 4.4451 - acc: 0.4437 - val_loss: 4.2407 - val_acc: 0.4393\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 4.0472 - acc: 0.4472 - val_loss: 3.8822 - val_acc: 0.4461\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 3.7063 - acc: 0.4519 - val_loss: 3.5742 - val_acc: 0.4438\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 3.4150 - acc: 0.4555 - val_loss: 3.3019 - val_acc: 0.4469\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 3.1645 - acc: 0.4596 - val_loss: 3.0641 - val_acc: 0.4537\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 2.9501 - acc: 0.4632 - val_loss: 2.8671 - val_acc: 0.4556\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 2.7669 - acc: 0.4667 - val_loss: 2.6952 - val_acc: 0.4591\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 2.6106 - acc: 0.4691 - val_loss: 2.5551 - val_acc: 0.4620\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 2.4752 - acc: 0.4719 - val_loss: 2.4326 - val_acc: 0.4667\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.3593 - acc: 0.4745 - val_loss: 2.3375 - val_acc: 0.4618\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 2.2607 - acc: 0.4758 - val_loss: 2.2456 - val_acc: 0.4628\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 2.1745 - acc: 0.4783 - val_loss: 2.1686 - val_acc: 0.4660\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 2.0999 - acc: 0.4810 - val_loss: 2.0934 - val_acc: 0.4726\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 12s 235us/step - loss: 2.0371 - acc: 0.4841 - val_loss: 2.0377 - val_acc: 0.4688\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.9818 - acc: 0.4861 - val_loss: 2.0196 - val_acc: 0.4526\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.9355 - acc: 0.4884 - val_loss: 1.9709 - val_acc: 0.4629\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 1.8915 - acc: 0.4906 - val_loss: 1.9111 - val_acc: 0.4732\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.8570 - acc: 0.4918 - val_loss: 1.8720 - val_acc: 0.4780\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 1.8248 - acc: 0.4946 - val_loss: 1.8827 - val_acc: 0.4672\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.7989 - acc: 0.4967 - val_loss: 1.8180 - val_acc: 0.4854\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.7751 - acc: 0.4977 - val_loss: 1.8180 - val_acc: 0.4705\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.7538 - acc: 0.4997 - val_loss: 1.7982 - val_acc: 0.4774\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.7355 - acc: 0.5028 - val_loss: 1.7799 - val_acc: 0.4819\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 1.7207 - acc: 0.5049 - val_loss: 1.7535 - val_acc: 0.4885\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.7071 - acc: 0.5062 - val_loss: 1.7469 - val_acc: 0.4903\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.6944 - acc: 0.5077 - val_loss: 1.7230 - val_acc: 0.4968\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.6835 - acc: 0.5087 - val_loss: 1.7292 - val_acc: 0.4896\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.6743 - acc: 0.5109 - val_loss: 1.7117 - val_acc: 0.4966\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.6644 - acc: 0.5113 - val_loss: 1.7171 - val_acc: 0.4877\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.6594 - acc: 0.5131 - val_loss: 1.7003 - val_acc: 0.5005\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.6490 - acc: 0.5154 - val_loss: 1.7320 - val_acc: 0.4793\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 1.6459 - acc: 0.5164 - val_loss: 1.6964 - val_acc: 0.4910\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.6392 - acc: 0.5173 - val_loss: 1.7088 - val_acc: 0.4857\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.6327 - acc: 0.5183 - val_loss: 1.6844 - val_acc: 0.4975\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.6301 - acc: 0.5210 - val_loss: 1.6926 - val_acc: 0.4959\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.6269 - acc: 0.5215 - val_loss: 1.6891 - val_acc: 0.4933\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 1.6207 - acc: 0.5232 - val_loss: 1.6646 - val_acc: 0.5085\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.6165 - acc: 0.5255 - val_loss: 1.6862 - val_acc: 0.4885\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.6121 - acc: 0.5244 - val_loss: 1.6642 - val_acc: 0.5030\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.6092 - acc: 0.5264 - val_loss: 1.7074 - val_acc: 0.4893\n",
            "Experiment with Regulizer = 0.000100\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 2.1697 - acc: 0.2734 - val_loss: 2.0089 - val_acc: 0.3480\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.9526 - acc: 0.3636 - val_loss: 1.9059 - val_acc: 0.3864\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.8674 - acc: 0.3957 - val_loss: 1.8420 - val_acc: 0.4007\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.8043 - acc: 0.4207 - val_loss: 1.7828 - val_acc: 0.4253\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.7542 - acc: 0.4354 - val_loss: 1.7431 - val_acc: 0.4388\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.7124 - acc: 0.4506 - val_loss: 1.7220 - val_acc: 0.4391\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.6790 - acc: 0.4619 - val_loss: 1.6942 - val_acc: 0.4470\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.6492 - acc: 0.4717 - val_loss: 1.6621 - val_acc: 0.4566\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.6219 - acc: 0.4795 - val_loss: 1.6496 - val_acc: 0.4612\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.5927 - acc: 0.4912 - val_loss: 1.6279 - val_acc: 0.4710\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.5703 - acc: 0.4986 - val_loss: 1.5997 - val_acc: 0.4823\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.5457 - acc: 0.5061 - val_loss: 1.6100 - val_acc: 0.4788\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 1.5254 - acc: 0.5135 - val_loss: 1.5868 - val_acc: 0.4854\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.5050 - acc: 0.5191 - val_loss: 1.5875 - val_acc: 0.4891\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.4830 - acc: 0.5276 - val_loss: 1.5539 - val_acc: 0.5009\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 1.4657 - acc: 0.5332 - val_loss: 1.5476 - val_acc: 0.5007\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 1.4485 - acc: 0.5370 - val_loss: 1.5394 - val_acc: 0.5034\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.4307 - acc: 0.5464 - val_loss: 1.5469 - val_acc: 0.4980\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.4150 - acc: 0.5489 - val_loss: 1.5279 - val_acc: 0.5043\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.3996 - acc: 0.5589 - val_loss: 1.5091 - val_acc: 0.5127\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.3868 - acc: 0.5631 - val_loss: 1.5069 - val_acc: 0.5137\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.3683 - acc: 0.5676 - val_loss: 1.5122 - val_acc: 0.5124\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.3533 - acc: 0.5764 - val_loss: 1.5185 - val_acc: 0.5161\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.3405 - acc: 0.5803 - val_loss: 1.4992 - val_acc: 0.5261\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.3252 - acc: 0.5844 - val_loss: 1.5203 - val_acc: 0.5114\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.3112 - acc: 0.5898 - val_loss: 1.5145 - val_acc: 0.5144\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.2979 - acc: 0.5932 - val_loss: 1.5013 - val_acc: 0.5172\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2876 - acc: 0.5979 - val_loss: 1.5476 - val_acc: 0.5098\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.2717 - acc: 0.6006 - val_loss: 1.5114 - val_acc: 0.5134\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2600 - acc: 0.6072 - val_loss: 1.4818 - val_acc: 0.5242\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.2472 - acc: 0.6099 - val_loss: 1.5163 - val_acc: 0.5175\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.2378 - acc: 0.6149 - val_loss: 1.4936 - val_acc: 0.5238\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.2197 - acc: 0.6197 - val_loss: 1.4771 - val_acc: 0.5341\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.2060 - acc: 0.6262 - val_loss: 1.4711 - val_acc: 0.5345\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.1948 - acc: 0.6314 - val_loss: 1.4768 - val_acc: 0.5284\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.1865 - acc: 0.6330 - val_loss: 1.5662 - val_acc: 0.5040\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.1721 - acc: 0.6369 - val_loss: 1.5094 - val_acc: 0.5246\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.1601 - acc: 0.6418 - val_loss: 1.4884 - val_acc: 0.5315\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.1469 - acc: 0.6477 - val_loss: 1.4757 - val_acc: 0.5345\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.1371 - acc: 0.6514 - val_loss: 1.5185 - val_acc: 0.5228\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.1174 - acc: 0.6584 - val_loss: 1.6084 - val_acc: 0.5008\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.1127 - acc: 0.6587 - val_loss: 1.4825 - val_acc: 0.5422\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.1025 - acc: 0.6623 - val_loss: 1.5409 - val_acc: 0.5219\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.0909 - acc: 0.6672 - val_loss: 1.5997 - val_acc: 0.5045\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.0752 - acc: 0.6720 - val_loss: 1.4917 - val_acc: 0.5410\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.0672 - acc: 0.6748 - val_loss: 1.5006 - val_acc: 0.5359\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.0535 - acc: 0.6795 - val_loss: 1.6347 - val_acc: 0.5013\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.0463 - acc: 0.6823 - val_loss: 1.5608 - val_acc: 0.5196\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.0325 - acc: 0.6865 - val_loss: 1.6402 - val_acc: 0.5085\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.0139 - acc: 0.6954 - val_loss: 1.5172 - val_acc: 0.5291\n",
            "Experiment with Regulizer = 0.000000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.0444 - acc: 0.2683 - val_loss: 1.8716 - val_acc: 0.3408\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.8105 - acc: 0.3650 - val_loss: 1.7699 - val_acc: 0.3793\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.7250 - acc: 0.3979 - val_loss: 1.6978 - val_acc: 0.4036\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.6654 - acc: 0.4181 - val_loss: 1.6431 - val_acc: 0.4239\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.6179 - acc: 0.4346 - val_loss: 1.6026 - val_acc: 0.4386\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.5779 - acc: 0.4483 - val_loss: 1.5783 - val_acc: 0.4449\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.5469 - acc: 0.4585 - val_loss: 1.5478 - val_acc: 0.4550\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.5149 - acc: 0.4693 - val_loss: 1.5278 - val_acc: 0.4637\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.4875 - acc: 0.4789 - val_loss: 1.4991 - val_acc: 0.4690\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.4642 - acc: 0.4869 - val_loss: 1.4832 - val_acc: 0.4795\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.4391 - acc: 0.4967 - val_loss: 1.4903 - val_acc: 0.4708\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.4172 - acc: 0.5034 - val_loss: 1.4603 - val_acc: 0.4797\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.3956 - acc: 0.5111 - val_loss: 1.4408 - val_acc: 0.4892\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.3738 - acc: 0.5174 - val_loss: 1.4411 - val_acc: 0.4873\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.3526 - acc: 0.5233 - val_loss: 1.4226 - val_acc: 0.4965\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.3349 - acc: 0.5317 - val_loss: 1.4034 - val_acc: 0.5030\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.3163 - acc: 0.5380 - val_loss: 1.4032 - val_acc: 0.5027\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.3013 - acc: 0.5430 - val_loss: 1.3829 - val_acc: 0.5108\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2811 - acc: 0.5480 - val_loss: 1.3706 - val_acc: 0.5165\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.2659 - acc: 0.5558 - val_loss: 1.3809 - val_acc: 0.5135\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2529 - acc: 0.5580 - val_loss: 1.3959 - val_acc: 0.5066\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.2382 - acc: 0.5645 - val_loss: 1.3781 - val_acc: 0.5119\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.2214 - acc: 0.5720 - val_loss: 1.3830 - val_acc: 0.5123\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.2041 - acc: 0.5772 - val_loss: 1.3460 - val_acc: 0.5219\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.1917 - acc: 0.5821 - val_loss: 1.4252 - val_acc: 0.5059\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.1768 - acc: 0.5874 - val_loss: 1.3486 - val_acc: 0.5191\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.1622 - acc: 0.5934 - val_loss: 1.3515 - val_acc: 0.5273\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.1507 - acc: 0.5950 - val_loss: 1.3740 - val_acc: 0.5119\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.1384 - acc: 0.5994 - val_loss: 1.3475 - val_acc: 0.5270\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.1241 - acc: 0.6046 - val_loss: 1.3592 - val_acc: 0.5200\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.1106 - acc: 0.6099 - val_loss: 1.3904 - val_acc: 0.5179\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.0982 - acc: 0.6150 - val_loss: 1.3715 - val_acc: 0.5196\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.0859 - acc: 0.6200 - val_loss: 1.3461 - val_acc: 0.5316\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.0723 - acc: 0.6233 - val_loss: 1.3571 - val_acc: 0.5224\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.0595 - acc: 0.6271 - val_loss: 1.3280 - val_acc: 0.5354\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.0472 - acc: 0.6315 - val_loss: 1.3913 - val_acc: 0.5212\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.0356 - acc: 0.6384 - val_loss: 1.4121 - val_acc: 0.5167\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.0224 - acc: 0.6412 - val_loss: 1.3532 - val_acc: 0.5323\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.0113 - acc: 0.6442 - val_loss: 1.3844 - val_acc: 0.5255\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 0.9966 - acc: 0.6490 - val_loss: 1.3693 - val_acc: 0.5313\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 0.9845 - acc: 0.6549 - val_loss: 1.3922 - val_acc: 0.5211\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9746 - acc: 0.6604 - val_loss: 1.3669 - val_acc: 0.5303\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 0.9594 - acc: 0.6645 - val_loss: 1.4533 - val_acc: 0.5106\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 0.9467 - acc: 0.6676 - val_loss: 1.3418 - val_acc: 0.5394\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 0.9387 - acc: 0.6711 - val_loss: 1.3985 - val_acc: 0.5261\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 0.9237 - acc: 0.6754 - val_loss: 1.4363 - val_acc: 0.5107\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.9139 - acc: 0.6803 - val_loss: 1.4052 - val_acc: 0.5280\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 0.8997 - acc: 0.6842 - val_loss: 1.4055 - val_acc: 0.5244\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 0.8927 - acc: 0.6883 - val_loss: 1.4313 - val_acc: 0.5213\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 0.8793 - acc: 0.6929 - val_loss: 1.4277 - val_acc: 0.5238\n",
            "Experiment with Regulizer = 0.000000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.0241 - acc: 0.2786 - val_loss: 1.8613 - val_acc: 0.3455\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.8130 - acc: 0.3619 - val_loss: 1.7609 - val_acc: 0.3826\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.7310 - acc: 0.3931 - val_loss: 1.6968 - val_acc: 0.4105\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.6726 - acc: 0.4134 - val_loss: 1.6492 - val_acc: 0.4186\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.6248 - acc: 0.4298 - val_loss: 1.6032 - val_acc: 0.4371\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.5833 - acc: 0.4467 - val_loss: 1.5677 - val_acc: 0.4496\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.5479 - acc: 0.4583 - val_loss: 1.5554 - val_acc: 0.4535\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.5174 - acc: 0.4675 - val_loss: 1.5324 - val_acc: 0.4559\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.4899 - acc: 0.4782 - val_loss: 1.5117 - val_acc: 0.4626\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.4618 - acc: 0.4875 - val_loss: 1.5028 - val_acc: 0.4617\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.4385 - acc: 0.4948 - val_loss: 1.4659 - val_acc: 0.4785\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 1.4158 - acc: 0.5027 - val_loss: 1.4453 - val_acc: 0.4914\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.3929 - acc: 0.5092 - val_loss: 1.4382 - val_acc: 0.4923\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.3719 - acc: 0.5166 - val_loss: 1.4329 - val_acc: 0.4945\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 1.3543 - acc: 0.5233 - val_loss: 1.4188 - val_acc: 0.4973\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.3364 - acc: 0.5296 - val_loss: 1.4051 - val_acc: 0.5000\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.3184 - acc: 0.5351 - val_loss: 1.4053 - val_acc: 0.5007\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2997 - acc: 0.5431 - val_loss: 1.3944 - val_acc: 0.5043\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2844 - acc: 0.5479 - val_loss: 1.4166 - val_acc: 0.5035\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.2681 - acc: 0.5536 - val_loss: 1.3734 - val_acc: 0.5154\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.2524 - acc: 0.5581 - val_loss: 1.3825 - val_acc: 0.5119\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 1.2379 - acc: 0.5637 - val_loss: 1.3539 - val_acc: 0.5210\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.2200 - acc: 0.5703 - val_loss: 1.3886 - val_acc: 0.5062\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.2087 - acc: 0.5762 - val_loss: 1.3682 - val_acc: 0.5166\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.1934 - acc: 0.5785 - val_loss: 1.4121 - val_acc: 0.5027\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.1792 - acc: 0.5846 - val_loss: 1.3739 - val_acc: 0.5222\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.1666 - acc: 0.5894 - val_loss: 1.3419 - val_acc: 0.5248\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.1505 - acc: 0.5950 - val_loss: 1.3512 - val_acc: 0.5206\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 1.1403 - acc: 0.5994 - val_loss: 1.3514 - val_acc: 0.5200\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 1.1255 - acc: 0.6041 - val_loss: 1.3740 - val_acc: 0.5222\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.1125 - acc: 0.6094 - val_loss: 1.3634 - val_acc: 0.5207\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 1.0981 - acc: 0.6134 - val_loss: 1.4060 - val_acc: 0.5055\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.0858 - acc: 0.6178 - val_loss: 1.3740 - val_acc: 0.5221\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.0744 - acc: 0.6223 - val_loss: 1.3657 - val_acc: 0.5214\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 1.0634 - acc: 0.6271 - val_loss: 1.3416 - val_acc: 0.5263\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 1.0510 - acc: 0.6314 - val_loss: 1.3362 - val_acc: 0.5336\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.0343 - acc: 0.6356 - val_loss: 1.3646 - val_acc: 0.5223\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.0252 - acc: 0.6402 - val_loss: 1.4069 - val_acc: 0.5126\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 1.0116 - acc: 0.6443 - val_loss: 1.3261 - val_acc: 0.5384\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 0.9990 - acc: 0.6483 - val_loss: 1.3368 - val_acc: 0.5356\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 0.9849 - acc: 0.6528 - val_loss: 1.3485 - val_acc: 0.5315\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.9740 - acc: 0.6561 - val_loss: 1.4889 - val_acc: 0.4922\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 0.9598 - acc: 0.6630 - val_loss: 1.3485 - val_acc: 0.5355\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 0.9503 - acc: 0.6663 - val_loss: 1.6827 - val_acc: 0.4623\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.9364 - acc: 0.6704 - val_loss: 1.3557 - val_acc: 0.5398\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 0.9295 - acc: 0.6739 - val_loss: 1.3716 - val_acc: 0.5249\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.9136 - acc: 0.6789 - val_loss: 1.4236 - val_acc: 0.5169\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 0.9024 - acc: 0.6828 - val_loss: 1.4107 - val_acc: 0.5278\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 0.8902 - acc: 0.6875 - val_loss: 1.3870 - val_acc: 0.5276\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 0.8790 - acc: 0.6937 - val_loss: 1.4256 - val_acc: 0.5283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rAQ0BdLmXYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "31677283-17ce-40a4-d078-d774bad1abae"
      },
      "source": [
        "\"\"\"Code Here\n",
        "將結果繪出\n",
        "\"\"\"\n",
        "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, cond in enumerate(results.keys()):\n",
        "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
        "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
        "plt.title(\"Loss\")\n",
        "plt.ylim([0, 5])\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, cond in enumerate(results.keys()):\n",
        "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
        "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0cb0062b2f06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFlCAYAAAA+t0u5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEG-yY84AKnM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3beb13af-19c8-4922-d033-9e3bb76a58ec"
      },
      "source": [
        "for regulizer_ratio in EXP:\n",
        "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
        "    print(\"Experiment with Regulizer = %.6f\" % (regulizer_ratio))\n",
        "    model = build_mlp_l1l2(input_shape=x_train.shape[1:], ratio=regulizer_ratio)\n",
        "    model.summary()\n",
        "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
        "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
        "\n",
        "    model.fit(x_train, y_train, \n",
        "              epochs=EPOCHS, \n",
        "              batch_size=BATCH_SIZE, \n",
        "              validation_data=(x_test, y_test), \n",
        "              shuffle=True)\n",
        "    \n",
        "    # Collect results\n",
        "    train_loss = model.history.history[\"loss\"]\n",
        "    valid_loss = model.history.history[\"val_loss\"]\n",
        "    train_acc = model.history.history[\"acc\"]\n",
        "    valid_acc = model.history.history[\"val_acc\"]\n",
        "    \n",
        "    exp_name_tag = \"exp-l1l2-%s\" % str(regulizer_ratio)\n",
        "    results[exp_name_tag] = {'train-loss': train_loss,\n",
        "                             'valid-loss': valid_loss,\n",
        "                             'train-acc': train_acc,\n",
        "                             'valid-acc': valid_acc}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment with Regulizer = 0.010000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 14s 271us/step - loss: 197.9663 - acc: 0.2272 - val_loss: 35.8793 - val_acc: 0.2458\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 15.8891 - acc: 0.1106 - val_loss: 5.1448 - val_acc: 0.1000\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 13s 260us/step - loss: 3.2207 - acc: 0.1000 - val_loss: 2.4719 - val_acc: 0.1000\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4632 - acc: 0.0995 - val_loss: 2.4624 - val_acc: 0.1000\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4624 - acc: 0.0990 - val_loss: 2.4622 - val_acc: 0.1000\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.4624 - acc: 0.0987 - val_loss: 2.4621 - val_acc: 0.1000\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 13s 260us/step - loss: 2.4623 - acc: 0.0967 - val_loss: 2.4622 - val_acc: 0.1000\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4623 - acc: 0.0957 - val_loss: 2.4621 - val_acc: 0.1000\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 2.4623 - acc: 0.0973 - val_loss: 2.4621 - val_acc: 0.1000\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4622 - acc: 0.0980 - val_loss: 2.4621 - val_acc: 0.1000\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4622 - acc: 0.0978 - val_loss: 2.4620 - val_acc: 0.1000\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.4621 - acc: 0.0974 - val_loss: 2.4619 - val_acc: 0.1000\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.4621 - acc: 0.0974 - val_loss: 2.4621 - val_acc: 0.1000\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4621 - acc: 0.0951 - val_loss: 2.4619 - val_acc: 0.1000\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.4620 - acc: 0.0970 - val_loss: 2.4619 - val_acc: 0.1000\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4620 - acc: 0.0984 - val_loss: 2.4619 - val_acc: 0.1000\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4620 - acc: 0.0981 - val_loss: 2.4618 - val_acc: 0.1000\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 2.4620 - acc: 0.0999 - val_loss: 2.4619 - val_acc: 0.1000\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.4620 - acc: 0.0980 - val_loss: 2.4619 - val_acc: 0.1000\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4620 - acc: 0.0966 - val_loss: 2.4617 - val_acc: 0.1000\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4619 - acc: 0.0981 - val_loss: 2.4619 - val_acc: 0.1000\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 2.4619 - acc: 0.0963 - val_loss: 2.4618 - val_acc: 0.1000\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 2.4619 - acc: 0.0954 - val_loss: 2.4619 - val_acc: 0.1000\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4619 - acc: 0.0967 - val_loss: 2.4618 - val_acc: 0.1000\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 2.4619 - acc: 0.0980 - val_loss: 2.4619 - val_acc: 0.1000\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 13s 260us/step - loss: 2.4619 - acc: 0.0975 - val_loss: 2.4618 - val_acc: 0.1000\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 2.4619 - acc: 0.0969 - val_loss: 2.4617 - val_acc: 0.1000\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 2.4619 - acc: 0.0977 - val_loss: 2.4618 - val_acc: 0.1000\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4618 - acc: 0.0968 - val_loss: 2.4617 - val_acc: 0.1000\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4618 - acc: 0.0979 - val_loss: 2.4618 - val_acc: 0.1000\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4618 - acc: 0.0979 - val_loss: 2.4616 - val_acc: 0.1000\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4618 - acc: 0.0980 - val_loss: 2.4616 - val_acc: 0.1000\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4617 - acc: 0.0974 - val_loss: 2.4617 - val_acc: 0.1000\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4617 - acc: 0.0963 - val_loss: 2.4615 - val_acc: 0.1000\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4617 - acc: 0.0997 - val_loss: 2.4616 - val_acc: 0.1000\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4617 - acc: 0.0982 - val_loss: 2.4616 - val_acc: 0.1000\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.4617 - acc: 0.0959 - val_loss: 2.4615 - val_acc: 0.1000\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 2.4616 - acc: 0.0992 - val_loss: 2.4615 - val_acc: 0.1000\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 2.4616 - acc: 0.0982 - val_loss: 2.4615 - val_acc: 0.1000\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4616 - acc: 0.0971 - val_loss: 2.4615 - val_acc: 0.1000\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4616 - acc: 0.0985 - val_loss: 2.4615 - val_acc: 0.1000\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 13s 270us/step - loss: 2.4616 - acc: 0.0976 - val_loss: 2.4614 - val_acc: 0.1000\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4615 - acc: 0.0969 - val_loss: 2.4615 - val_acc: 0.1000\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.4615 - acc: 0.0982 - val_loss: 2.4613 - val_acc: 0.1000\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4615 - acc: 0.0985 - val_loss: 2.4614 - val_acc: 0.1000\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 2.4614 - acc: 0.0987 - val_loss: 2.4613 - val_acc: 0.1000\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4614 - acc: 0.0979 - val_loss: 2.4613 - val_acc: 0.1000\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 2.4614 - acc: 0.0976 - val_loss: 2.4613 - val_acc: 0.1000\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 2.4614 - acc: 0.0976 - val_loss: 2.4613 - val_acc: 0.1000\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 13s 260us/step - loss: 2.4614 - acc: 0.0976 - val_loss: 2.4612 - val_acc: 0.1000\n",
            "Experiment with Regulizer = 0.000100\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 14s 271us/step - loss: 18.7886 - acc: 0.2784 - val_loss: 17.3549 - val_acc: 0.3434\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 16.1418 - acc: 0.3569 - val_loss: 14.9824 - val_acc: 0.3703\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 13.9570 - acc: 0.3795 - val_loss: 12.9746 - val_acc: 0.3929\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 12.1089 - acc: 0.3915 - val_loss: 11.2723 - val_acc: 0.4052\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 10.5374 - acc: 0.4031 - val_loss: 9.8275 - val_acc: 0.4067\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 9.2007 - acc: 0.4101 - val_loss: 8.5975 - val_acc: 0.4168\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 8.0628 - acc: 0.4142 - val_loss: 7.5494 - val_acc: 0.4206\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 7.0935 - acc: 0.4219 - val_loss: 6.6541 - val_acc: 0.4264\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 6.2669 - acc: 0.4255 - val_loss: 5.8931 - val_acc: 0.4276\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 5.5631 - acc: 0.4275 - val_loss: 5.2500 - val_acc: 0.4264\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 4.9649 - acc: 0.4324 - val_loss: 4.6969 - val_acc: 0.4288\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 4.4544 - acc: 0.4352 - val_loss: 4.2306 - val_acc: 0.4325\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 4.0217 - acc: 0.4379 - val_loss: 3.8318 - val_acc: 0.4364\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 3.6550 - acc: 0.4389 - val_loss: 3.4949 - val_acc: 0.4385\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 3.3427 - acc: 0.4406 - val_loss: 3.2135 - val_acc: 0.4363\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 3.0808 - acc: 0.4436 - val_loss: 2.9872 - val_acc: 0.4264\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 2.8598 - acc: 0.4470 - val_loss: 2.7692 - val_acc: 0.4428\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 2.6761 - acc: 0.4461 - val_loss: 2.5995 - val_acc: 0.4450\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 14s 274us/step - loss: 2.5201 - acc: 0.4476 - val_loss: 2.4572 - val_acc: 0.4473\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 2.3895 - acc: 0.4496 - val_loss: 2.3416 - val_acc: 0.4517\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.2842 - acc: 0.4510 - val_loss: 2.2421 - val_acc: 0.4470\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 2.1983 - acc: 0.4518 - val_loss: 2.1786 - val_acc: 0.4380\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 2.1281 - acc: 0.4526 - val_loss: 2.1145 - val_acc: 0.4478\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.0704 - acc: 0.4535 - val_loss: 2.0550 - val_acc: 0.4443\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 2.0234 - acc: 0.4561 - val_loss: 2.0101 - val_acc: 0.4486\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.9861 - acc: 0.4553 - val_loss: 1.9840 - val_acc: 0.4506\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.9549 - acc: 0.4555 - val_loss: 1.9428 - val_acc: 0.4544\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.9299 - acc: 0.4557 - val_loss: 2.0008 - val_acc: 0.4181\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.9098 - acc: 0.4571 - val_loss: 1.9178 - val_acc: 0.4536\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.8928 - acc: 0.4571 - val_loss: 1.8979 - val_acc: 0.4529\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.8765 - acc: 0.4588 - val_loss: 1.8979 - val_acc: 0.4484\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.8629 - acc: 0.4603 - val_loss: 1.8692 - val_acc: 0.4624\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.8509 - acc: 0.4631 - val_loss: 1.8723 - val_acc: 0.4471\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.8412 - acc: 0.4622 - val_loss: 1.8441 - val_acc: 0.4617\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.8307 - acc: 0.4640 - val_loss: 1.8675 - val_acc: 0.4429\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.8217 - acc: 0.4658 - val_loss: 1.8326 - val_acc: 0.4623\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.8132 - acc: 0.4651 - val_loss: 1.8277 - val_acc: 0.4612\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 14s 270us/step - loss: 1.8077 - acc: 0.4692 - val_loss: 1.8365 - val_acc: 0.4567\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 14s 272us/step - loss: 1.8005 - acc: 0.4695 - val_loss: 1.8302 - val_acc: 0.4493\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.7956 - acc: 0.4688 - val_loss: 1.8048 - val_acc: 0.4684\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.7899 - acc: 0.4711 - val_loss: 1.7984 - val_acc: 0.4691\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 14s 273us/step - loss: 1.7836 - acc: 0.4730 - val_loss: 1.8149 - val_acc: 0.4644\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 13s 270us/step - loss: 1.7786 - acc: 0.4720 - val_loss: 1.7937 - val_acc: 0.4697\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 1.7763 - acc: 0.4732 - val_loss: 1.8252 - val_acc: 0.4495\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 1.7711 - acc: 0.4737 - val_loss: 1.8811 - val_acc: 0.4321\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 14s 271us/step - loss: 1.7674 - acc: 0.4764 - val_loss: 1.7915 - val_acc: 0.4665\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 14s 271us/step - loss: 1.7631 - acc: 0.4763 - val_loss: 1.8474 - val_acc: 0.4347\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.7596 - acc: 0.4777 - val_loss: 1.7753 - val_acc: 0.4731\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.7547 - acc: 0.4792 - val_loss: 1.7823 - val_acc: 0.4740\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.7526 - acc: 0.4790 - val_loss: 1.7760 - val_acc: 0.4700\n",
            "Experiment with Regulizer = 0.000000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 14s 275us/step - loss: 15.0991 - acc: 0.2661 - val_loss: 13.9530 - val_acc: 0.3355\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 13.0162 - acc: 0.3567 - val_loss: 12.1230 - val_acc: 0.3671\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 11.3417 - acc: 0.3800 - val_loss: 10.5961 - val_acc: 0.3913\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 9.9308 - acc: 0.3944 - val_loss: 9.2930 - val_acc: 0.3994\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 8.7297 - acc: 0.4058 - val_loss: 8.1866 - val_acc: 0.4139\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 7.7079 - acc: 0.4150 - val_loss: 7.2510 - val_acc: 0.4128\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 6.8367 - acc: 0.4215 - val_loss: 6.4468 - val_acc: 0.4237\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 6.0923 - acc: 0.4272 - val_loss: 5.7579 - val_acc: 0.4264\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 5.4569 - acc: 0.4327 - val_loss: 5.1715 - val_acc: 0.4290\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 4.9142 - acc: 0.4361 - val_loss: 4.6678 - val_acc: 0.4367\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 4.4494 - acc: 0.4408 - val_loss: 4.2512 - val_acc: 0.4316\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 14s 272us/step - loss: 4.0521 - acc: 0.4467 - val_loss: 3.8881 - val_acc: 0.4328\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 14s 271us/step - loss: 3.7120 - acc: 0.4503 - val_loss: 3.5760 - val_acc: 0.4339\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 13s 270us/step - loss: 3.4215 - acc: 0.4537 - val_loss: 3.3090 - val_acc: 0.4431\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 14s 275us/step - loss: 3.1708 - acc: 0.4554 - val_loss: 3.0673 - val_acc: 0.4528\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 2.9566 - acc: 0.4602 - val_loss: 2.8654 - val_acc: 0.4598\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 2.7732 - acc: 0.4615 - val_loss: 2.7036 - val_acc: 0.4598\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 14s 271us/step - loss: 2.6146 - acc: 0.4671 - val_loss: 2.5499 - val_acc: 0.4682\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 13s 270us/step - loss: 2.4804 - acc: 0.4695 - val_loss: 2.4331 - val_acc: 0.4650\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 2.3635 - acc: 0.4721 - val_loss: 2.3411 - val_acc: 0.4580\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 2.2647 - acc: 0.4737 - val_loss: 2.2589 - val_acc: 0.4598\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 14s 270us/step - loss: 2.1785 - acc: 0.4770 - val_loss: 2.1749 - val_acc: 0.4549\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 2.1043 - acc: 0.4804 - val_loss: 2.0898 - val_acc: 0.4705\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 2.0414 - acc: 0.4814 - val_loss: 2.0296 - val_acc: 0.4716\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.9878 - acc: 0.4824 - val_loss: 1.9969 - val_acc: 0.4673\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.9396 - acc: 0.4833 - val_loss: 1.9573 - val_acc: 0.4698\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.8967 - acc: 0.4887 - val_loss: 1.9048 - val_acc: 0.4844\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.8619 - acc: 0.4892 - val_loss: 1.8769 - val_acc: 0.4770\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.8299 - acc: 0.4925 - val_loss: 1.8470 - val_acc: 0.4798\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.8035 - acc: 0.4938 - val_loss: 1.8319 - val_acc: 0.4796\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.7802 - acc: 0.4949 - val_loss: 1.8064 - val_acc: 0.4786\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.7586 - acc: 0.4977 - val_loss: 1.7825 - val_acc: 0.4820\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 1.7416 - acc: 0.4994 - val_loss: 1.7594 - val_acc: 0.4926\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.7234 - acc: 0.4997 - val_loss: 1.7732 - val_acc: 0.4812\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 14s 274us/step - loss: 1.7108 - acc: 0.5022 - val_loss: 1.7504 - val_acc: 0.4895\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.6995 - acc: 0.5051 - val_loss: 1.7613 - val_acc: 0.4809\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.6901 - acc: 0.5050 - val_loss: 1.7324 - val_acc: 0.4826\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 14s 275us/step - loss: 1.6765 - acc: 0.5071 - val_loss: 1.7130 - val_acc: 0.4883\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.6673 - acc: 0.5110 - val_loss: 1.7416 - val_acc: 0.4780\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 13s 270us/step - loss: 1.6608 - acc: 0.5104 - val_loss: 1.7210 - val_acc: 0.4933\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.6521 - acc: 0.5135 - val_loss: 1.7131 - val_acc: 0.4960\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 1.6470 - acc: 0.5157 - val_loss: 1.7261 - val_acc: 0.4854\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.6415 - acc: 0.5145 - val_loss: 1.7174 - val_acc: 0.4881\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.6380 - acc: 0.5172 - val_loss: 1.7028 - val_acc: 0.4900\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.6336 - acc: 0.5181 - val_loss: 1.6911 - val_acc: 0.4966\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.6262 - acc: 0.5198 - val_loss: 1.7064 - val_acc: 0.4887\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.6237 - acc: 0.5211 - val_loss: 1.7300 - val_acc: 0.4802\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.6169 - acc: 0.5252 - val_loss: 1.6936 - val_acc: 0.4835\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 13s 269us/step - loss: 1.6148 - acc: 0.5252 - val_loss: 1.6773 - val_acc: 0.5021\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.6129 - acc: 0.5240 - val_loss: 1.6978 - val_acc: 0.4889\n",
            "Experiment with Regulizer = 0.000000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
            "_________________________________________________________________\n",
            "hidden_layer2 (Dense)        (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "hidden_layer3 (Dense)        (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,738,890\n",
            "Trainable params: 1,738,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 15.0858 - acc: 0.2664 - val_loss: 13.9455 - val_acc: 0.3336\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 13s 259us/step - loss: 13.0094 - acc: 0.3571 - val_loss: 12.1166 - val_acc: 0.3712\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 13s 256us/step - loss: 11.3375 - acc: 0.3820 - val_loss: 10.5858 - val_acc: 0.3919\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 13s 259us/step - loss: 9.9260 - acc: 0.3949 - val_loss: 9.2846 - val_acc: 0.3983\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 8.7258 - acc: 0.4037 - val_loss: 8.1862 - val_acc: 0.4018\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 13s 260us/step - loss: 7.7040 - acc: 0.4116 - val_loss: 7.2489 - val_acc: 0.4095\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 13s 258us/step - loss: 6.8314 - acc: 0.4210 - val_loss: 6.4431 - val_acc: 0.4179\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 6.0870 - acc: 0.4237 - val_loss: 5.7553 - val_acc: 0.4233\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 5.4512 - acc: 0.4313 - val_loss: 5.1631 - val_acc: 0.4344\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 4.9084 - acc: 0.4386 - val_loss: 4.6642 - val_acc: 0.4413\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 4.4452 - acc: 0.4414 - val_loss: 4.2515 - val_acc: 0.4315\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 13s 259us/step - loss: 4.0467 - acc: 0.4466 - val_loss: 3.8845 - val_acc: 0.4372\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 3.7065 - acc: 0.4511 - val_loss: 3.5720 - val_acc: 0.4441\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 13s 261us/step - loss: 3.4156 - acc: 0.4539 - val_loss: 3.2885 - val_acc: 0.4527\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 3.1647 - acc: 0.4585 - val_loss: 3.0723 - val_acc: 0.4473\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 2.9511 - acc: 0.4629 - val_loss: 2.8817 - val_acc: 0.4477\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 2.7672 - acc: 0.4661 - val_loss: 2.6951 - val_acc: 0.4597\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 2.6098 - acc: 0.4694 - val_loss: 2.5580 - val_acc: 0.4560\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 2.4748 - acc: 0.4722 - val_loss: 2.4418 - val_acc: 0.4605\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 2.3588 - acc: 0.4740 - val_loss: 2.3759 - val_acc: 0.4464\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.2600 - acc: 0.4758 - val_loss: 2.2390 - val_acc: 0.4721\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 2.1742 - acc: 0.4789 - val_loss: 2.1824 - val_acc: 0.4602\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 2.1000 - acc: 0.4834 - val_loss: 2.0887 - val_acc: 0.4762\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 2.0354 - acc: 0.4824 - val_loss: 2.0325 - val_acc: 0.4690\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.9813 - acc: 0.4855 - val_loss: 1.9887 - val_acc: 0.4685\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.9338 - acc: 0.4888 - val_loss: 1.9365 - val_acc: 0.4827\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.8931 - acc: 0.4896 - val_loss: 1.9093 - val_acc: 0.4720\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.8579 - acc: 0.4923 - val_loss: 1.9098 - val_acc: 0.4585\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 14s 270us/step - loss: 1.8262 - acc: 0.4918 - val_loss: 1.8638 - val_acc: 0.4696\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 13s 268us/step - loss: 1.7988 - acc: 0.4973 - val_loss: 1.8304 - val_acc: 0.4802\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.7761 - acc: 0.4982 - val_loss: 1.8118 - val_acc: 0.4779\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.7550 - acc: 0.4986 - val_loss: 1.7905 - val_acc: 0.4848\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.7374 - acc: 0.5011 - val_loss: 1.7936 - val_acc: 0.4814\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.7205 - acc: 0.5030 - val_loss: 1.7564 - val_acc: 0.4825\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.7066 - acc: 0.5048 - val_loss: 1.7562 - val_acc: 0.4863\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.6962 - acc: 0.5059 - val_loss: 1.7302 - val_acc: 0.4889\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.6819 - acc: 0.5091 - val_loss: 1.7586 - val_acc: 0.4802\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.6722 - acc: 0.5123 - val_loss: 1.7231 - val_acc: 0.4902\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.6648 - acc: 0.5105 - val_loss: 1.7133 - val_acc: 0.4971\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.6566 - acc: 0.5132 - val_loss: 1.7394 - val_acc: 0.4680\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.6523 - acc: 0.5146 - val_loss: 1.7011 - val_acc: 0.4888\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.6448 - acc: 0.5160 - val_loss: 1.7265 - val_acc: 0.4748\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 13s 263us/step - loss: 1.6382 - acc: 0.5168 - val_loss: 1.7109 - val_acc: 0.4905\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 1.6345 - acc: 0.5175 - val_loss: 1.6986 - val_acc: 0.4931\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.6269 - acc: 0.5208 - val_loss: 1.6818 - val_acc: 0.4990\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.6226 - acc: 0.5221 - val_loss: 1.6756 - val_acc: 0.4908\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 13s 264us/step - loss: 1.6203 - acc: 0.5223 - val_loss: 1.7022 - val_acc: 0.4804\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 13s 266us/step - loss: 1.6164 - acc: 0.5233 - val_loss: 1.7193 - val_acc: 0.4872\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 13s 267us/step - loss: 1.6130 - acc: 0.5235 - val_loss: 1.6681 - val_acc: 0.5048\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 13s 265us/step - loss: 1.6100 - acc: 0.5269 - val_loss: 1.6922 - val_acc: 0.4951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tat_l6UQAK-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "0ed2d5c5-824e-42d0-80f1-2004e39b202e"
      },
      "source": [
        "\"\"\"Code Here\n",
        "將結果繪出\n",
        "\"\"\"\n",
        "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, cond in enumerate(results.keys()):\n",
        "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
        "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
        "plt.title(\"Loss\")\n",
        "plt.ylim([0, 5])\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, cond in enumerate(results.keys()):\n",
        "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
        "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-066948928ed1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid-loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor_bar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFlCAYAAAA+t0u5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ann5Ce1UALJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}